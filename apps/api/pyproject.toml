[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.pytest.ini_options]
minversion = "6.0"
addopts = "-ra -q --strict-markers --disable-warnings --tb=short"
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
markers = [
    "slow: marks tests as slow (deselect with '-m \"not slow\"')",
    "integration: marks tests as integration tests",
    "unit: marks tests as unit tests", 
    "knowledge_graph: marks tests for knowledge graph module"
]
asyncio_mode = "auto"
filterwarnings = [
    "ignore::UserWarning",
    "ignore::DeprecationWarning", 
    "ignore::PendingDeprecationWarning"
]

[tool.hatch.build.targets.wheel]
packages = ["src"]

[project]
name = "ai-agent-api"
version = "0.1.0"
description = "AI Agent System Backend API"
readme = "README.md"
requires-python = ">=3.11"
license = { text = "MIT" }
authors = [
    { name = "AI Agent Team" }
]
keywords = ["ai", "agent", "fastapi", "langgraph", "autogen"]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Framework :: FastAPI",
]

dependencies = [
    # Core Framework
    "fastapi>=0.116.1",
    "uvicorn[standard]>=0.30.0",
    "pydantic>=2.4.0",
    "pydantic-settings>=2.0.0",
    # Database
    "sqlalchemy>=2.0.0",
    "alembic>=1.12.0",
    "asyncpg>=0.29.0", # PostgreSQL async driver
    "redis[hiredis]>=5.0.0",
    # AI Frameworks
    "langgraph==0.6.5",
    "autogen-agentchat>=0.7.1", # 使用当前可用的稳定版本
    "langchain>=0.3.0",
    "openai>=1.54.0",
    # Vector Database
    "qdrant-client>=1.7.0",
    "pgvector>=0.4.1", # Latest available version, will upgrade to 0.8 when released
    "psycopg2-binary>=2.9.0", # PostgreSQL driver with binary extensions
    "numpy>=1.24.0", # For vector quantization algorithms
    "scikit-learn>=1.3.0", # For K-means clustering in quantization
    # Service Discovery
    # "etcd3>=0.12.0", # etcd client - disabled for now due to protobuf conflicts
    # Will be enabled once protobuf version conflicts are resolved
    # Deep Learning & Reinforcement Learning
    "tensorflow>=2.15.0", # Deep learning framework for DQN
    "tensorflow-probability>=0.22.0", # Probabilistic programming for RL
    # Graph Processing
    "networkx>=3.2.0",
    # Knowledge Graph & NLP
    "spacy>=3.7.0",
    "transformers>=4.35.0",
    "torch>=2.1.0",
    "stanza>=1.7.0",
    # MCP Protocol
    "mcp>=1.0.0",
    # Authentication & Security
    "fastapi-users[sqlalchemy]>=12.1.0",
    "python-jose[cryptography]>=3.3.0",
    "passlib[bcrypt]>=1.7.4",
    "slowapi>=0.1.9", # Rate limiting
    "python-multipart>=0.0.6", # Form data (already listed below, removing duplicate)
    "cryptography>=42.0.0", # Encryption support
    "bcrypt>=4.1.0", # Password hashing
    # Utilities
    "aiofiles>=23.2.1", # Async file operations
    "httpx>=0.25.0", # HTTP client
    "structlog>=23.2.0", # Structured logging
    "psutil>=5.9.0", # System and process utilities
    "tenacity>=8.2.0", # Retry logic
    # Development
    "python-dotenv>=1.0.0",
    "autogen-ext>=0.7.1",
    "tiktoken>=0.9.0",
    "matplotlib>=3.10.5",
    "seaborn>=0.13.2",
    "h5py>=3.14.0",
    "pandas>=2.3.1",
    "numba>=0.61.2",
    # Multimodal Processing
    "opencv-python>=4.8.0", # Video processing
    "Pillow>=10.0.0", # Image processing
    "PyPDF2>=3.0.0", # PDF processing
    "PyMuPDF>=1.23.0", # Advanced PDF processing
    "python-docx>=1.0.0", # Word document processing
    "python-pptx>=0.6.23", # PowerPoint processing
    "pytesseract>=0.3.10", # OCR for text extraction
    "unstructured[all-docs]>=0.10.0", # Document parsing for multimodal
    "langchain-community>=0.3.0", # LangChain community integrations
    "chromadb>=0.5.0", # Vector database for multimodal storage
    "nomic>=3.0.0", # Nomic embeddings for multimodal
    "openpyxl>=3.1.0", # Excel file processing
    "chardet>=5.2.0", # Character encoding detection
    "beautifulsoup4>=4.12.0", # HTML/XML parsing
    # A/B Testing and Statistical Analysis
    "mmh3>=4.1.0", # MurmurHash3 for traffic splitting
    "scipy>=1.11.0", # Statistical tests and functions
    "statsmodels>=0.14.0", # Advanced statistical modeling and power analysis
    "pytest-mock>=3.14.1",
    "pytest-html>=4.1.1",
    "optuna>=4.5.0",
    # Model Evaluation
    "evaluate>=0.4.0", # Hugging Face evaluation library
    "lm-eval[api]>=0.4.0", # Language Model evaluation harness
    "datasets>=2.14.0", # Dataset processing
    "accelerate>=0.21.0", # Model acceleration
    "peft>=0.5.0", # Parameter-efficient fine-tuning
    "sentence-transformers>=2.2.0", # Sentence embeddings
    "rouge-score>=0.1.2", # ROUGE metrics
    "sacrebleu>=2.3.0", # BLEU metrics
    "nltk>=3.8.1", # Natural language toolkit
    "jinja2>=3.1.0",
    "textblob>=0.19.0",
    "aioredis>=2.0.1",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-asyncio>=0.21.0",
    "pytest-cov>=4.1.0",
    "httpx>=0.25.0",  # For testing FastAPI
    "aiohttp>=3.12.0",  # For async HTTP testing
    "factory-boy>=3.3.0",  # Test data generation
    "faker>=20.0.0",  # Fake data generation
]

test = [
    "pytest>=7.4.0",
    "pytest-asyncio>=0.21.0",
    "pytest-cov>=4.1.0",
    "httpx>=0.25.0",
    "aiohttp>=3.12.0",
    "factory-boy>=3.3.0",
    "faker>=20.0.0",
]

lint = [
    "black>=23.0.0",
    "ruff>=0.1.0",
    "mypy>=1.7.0",
    "pre-commit>=3.5.0",
]

[project.urls]
Homepage = "https://github.com/your-org/ai-agent-system"
Repository = "https://github.com/your-org/ai-agent-system"
Issues = "https://github.com/your-org/ai-agent-system/issues"

[dependency-groups]
test = [
    "pytest>=7.4.0",
    "pytest-asyncio>=0.21.0",
    "pytest-cov>=4.1.0",
    "httpx>=0.25.0",
    "factory-boy>=3.3.0",
    "faker>=20.0.0",
    "aiohttp>=3.9.0",
]

dev = [
    "pytest>=7.4.0",
    "pytest-asyncio>=0.21.0",
    "pytest-cov>=4.1.0",
    "httpx>=0.25.0",
    "factory-boy>=3.3.0",
    "faker>=20.0.0",
    "aiohttp>=3.12.0",
]

lint = [
    "black>=23.0.0",
    "ruff>=0.1.0",
    "mypy>=1.7.0",
    "pre-commit>=3.5.0",
]

[tool.black]
line-length = 88
target-version = ['py311']
include = '\.pyi?$'
extend-exclude = '''
/(
  # directories
  \.eggs
  | \.git
  | \.mypy_cache
  | \.pytest_cache
  | \.venv
  | build
  | dist
)/
'''

[tool.ruff]
target-version = "py311"
line-length = 88
select = [
    "E",  # pycodestyle errors
    "W",  # pycodestyle warnings
    "F",  # pyflakes
    "I",  # isort
    "B",  # flake8-bugbear
    "C4", # flake8-comprehensions
    "UP", # pyupgrade
]
ignore = [
    "E501",  # line too long, handled by black
    "B008",  # do not perform function calls in argument defaults
    "C901",  # too complex
]

[tool.ruff.per-file-ignores]
"__init__.py" = ["F401"]

[tool.ruff.isort]
known-first-party = ["src"]

