#!/usr/bin/env python3
"""
å¿«é€ŸéªŒè¯æ¨¡å‹å‹ç¼©æ ¸å¿ƒåŠŸèƒ½
"""

import torch
import torch.nn as nn

# æµ‹è¯•é‡åŒ–å¼•æ“åŸºç¡€åŠŸèƒ½
def test_basic_quantization():
    print("ğŸ”§ æµ‹è¯•åŸºç¡€é‡åŒ–åŠŸèƒ½...")
    
    try:
        # åˆ›å»ºç®€å•æ¨¡å‹
        class SimpleModel(nn.Module):
            def __init__(self):
                super().__init__()
                self.linear = nn.Linear(5, 2)
            
            def forward(self, x):
                return self.linear(x)
        
        model = SimpleModel()
        model.eval()
        
        # ä½¿ç”¨PyTorchåŸç”Ÿé‡åŒ–
        quantized_model = torch.quantization.quantize_dynamic(
            model, {nn.Linear}, dtype=torch.qint8
        )
        
        # æµ‹è¯•æ¨ç†
        test_input = torch.randn(1, 5)
        
        with torch.no_grad():
            original_output = model(test_input)
            quantized_output = quantized_model(test_input)
        
        print(f"  âœ… åŸå§‹æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {original_output.shape}")
        print(f"  âœ… é‡åŒ–æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {quantized_output.shape}")
        print(f"  âœ… è¾“å‡ºå·®å¼‚: {torch.mean(torch.abs(original_output - quantized_output)).item():.6f}")
        
        # è®¡ç®—æ¨¡å‹å¤§å°
        import pickle
        original_size = len(pickle.dumps(model.state_dict()))
        quantized_size = len(pickle.dumps(quantized_model.state_dict()))
        compression_ratio = original_size / quantized_size
        
        print(f"  âœ… å‹ç¼©æ¯”: {compression_ratio:.2f}x")
        
        return True
        
    except Exception as e:
        print(f"  âŒ é‡åŒ–æµ‹è¯•å¤±è´¥: {e}")
        return False


# æµ‹è¯•æ•°æ®æ¨¡å‹
def test_data_models():
    print("\nğŸ“Š æµ‹è¯•æ•°æ®æ¨¡å‹...")
    
    try:
        from src.ai.model_compression.models import (
            QuantizationConfig,
            QuantizationMethod, 
            PrecisionType,
            CompressionJob,
            CompressionMethod
        )
        
        # åˆ›å»ºé‡åŒ–é…ç½®
        config = QuantizationConfig(
            method=QuantizationMethod.PTQ,
            precision=PrecisionType.INT8,
            calibration_dataset_size=100
        )
        print(f"  âœ… é‡åŒ–é…ç½®åˆ›å»ºæˆåŠŸ: {config.method}, {config.precision}")
        
        # åˆ›å»ºå‹ç¼©ä»»åŠ¡
        job = CompressionJob(
            job_name="test_job",
            model_path="test.pth",
            compression_method=CompressionMethod.QUANTIZATION,
            quantization_config=config
        )
        print(f"  âœ… å‹ç¼©ä»»åŠ¡åˆ›å»ºæˆåŠŸ: {job.job_name}")
        
        # æµ‹è¯•é…ç½®è½¬æ¢
        config_dict = config.to_dict()
        print(f"  âœ… é…ç½®å­—å…¸è½¬æ¢æˆåŠŸ: {len(config_dict)} ä¸ªå­—æ®µ")
        
        return True
        
    except Exception as e:
        print(f"  âŒ æ•°æ®æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return False


# æµ‹è¯•é‡åŒ–å¼•æ“
def test_quantization_engine():
    print("\nâš™ï¸ æµ‹è¯•é‡åŒ–å¼•æ“...")
    
    try:
        from src.ai.model_compression.quantization_engine import QuantizationEngine
        from src.ai.model_compression.models import QuantizationConfig, QuantizationMethod, PrecisionType
        
        # åˆ›å»ºå¼•æ“
        engine = QuantizationEngine()
        print(f"  âœ… é‡åŒ–å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
        print(f"     æ”¯æŒçš„æ–¹æ³•: {list(engine.supported_methods.keys())}")
        
        # åˆ›å»ºç®€å•æ¨¡å‹
        class TestModel(nn.Module):
            def __init__(self):
                super().__init__()
                self.linear1 = nn.Linear(10, 5)
                self.relu = nn.ReLU()
                self.linear2 = nn.Linear(5, 2)
            
            def forward(self, x):
                return self.linear2(self.relu(self.linear1(x)))
        
        model = TestModel()
        
        # æµ‹è¯•æ¨¡å‹å¤§å°è®¡ç®—
        model_size = engine._get_model_size(model)
        param_count = engine._count_parameters(model)
        print(f"  âœ… æ¨¡å‹å¤§å°: {model_size} bytes")
        print(f"  âœ… å‚æ•°æ•°é‡: {param_count}")
        
        # é…ç½®éªŒè¯
        config = QuantizationConfig(
            method=QuantizationMethod.PTQ,
            precision=PrecisionType.INT8
        )
        
        is_valid = engine.validate_config(config)
        print(f"  âœ… é…ç½®éªŒè¯: {is_valid}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ é‡åŒ–å¼•æ“æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å¿«é€ŸéªŒè¯...\n")
    
    tests = [
        test_basic_quantization,
        test_data_models, 
        test_quantization_engine
    ]
    
    results = []
    for test in tests:
        results.append(test())
    
    # æ€»ç»“
    passed = sum(results)
    total = len(results)
    
    print(f"\nğŸ“Š éªŒè¯ç»“æœ:")
    print(f"   é€šè¿‡: {passed}/{total}")
    print(f"   æˆåŠŸç‡: {passed/total*100:.1f}%")
    
    if passed == total:
        print("ğŸ‰ æ ¸å¿ƒåŠŸèƒ½éªŒè¯é€šè¿‡ï¼")
        return 0
    else:
        print("âš ï¸  éƒ¨åˆ†åŠŸèƒ½éœ€è¦ä¿®å¤ã€‚")
        return 1


if __name__ == "__main__":
    exit(main())