"""
æ¨¡å‹æ³¨å†Œè¡¨ä½¿ç”¨ç¤ºä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨ModelRegistryç®¡ç†ä¸åŒç±»å‹çš„AIæ¨¡å‹
"""

import os
import tempfile
import logging
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

from model_registry import (
    ModelRegistry, ModelFormat, ModelType, CompressionType,
    register_pytorch_model, register_onnx_model, register_huggingface_model
)


def example_pytorch_model_registration():
    """PyTorchæ¨¡å‹æ³¨å†Œç¤ºä¾‹"""
    print("\n=== PyTorchæ¨¡å‹æ³¨å†Œç¤ºä¾‹ ===")
    
    try:
        import torch
        import torch.nn as nn
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„PyTorchæ¨¡å‹
        class SimpleClassifier(nn.Module):
            def __init__(self, input_size=784, hidden_size=128, num_classes=10):
                super().__init__()
                self.flatten = nn.Flatten()
                self.linear_relu_stack = nn.Sequential(
                    nn.Linear(input_size, hidden_size),
                    nn.ReLU(),
                    nn.Linear(hidden_size, hidden_size),
                    nn.ReLU(),
                    nn.Linear(hidden_size, num_classes)
                )
            
            def forward(self, x):
                x = self.flatten(x)
                logits = self.linear_relu_stack(x)
                return logits
        
        # åˆ›å»ºæ¨¡å‹å®ä¾‹
        model = SimpleClassifier()
        
        # åˆ›å»ºä¸´æ—¶æ³¨å†Œè¡¨
        with tempfile.TemporaryDirectory() as temp_dir:
            registry = ModelRegistry(temp_dir)
            
            # æ³¨å†Œæ¨¡å‹
            entry = registry.register_model(
                name="simple_classifier",
                model=model,
                model_format=ModelFormat.PYTORCH,
                model_type=ModelType.CLASSIFICATION,
                version="1.0.0",
                description="ç®€å•çš„MNISTåˆ†ç±»å™¨",
                author="ç¤ºä¾‹ä½œè€…",
                training_dataset="MNIST",
                training_epochs=10,
                performance_metrics={"accuracy": 0.95, "loss": 0.05},
                tags=["mnist", "classification", "simple"],
                input_shape=[1, 28, 28],
                output_shape=[10]
            )
            
            print(f"âœ… æˆåŠŸæ³¨å†ŒPyTorchæ¨¡å‹: {entry.metadata.name}:{entry.metadata.version}")
            print(f"   å‚æ•°æ•°é‡: {entry.metadata.parameters_count:,}")
            print(f"   æ¨¡å‹å¤§å°: {entry.metadata.model_size_mb:.2f} MB")
            
            # åŠ è½½æ¨¡å‹
            loaded_model, _ = registry.load_model("simple_classifier", "1.0.0")
            print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {type(loaded_model).__name__}")
            
            # æµ‹è¯•æ¨ç†
            test_input = torch.randn(1, 1, 28, 28)
            with torch.no_grad():
                output = loaded_model(test_input)
                print(f"   æµ‹è¯•è¾“å‡ºå½¢çŠ¶: {output.shape}")
    
    except ImportError:
        print("âŒ PyTorchæœªå®‰è£…ï¼Œè·³è¿‡PyTorchç¤ºä¾‹")
    except Exception as e:
        print(f"âŒ PyTorchç¤ºä¾‹å¤±è´¥: {e}")


def example_onnx_model_registration():
    """ONNXæ¨¡å‹æ³¨å†Œç¤ºä¾‹"""
    print("\n=== ONNXæ¨¡å‹æ³¨å†Œç¤ºä¾‹ ===")
    
    try:
        import torch
        import torch.nn as nn
        import onnx
        import tempfile
        
        # åˆ›å»ºPyTorchæ¨¡å‹
        class SimpleNet(nn.Module):
            def __init__(self):
                super().__init__()
                self.fc = nn.Linear(10, 5)
            
            def forward(self, x):
                return self.fc(x)
        
        model = SimpleNet()
        
        # å¯¼å‡ºä¸ºONNX
        dummy_input = torch.randn(1, 10)
        
        with tempfile.NamedTemporaryFile(suffix='.onnx', delete=False) as f:
            onnx_path = f.name
        
        try:
            torch.onnx.export(
                model, dummy_input, onnx_path,
                export_params=True,
                opset_version=11,
                do_constant_folding=True,
                input_names=['input'],
                output_names=['output']
            )
            
            # åŠ è½½ONNXæ¨¡å‹
            onnx_model = onnx.load(onnx_path)
            
            # åˆ›å»ºä¸´æ—¶æ³¨å†Œè¡¨
            with tempfile.TemporaryDirectory() as temp_dir:
                registry = ModelRegistry(temp_dir)
                
                # æ³¨å†ŒONNXæ¨¡å‹
                entry = registry.register_model(
                    name="simple_onnx_net",
                    model=onnx_model,
                    model_format=ModelFormat.ONNX,
                    model_type=ModelType.CUSTOM,
                    version="1.0.0",
                    description="è½¬æ¢åçš„ONNXæ¨¡å‹",
                    author="ç¤ºä¾‹ä½œè€…",
                    training_framework="PyTorch -> ONNX",
                    tags=["onnx", "converted"],
                    input_shape=[1, 10],
                    output_shape=[1, 5]
                )
                
                print(f"âœ… æˆåŠŸæ³¨å†ŒONNXæ¨¡å‹: {entry.metadata.name}:{entry.metadata.version}")
                print(f"   IRç‰ˆæœ¬: {onnx_model.ir_version}")
                print(f"   Producer: {onnx_model.producer_name}")
                print(f"   æ¨¡å‹å¤§å°: {entry.metadata.model_size_mb:.2f} MB")
                
                # åŠ è½½æ¨¡å‹
                loaded_onnx_model, _ = registry.load_model("simple_onnx_net")
                print(f"âœ… æˆåŠŸåŠ è½½ONNXæ¨¡å‹")
                
        finally:
            if os.path.exists(onnx_path):
                os.unlink(onnx_path)
    
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–ï¼Œè·³è¿‡ONNXç¤ºä¾‹: {e}")
    except Exception as e:
        print(f"âŒ ONNXç¤ºä¾‹å¤±è´¥: {e}")


def example_huggingface_model_registration():
    """HuggingFaceæ¨¡å‹æ³¨å†Œç¤ºä¾‹"""
    print("\n=== HuggingFaceæ¨¡å‹æ³¨å†Œç¤ºä¾‹ ===")
    
    try:
        from transformers import AutoModel, AutoTokenizer, AutoConfig
        
        # ä½¿ç”¨å°å‹æ¨¡å‹è¿›è¡Œæ¼”ç¤º
        model_name = "distilbert-base-uncased"
        
        print(f"æ­£åœ¨åŠ è½½HuggingFaceæ¨¡å‹: {model_name}...")
        
        # åŠ è½½æ¨¡å‹å’Œtokenizer
        model = AutoModel.from_pretrained(model_name)
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        config = AutoConfig.from_pretrained(model_name)
        
        # åˆ›å»ºä¸´æ—¶æ³¨å†Œè¡¨
        with tempfile.TemporaryDirectory() as temp_dir:
            registry = ModelRegistry(temp_dir)
            
            # æ³¨å†ŒHuggingFaceæ¨¡å‹
            entry = registry.register_model(
                name="distilbert_demo",
                model=model,
                tokenizer=tokenizer,
                model_format=ModelFormat.HUGGINGFACE,
                model_type=ModelType.LANGUAGE_MODEL,
                version="1.0.0",
                description="DistilBERTæ¼”ç¤ºæ¨¡å‹",
                author="Hugging Face",
                training_dataset="English Wikipedia and BookCorpus",
                tags=["bert", "distilbert", "nlp", "transformer"],
                repository_url=f"https://huggingface.co/{model_name}",
                license="Apache-2.0"
            )
            
            print(f"âœ… æˆåŠŸæ³¨å†ŒHuggingFaceæ¨¡å‹: {entry.metadata.name}:{entry.metadata.version}")
            print(f"   å‚æ•°æ•°é‡: {entry.metadata.parameters_count:,}")
            print(f"   æ¨¡å‹å¤§å°: {entry.metadata.model_size_mb:.2f} MB")
            print(f"   é…ç½®ç±»å‹: {config.model_type}")
            
            # åŠ è½½æ¨¡å‹
            loaded_model, loaded_tokenizer = registry.load_model("distilbert_demo")
            print(f"âœ… æˆåŠŸåŠ è½½HuggingFaceæ¨¡å‹å’Œtokenizer")
            
            # æµ‹è¯•tokenizer
            test_text = "Hello, this is a test sentence."
            tokens = loaded_tokenizer.encode(test_text, return_tensors="pt")
            print(f"   æµ‹è¯•æ–‡æœ¬: '{test_text}'")
            print(f"   Tokenæ•°é‡: {tokens.shape[1]}")
            
            # æµ‹è¯•æ¨¡å‹æ¨ç†
            with torch.no_grad():
                outputs = loaded_model(tokens)
                hidden_states = outputs.last_hidden_state
                print(f"   è¾“å‡ºå½¢çŠ¶: {hidden_states.shape}")
    
    except ImportError:
        print("âŒ Transformersæœªå®‰è£…ï¼Œè·³è¿‡HuggingFaceç¤ºä¾‹")
    except Exception as e:
        print(f"âŒ HuggingFaceç¤ºä¾‹å¤±è´¥: {e}")


def example_model_management_operations():
    """æ¨¡å‹ç®¡ç†æ“ä½œç¤ºä¾‹"""
    print("\n=== æ¨¡å‹ç®¡ç†æ“ä½œç¤ºä¾‹ ===")
    
    with tempfile.TemporaryDirectory() as temp_dir:
        registry = ModelRegistry(temp_dir)
        
        # åˆ›å»ºä¸€äº›ç¤ºä¾‹æ¨¡å‹
        dummy_models = [
            {
                "name": "model_a",
                "model": {"type": "dummy", "params": 1000},
                "format": ModelFormat.PYTORCH,
                "model_type": ModelType.CLASSIFICATION,
                "description": "åˆ†ç±»æ¨¡å‹A"
            },
            {
                "name": "model_b", 
                "model": {"type": "dummy", "params": 2000},
                "format": ModelFormat.ONNX,
                "model_type": ModelType.GENERATION,
                "description": "ç”Ÿæˆæ¨¡å‹B"
            },
            {
                "name": "model_c",
                "model": {"type": "dummy", "params": 500},
                "format": ModelFormat.PYTORCH,
                "model_type": ModelType.EMBEDDING,
                "description": "åµŒå…¥æ¨¡å‹C"
            }
        ]
        
        # æ³¨å†Œæ¨¡å‹ï¼ˆä½¿ç”¨mock loaderï¼‰
        from unittest.mock import Mock
        mock_loader = Mock()
        mock_loader.save = Mock()
        mock_loader.get_metadata.return_value = {"total_parameters": 1000, "model_size_mb": 10.0}
        
        for format_type in [ModelFormat.PYTORCH, ModelFormat.ONNX]:
            registry.loaders[format_type] = mock_loader
        
        for model_info in dummy_models:
            try:
                entry = registry.register_model(**model_info)
                print(f"âœ… æ³¨å†Œæ¨¡å‹: {entry.metadata.name}")
            except Exception as e:
                print(f"âŒ æ³¨å†Œå¤±è´¥: {e}")
        
        print(f"\nğŸ“Š å½“å‰æ³¨å†Œæ¨¡å‹æ•°é‡: {len(registry.models)}")
        
        # åˆ—å‡ºæ‰€æœ‰æ¨¡å‹
        print("\nğŸ“‹ æ‰€æœ‰æ¨¡å‹:")
        all_models = registry.list_models()
        for model in all_models:
            print(f"   - {model.metadata.name}:{model.metadata.version} "
                  f"({model.metadata.format.value}, {model.metadata.model_type.value})")
        
        # æŒ‰ç±»å‹ç­›é€‰
        print("\nğŸ” åˆ†ç±»æ¨¡å‹:")
        classification_models = registry.list_models(ModelType.CLASSIFICATION)
        for model in classification_models:
            print(f"   - {model.metadata.name}: {model.metadata.description}")
        
        # è·å–æ¨¡å‹ä¿¡æ¯
        print("\nğŸ“„ æ¨¡å‹è¯¦ç»†ä¿¡æ¯:")
        model_info = registry.get_model_info("model_a", "latest")
        if model_info:
            print(f"   æ¨¡å‹: {model_info.metadata.name}")
            print(f"   ç‰ˆæœ¬: {model_info.metadata.version}")
            print(f"   ç±»å‹: {model_info.metadata.model_type.value}")
            print(f"   æ ¼å¼: {model_info.metadata.format.value}")
            print(f"   æè¿°: {model_info.metadata.description}")
        
        # éªŒè¯æ³¨å†Œè¡¨
        print("\nğŸ” éªŒè¯æ³¨å†Œè¡¨:")
        validation = registry.validate_registry()
        print(f"   æ€»æ¨¡å‹æ•°: {validation['total_models']}")
        print(f"   æœ‰æ•ˆæ¨¡å‹æ•°: {validation['valid_models']}")
        print(f"   é”™è¯¯æ•°: {len(validation['errors'])}")
        print(f"   è­¦å‘Šæ•°: {len(validation['warnings'])}")
        
        if validation['errors']:
            print("   é”™è¯¯:")
            for error in validation['errors']:
                print(f"     - {error}")
        
        if validation['warnings']:
            print("   è­¦å‘Š:")
            for warning in validation['warnings']:
                print(f"     - {warning}")


def example_model_versioning():
    """æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶ç¤ºä¾‹"""
    print("\n=== æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶ç¤ºä¾‹ ===")
    
    with tempfile.TemporaryDirectory() as temp_dir:
        registry = ModelRegistry(temp_dir)
        
        # Mock loader
        mock_loader = Mock()
        mock_loader.save = Mock()
        mock_loader.get_metadata.return_value = {"total_parameters": 1000, "model_size_mb": 10.0}
        registry.loaders[ModelFormat.PYTORCH] = mock_loader
        
        model_name = "evolving_model"
        
        # æ³¨å†Œå¤šä¸ªç‰ˆæœ¬
        versions = [
            {"version": "1.0.0", "accuracy": 0.80, "description": "åˆå§‹ç‰ˆæœ¬"},
            {"version": "1.1.0", "accuracy": 0.85, "description": "æ”¹è¿›çš„è®­ç»ƒæµç¨‹"},
            {"version": "2.0.0", "accuracy": 0.90, "description": "å…¨æ–°æ¶æ„"},
            {"version": "2.1.0", "accuracy": 0.92, "description": "å¾®è°ƒä¼˜åŒ–"}
        ]
        
        for version_info in versions:
            registry.register_model(
                name=model_name,
                model={"dummy": True},
                model_format=ModelFormat.PYTORCH,
                version=version_info["version"],
                description=version_info["description"],
                performance_metrics={"accuracy": version_info["accuracy"]}
            )
            print(f"âœ… æ³¨å†Œç‰ˆæœ¬ {version_info['version']}: {version_info['description']}")
        
        # åˆ—å‡ºæ‰€æœ‰ç‰ˆæœ¬
        print(f"\nğŸ“‹ '{model_name}' çš„æ‰€æœ‰ç‰ˆæœ¬:")
        all_models = registry.list_models()
        evolving_models = [m for m in all_models if m.metadata.name == model_name]
        
        # æŒ‰ç‰ˆæœ¬æ’åº
        evolving_models.sort(key=lambda x: x.metadata.version, reverse=True)
        
        for model in evolving_models:
            accuracy = model.metadata.performance_metrics.get("accuracy", "N/A")
            print(f"   - v{model.metadata.version}: {model.metadata.description} "
                  f"(å‡†ç¡®ç‡: {accuracy})")
        
        # è·å–æœ€æ–°ç‰ˆæœ¬
        latest_model = registry.get_model_info(model_name, "latest")
        print(f"\nğŸ”¥ æœ€æ–°ç‰ˆæœ¬: v{latest_model.metadata.version}")
        
        # åˆ é™¤æ—§ç‰ˆæœ¬
        print(f"\nğŸ—‘ï¸  åˆ é™¤æ—§ç‰ˆæœ¬ v1.0.0")
        registry.remove_model(model_name, "1.0.0")
        
        # ç¡®è®¤åˆ é™¤
        remaining_models = [m for m in registry.list_models() if m.metadata.name == model_name]
        print(f"   å‰©ä½™ç‰ˆæœ¬æ•°: {len(remaining_models)}")


def example_convenience_functions():
    """ä¾¿æ·å‡½æ•°ä½¿ç”¨ç¤ºä¾‹"""
    print("\n=== ä¾¿æ·å‡½æ•°ä½¿ç”¨ç¤ºä¾‹ ===")
    
    try:
        import torch
        import torch.nn as nn
        
        # åˆ›å»ºç®€å•æ¨¡å‹
        model = nn.Linear(10, 1)
        
        # ä½¿ç”¨ä¾¿æ·å‡½æ•°æ³¨å†ŒPyTorchæ¨¡å‹
        with tempfile.TemporaryDirectory() as temp_dir:
            # ä¸´æ—¶è®¾ç½®å…¨å±€æ³¨å†Œè¡¨è·¯å¾„
            import model_registry
            original_registry = model_registry.model_registry
            temp_registry = ModelRegistry(temp_dir)
            model_registry.model_registry = temp_registry
            
            try:
                entry = register_pytorch_model(
                    name="linear_model",
                    model=model,
                    version="1.0.0",
                    description="çº¿æ€§å›å½’æ¨¡å‹",
                    model_type=ModelType.CUSTOM,
                    tags=["linear", "regression"]
                )
                
                print(f"âœ… ä½¿ç”¨ä¾¿æ·å‡½æ•°æ³¨å†Œæ¨¡å‹: {entry.metadata.name}")
                print(f"   å‚æ•°æ•°é‡: {entry.metadata.parameters_count:,}")
                
            finally:
                # æ¢å¤åŸå§‹æ³¨å†Œè¡¨
                model_registry.model_registry = original_registry
    
    except ImportError:
        print("âŒ PyTorchæœªå®‰è£…ï¼Œè·³è¿‡ä¾¿æ·å‡½æ•°ç¤ºä¾‹")
    except Exception as e:
        print(f"âŒ ä¾¿æ·å‡½æ•°ç¤ºä¾‹å¤±è´¥: {e}")


def example_error_handling():
    """é”™è¯¯å¤„ç†ç¤ºä¾‹"""
    print("\n=== é”™è¯¯å¤„ç†ç¤ºä¾‹ ===")
    
    with tempfile.TemporaryDirectory() as temp_dir:
        registry = ModelRegistry(temp_dir)
        
        # å°è¯•åŠ è½½ä¸å­˜åœ¨çš„æ¨¡å‹
        try:
            registry.load_model("non_existent_model")
        except ValueError as e:
            print(f"âœ… æ­£ç¡®æ•è·é”™è¯¯: {e}")
        
        # å°è¯•æ³¨å†Œé‡å¤æ¨¡å‹
        mock_loader = Mock()
        mock_loader.save = Mock()
        mock_loader.get_metadata.return_value = {}
        registry.loaders[ModelFormat.PYTORCH] = mock_loader
        
        try:
            # ç¬¬ä¸€æ¬¡æ³¨å†Œ
            registry.register_model(
                name="duplicate_test",
                model={"dummy": True},
                model_format=ModelFormat.PYTORCH
            )
            
            # ç¬¬äºŒæ¬¡æ³¨å†Œï¼ˆåº”è¯¥å¤±è´¥ï¼‰
            registry.register_model(
                name="duplicate_test",
                model={"dummy": True},
                model_format=ModelFormat.PYTORCH
            )
        except ValueError as e:
            print(f"âœ… æ­£ç¡®æ•è·é‡å¤æ³¨å†Œé”™è¯¯: {e}")
        
        # å°è¯•ä½¿ç”¨ä¸æ”¯æŒçš„æ ¼å¼
        try:
            registry.register_model(
                name="unsupported_test",
                model={"dummy": True},
                model_format=ModelFormat.SAFETENSORS  # å‡è®¾æ²¡æœ‰loader
            )
        except ValueError as e:
            print(f"âœ… æ­£ç¡®æ•è·ä¸æ”¯æŒæ ¼å¼é”™è¯¯: {e}")


def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("ğŸš€ æ¨¡å‹æ³¨å†Œè¡¨ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    try:
        example_pytorch_model_registration()
        example_onnx_model_registration()
        example_huggingface_model_registration()
        example_model_management_operations()
        example_model_versioning()
        example_convenience_functions()
        example_error_handling()
        
        print("\nâœ… æ‰€æœ‰ç¤ºä¾‹å®Œæˆ!")
        
    except Exception as e:
        print(f"\nâŒ è¿è¡Œç¤ºä¾‹æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()