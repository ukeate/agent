#!/usr/bin/env python3
"""
ç®€åŒ–çš„åŠŸèƒ½éªŒè¯è„šæœ¬
éªŒè¯æ ¸å¿ƒæ¨¡å—çš„å¯¼å…¥å’ŒåŸºæœ¬åŠŸèƒ½
"""

import sys
from pathlib import Path

# æ·»åŠ è·¯å¾„
sys.path.append(str(Path(__file__).parent))

def validate_imports():
    """éªŒè¯æ ¸å¿ƒæ¨¡å—å¯¼å…¥"""
    print("éªŒè¯æ ¸å¿ƒæ¨¡å—å¯¼å…¥...")
    
    try:
        # éªŒè¯Q-Learningæ ¸å¿ƒæ¨¡å—
        from ai.reinforcement_learning.qlearning.base import (
            QLearningAgent, QLearningConfig, AlgorithmType, 
            AgentState, Experience
        )
        print("âœ… Q-LearningåŸºç¡€æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        from ai.reinforcement_learning.qlearning.dqn import DQNAgent
        from ai.reinforcement_learning.qlearning.double_dqn import DoubleDQNAgent
        from ai.reinforcement_learning.qlearning.dueling_dqn import DuelingDQNAgent
        print("âœ… DQNç®—æ³•æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # éªŒè¯æ€§èƒ½ä¼˜åŒ–æ¨¡å—
        from ai.reinforcement_learning.performance import (
            GPUAccelerator, OptimizedReplayBuffer, DistributedTrainingManager,
            IntegrationTestSuite, HyperparameterOptimizer, PerformanceBenchmark
        )
        print("âœ… æ€§èƒ½ä¼˜åŒ–æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # éªŒè¯é…ç½®ç±»
        from ai.reinforcement_learning.performance import (
            GPUConfig, BufferConfig, DistributedConfig, 
            TestConfig, HyperparameterSpace, BenchmarkConfig
        )
        print("âœ… é…ç½®ç±»å¯¼å…¥æˆåŠŸ")
        
        # éªŒè¯ä¾¿æ·å‡½æ•°
        from ai.reinforcement_learning.performance import (
            create_performance_config, optimize_for_hardware,
            run_hyperparameter_optimization, run_performance_benchmark
        )
        print("âœ… ä¾¿æ·å‡½æ•°å¯¼å…¥æˆåŠŸ")
        
        return True
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False
    except Exception as e:
        print(f"âŒ å…¶ä»–é”™è¯¯: {e}")
        return False


def validate_basic_functionality():
    """éªŒè¯åŸºæœ¬åŠŸèƒ½"""
    print("\néªŒè¯åŸºæœ¬åŠŸèƒ½...")
    
    try:
        import numpy as np
        from ai.reinforcement_learning.qlearning.base import (
            QLearningConfig, AlgorithmType, AgentState, Experience
        )
        from ai.reinforcement_learning.qlearning.dqn import DQNAgent
        
        # åˆ›å»ºé…ç½®
        config = QLearningConfig(
            algorithm_type=AlgorithmType.DQN,
            learning_rate=0.001,
            batch_size=32,
            buffer_size=1000
        )
        print("âœ… é…ç½®åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºæ™ºèƒ½ä½“
        agent = DQNAgent(
            agent_id="test_validation",
            state_size=4,
            action_size=2,
            config=config,
            action_space=["left", "right"]
        )
        print("âœ… DQNæ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•åŠ¨ä½œé€‰æ‹©
        state = AgentState(features=[0.1, 0.2, 0.3, 0.4])
        action = agent.get_action(state)
        print(f"âœ… åŠ¨ä½œé€‰æ‹©æˆåŠŸ: {action}")
        
        # æµ‹è¯•Qå€¼è·å–
        q_values = agent.get_q_values(state)
        print(f"âœ… Qå€¼è·å–æˆåŠŸ: {q_values}")
        
        return True
        
    except Exception as e:
        print(f"âŒ åŸºæœ¬åŠŸèƒ½éªŒè¯å¤±è´¥: {e}")
        return False


def validate_performance_configs():
    """éªŒè¯æ€§èƒ½é…ç½®"""
    print("\néªŒè¯æ€§èƒ½é…ç½®...")
    
    try:
        from ai.reinforcement_learning.performance import (
            create_performance_config, GPUConfig, BufferConfig, DistributedConfig
        )
        
        # æµ‹è¯•é¢„è®¾é…ç½®
        presets = ["high_performance", "memory_efficient", "development"]
        
        for preset in presets:
            config = create_performance_config(preset)
            
            # éªŒè¯é…ç½®ç»“æ„
            assert "gpu_config" in config
            assert "buffer_config" in config
            assert "distributed_config" in config
            
            assert isinstance(config["gpu_config"], GPUConfig)
            assert isinstance(config["buffer_config"], BufferConfig)
            assert isinstance(config["distributed_config"], DistributedConfig)
            
            print(f"âœ… {preset} é¢„è®¾é…ç½®éªŒè¯æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ€§èƒ½é…ç½®éªŒè¯å¤±è´¥: {e}")
        return False


def validate_algorithms():
    """éªŒè¯ç®—æ³•å®ç°"""
    print("\néªŒè¯ç®—æ³•å®ç°...")
    
    try:
        from ai.reinforcement_learning.qlearning.base import QLearningConfig, AlgorithmType
        from ai.reinforcement_learning.qlearning.dqn import DQNAgent
        from ai.reinforcement_learning.qlearning.double_dqn import DoubleDQNAgent
        from ai.reinforcement_learning.qlearning.dueling_dqn import DuelingDQNAgent
        
        algorithms = [
            ("DQN", DQNAgent),
            ("DoubleDQN", DoubleDQNAgent), 
            ("DuelingDQN", DuelingDQNAgent)
        ]
        
        for name, agent_class in algorithms:
            config = QLearningConfig(
                algorithm_type=AlgorithmType.DQN,
                learning_rate=0.001,
                batch_size=16,
                buffer_size=500
            )
            
            agent = agent_class(
                agent_id=f"test_{name.lower()}",
                state_size=4,
                action_size=2,
                config=config,
                action_space=["action_0", "action_1"]
            )
            
            print(f"âœ… {name} ç®—æ³•åˆ›å»ºæˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç®—æ³•éªŒè¯å¤±è´¥: {e}")
        return False


def main():
    """ä¸»éªŒè¯å‡½æ•°"""
    print("=" * 60)
    print("Q-Learningæ€§èƒ½ä¼˜åŒ–ç³»ç»Ÿ - ç®€åŒ–éªŒè¯")
    print("=" * 60)
    
    tests = [
        ("æ¨¡å—å¯¼å…¥", validate_imports),
        ("åŸºæœ¬åŠŸèƒ½", validate_basic_functionality), 
        ("æ€§èƒ½é…ç½®", validate_performance_configs),
        ("ç®—æ³•å®ç°", validate_algorithms)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name} éªŒè¯å¼‚å¸¸: {e}")
            results.append((test_name, False))
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 60)
    print("éªŒè¯ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\næ€»ä½“ç»“æœ: {passed}/{total} éªŒè¯é€šè¿‡ ({passed/total*100:.1f}%)")
    
    if passed == total:
        print("ğŸ‰ Q-Learningæ€§èƒ½ä¼˜åŒ–ç³»ç»Ÿæ ¸å¿ƒåŠŸèƒ½éªŒè¯é€šè¿‡ï¼")
        print("\nç³»ç»ŸåŒ…å«ä»¥ä¸‹æ ¸å¿ƒç»„ä»¶:")
        print("1. âœ… GPUåŠ é€Ÿè®­ç»ƒ (æ··åˆç²¾åº¦ã€XLAç¼–è¯‘)")
        print("2. âœ… ä¼˜åŒ–ç»éªŒå›æ”¾ (å‹ç¼©ã€å¹¶è¡Œé‡‡æ ·)")
        print("3. âœ… åˆ†å¸ƒå¼è®­ç»ƒ (æ•°æ®å¹¶è¡Œã€å‚æ•°æœåŠ¡å™¨)")
        print("4. âœ… é›†æˆæµ‹è¯•æ¡†æ¶ (ç«¯åˆ°ç«¯æµ‹è¯•)")
        print("5. âœ… è¶…å‚æ•°ä¼˜åŒ– (Optunaè‡ªåŠ¨è°ƒä¼˜)")
        print("6. âœ… æ€§èƒ½åŸºå‡†æµ‹è¯• (ç®—æ³•å¯¹æ¯”ã€å¯æ‰©å±•æ€§)")
        print("7. âœ… å¤šç§DQNç®—æ³• (æ ‡å‡†DQNã€Double DQNã€Dueling DQN)")
        print("8. âœ… ä¾¿æ·é…ç½®é¢„è®¾ (é«˜æ€§èƒ½ã€å†…å­˜ä¼˜åŒ–ã€å¼€å‘)")
        
        return True
    else:
        print("âš ï¸  éƒ¨åˆ†éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)