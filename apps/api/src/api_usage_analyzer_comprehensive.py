import os
import re
import json
import ast
from pathlib import Path
from typing import Dict, List, Set, Tuple, Any
from collections import defaultdict
import asyncio
from src.core.logging import setup_logging

from src.core.logging import get_logger
logger = get_logger(__name__)

#!/usr/bin/env python3
"""
å…¨é¢APIä½¿ç”¨æƒ…å†µåˆ†æå·¥å…·
åˆ†æåç«¯APIç«¯ç‚¹ä¸å‰ç«¯ä½¿ç”¨æƒ…å†µçš„å¯¹åº”å…³ç³»
"""

class APIUsageAnalyzer:
    def __init__(self):
        self.api_endpoints = {}  # APIæ¨¡å— -> ç«¯ç‚¹åˆ—è¡¨
        self.frontend_services = {}  # æœåŠ¡æ–‡ä»¶ -> APIè°ƒç”¨
        self.frontend_pages = {}  # é¡µé¢æ–‡ä»¶ -> æœåŠ¡ä½¿ç”¨
        self.usage_mapping = defaultdict(list)  # APIç«¯ç‚¹ -> ä½¿ç”¨ä½ç½®
        
    def extract_fastapi_routes(self, file_path: str) -> List[Dict]:
        """ä»FastAPIæ–‡ä»¶ä¸­æå–è·¯ç”±ä¿¡æ¯"""
        routes = []
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾è·¯ç”±å®šä¹‰æ¨¡å¼
            route_patterns = [
                r'@router\.(?P<method>get|post|put|delete|patch)\([\'"](?P<path>[^\'"]+)[\'"]',
                r'@app\.(?P<method>get|post|put|delete|patch)\([\'"](?P<path>[^\'"]+)[\'"]',
                r'router\.(?P<method>add_api_route)\([\'"](?P<path>[^\'"]+)[\'"]'
            ]
            
            # æŸ¥æ‰¾å‡½æ•°å®šä¹‰
            func_pattern = r'(?:async\s+)?def\s+(\w+)\s*\([^)]*\):'
            functions = re.findall(func_pattern, content)
            
            for pattern in route_patterns:
                matches = re.finditer(pattern, content)
                for match in matches:
                    method = match.group('method')
                    path = match.group('path')
                    
                    # å¯»æ‰¾å¯¹åº”çš„å‡½æ•°å
                    func_name = None
                    start_pos = match.end()
                    next_func = re.search(func_pattern, content[start_pos:])
                    if next_func:
                        func_name = next_func.group(1)
                    
                    routes.append({
                        'method': method.upper(),
                        'path': path,
                        'function': func_name,
                        'file': os.path.basename(file_path)
                    })
                    
        except Exception as e:
            logger.error(f"åˆ†æAPIæ–‡ä»¶é”™è¯¯ {file_path}: {e}")
            
        return routes
    
    def extract_frontend_api_calls(self, file_path: str) -> List[Dict]:
        """ä»å‰ç«¯æœåŠ¡æ–‡ä»¶ä¸­æå–APIè°ƒç”¨"""
        api_calls = []
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # åŒ¹é…APIè°ƒç”¨æ¨¡å¼
            patterns = [
                r'(?:get|post|put|delete|patch)\s*\(\s*[\'"`]([^\'"`]+)[\'"`]',
                r'fetch\s*\(\s*[\'"`]([^\'"`]+)[\'"`]',
                r'axios\.(?:get|post|put|delete|patch)\s*\(\s*[\'"`]([^\'"`]+)[\'"`]',
                r'apiClient\.(?:get|post|put|delete|patch)\s*\(\s*[\'"`]([^\'"`]+)[\'"`]',
                r'const\s+\w+\s*=\s*[\'"`]([^\'"`]*(?:/api/|/v1/)[^\'"`]+)[\'"`]'
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, content)
                for match in matches:
                    if '/api/' in match or '/v1/' in match:
                        api_calls.append({
                            'endpoint': match,
                            'file': os.path.basename(file_path)
                        })
                        
        except Exception as e:
            logger.error(f"åˆ†æå‰ç«¯æœåŠ¡æ–‡ä»¶é”™è¯¯ {file_path}: {e}")
            
        return api_calls
    
    def extract_service_usage(self, file_path: str) -> List[Dict]:
        """ä»å‰ç«¯é¡µé¢æ–‡ä»¶ä¸­æå–æœåŠ¡ä½¿ç”¨"""
        service_usage = []
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # åŒ¹é…æœåŠ¡å¯¼å…¥å’Œä½¿ç”¨æ¨¡å¼
            import_pattern = r'import\s+(?:\{[^}]+\}|\w+)\s+from\s+[\'"`]\.\.?/services/(\w+)[\'"`]'
            usage_pattern = r'(\w+Service)\.(\w+)\s*\('
            
            # æŸ¥æ‰¾æœåŠ¡å¯¼å…¥
            imports = re.findall(import_pattern, content)
            for service_import in imports:
                service_usage.append({
                    'service': service_import,
                    'type': 'import',
                    'file': os.path.basename(file_path)
                })
            
            # æŸ¥æ‰¾æœåŠ¡ä½¿ç”¨
            usages = re.findall(usage_pattern, content)
            for service_name, method in usages:
                service_usage.append({
                    'service': service_name,
                    'method': method,
                    'type': 'usage',
                    'file': os.path.basename(file_path)
                })
                
        except Exception as e:
            logger.error(f"åˆ†æå‰ç«¯é¡µé¢æ–‡ä»¶é”™è¯¯ {file_path}: {e}")
            
        return service_usage
    
    def normalize_endpoint(self, endpoint: str) -> str:
        """æ ‡å‡†åŒ–ç«¯ç‚¹è·¯å¾„"""
        # ç§»é™¤æŸ¥è¯¢å‚æ•°
        endpoint = endpoint.split('?')[0]
        # ç§»é™¤åŸºç¡€URL
        endpoint = re.sub(r'^https?://[^/]+', '', endpoint)
        # ç¡®ä¿ä»¥/å¼€å¤´
        if not endpoint.startswith('/'):
            endpoint = '/' + endpoint
        return endpoint
    
    def match_endpoints(self) -> Dict[str, Dict]:
        """åŒ¹é…APIç«¯ç‚¹ä¸å‰ç«¯ä½¿ç”¨"""
        matching_results = {}
        
        for api_module, endpoints in self.api_endpoints.items():
            for endpoint_info in endpoints:
                endpoint_key = f"{endpoint_info['method']} {endpoint_info['path']}"
                matching_results[endpoint_key] = {
                    'api_info': endpoint_info,
                    'frontend_usage': [],
                    'is_used': False
                }
        
        # æ£€æŸ¥å‰ç«¯APIè°ƒç”¨
        for service_file, api_calls in self.frontend_services.items():
            for call in api_calls:
                normalized_call = self.normalize_endpoint(call['endpoint'])
                
                # å°è¯•åŒ¹é…ç«¯ç‚¹
                for endpoint_key, endpoint_data in matching_results.items():
                    api_path = endpoint_data['api_info']['path']
                    
                    # ç®€å•è·¯å¾„åŒ¹é…
                    if api_path in normalized_call or normalized_call in api_path:
                        endpoint_data['frontend_usage'].append({
                            'service': service_file,
                            'call': call['endpoint']
                        })
                        endpoint_data['is_used'] = True
        
        return matching_results
    
    def analyze_directories(self):
        """åˆ†ææ‰€æœ‰ç›¸å…³ç›®å½•"""
        logger.info("å¼€å§‹åˆ†æAPIå’Œå‰ç«¯æ–‡ä»¶...")
        
        # åˆ†æåç«¯APIæ–‡ä»¶
        api_dir = Path("./api/v1")
        if api_dir.exists():
            for api_file in api_dir.glob("*.py"):
                if api_file.name != "__init__.py":
                    routes = self.extract_fastapi_routes(str(api_file))
                    if routes:
                        self.api_endpoints[api_file.name] = routes
                        logger.info(f"âœ“ åˆ†æAPIæ–‡ä»¶: {api_file.name} (å‘ç° {len(routes)} ä¸ªç«¯ç‚¹)")
        
        # åˆ†æå‰ç«¯æœåŠ¡æ–‡ä»¶
        services_dir = Path("/Users/runout/awork/code/my_git/agent/apps/web/src/services")
        if services_dir.exists():
            for service_file in services_dir.glob("*.ts"):
                api_calls = self.extract_frontend_api_calls(str(service_file))
                if api_calls:
                    self.frontend_services[service_file.name] = api_calls
                    logger.info(f"âœ“ åˆ†ææœåŠ¡æ–‡ä»¶: {service_file.name} (å‘ç° {len(api_calls)} ä¸ªAPIè°ƒç”¨)")
        
        # åˆ†æå‰ç«¯é¡µé¢æ–‡ä»¶
        pages_dir = Path("/Users/runout/awork/code/my_git/agent/apps/web/src/pages")
        if pages_dir.exists():
            for page_file in pages_dir.glob("*.tsx"):
                service_usage = self.extract_service_usage(str(page_file))
                if service_usage:
                    self.frontend_pages[page_file.name] = service_usage
                    logger.info(f"âœ“ åˆ†æé¡µé¢æ–‡ä»¶: {page_file.name} (å‘ç° {len(service_usage)} ä¸ªæœåŠ¡ä½¿ç”¨)")
    
    def generate_detailed_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        matching_results = self.match_endpoints()
        
        # ç»Ÿè®¡æ•°æ®
        total_endpoints = len(matching_results)
        used_endpoints = sum(1 for data in matching_results.values() if data['is_used'])
        unused_endpoints = total_endpoints - used_endpoints
        usage_rate = (used_endpoints / total_endpoints * 100) if total_endpoints > 0 else 0
        
        # æŒ‰æ¨¡å—ç»Ÿè®¡
        module_stats = defaultdict(lambda: {'total': 0, 'used': 0, 'unused': 0})
        for endpoint_key, data in matching_results.items():
            module = data['api_info']['file']
            module_stats[module]['total'] += 1
            if data['is_used']:
                module_stats[module]['used'] += 1
            else:
                module_stats[module]['unused'] += 1
        
        # æœªä½¿ç”¨çš„APIç«¯ç‚¹
        unused_endpoints_list = []
        for endpoint_key, data in matching_results.items():
            if not data['is_used']:
                unused_endpoints_list.append({
                    'endpoint': endpoint_key,
                    'module': data['api_info']['file'],
                    'function': data['api_info']['function']
                })
        
        report = {
            'summary': {
                'total_api_modules': len(self.api_endpoints),
                'total_endpoints': total_endpoints,
                'used_endpoints': used_endpoints,
                'unused_endpoints': unused_endpoints,
                'usage_rate': round(usage_rate, 2),
                'total_frontend_services': len(self.frontend_services),
                'total_frontend_pages': len(self.frontend_pages)
            },
            'module_statistics': dict(module_stats),
            'endpoint_details': matching_results,
            'unused_endpoints': unused_endpoints_list,
            'api_endpoints_by_module': self.api_endpoints,
            'frontend_services': self.frontend_services,
            'frontend_pages_summary': {
                k: len(v) for k, v in self.frontend_pages.items()
            }
        }
        
        return report
    
    def print_report(self, report: Dict[str, Any]):
        """æ‰“å°æŠ¥å‘Šåˆ°æ§åˆ¶å°"""
        logger.info("\n" + "="*80)
        logger.info("APIä½¿ç”¨æƒ…å†µåˆ†ææŠ¥å‘Š")
        logger.info("="*80)
        
        summary = report['summary']
        logger.info(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        logger.info(f"   APIæ¨¡å—æ•°é‡: {summary['total_api_modules']}")
        logger.info(f"   APIç«¯ç‚¹æ€»æ•°: {summary['total_endpoints']}")
        logger.info(f"   å·²ä½¿ç”¨ç«¯ç‚¹: {summary['used_endpoints']}")
        logger.info(f"   æœªä½¿ç”¨ç«¯ç‚¹: {summary['unused_endpoints']}")
        logger.info(f"   ä½¿ç”¨ç‡: {summary['usage_rate']}%")
        logger.info(f"   å‰ç«¯æœåŠ¡æ•°é‡: {summary['total_frontend_services']}")
        logger.info(f"   å‰ç«¯é¡µé¢æ•°é‡: {summary['total_frontend_pages']}")
        
        logger.info(f"\nğŸ“ˆ å„æ¨¡å—ä½¿ç”¨ç‡ç»Ÿè®¡:")
        for module, stats in report['module_statistics'].items():
            rate = (stats['used'] / stats['total'] * 100) if stats['total'] > 0 else 0
            logger.info(f"   {module}: {stats['used']}/{stats['total']} ({rate:.1f}%)")
        
        logger.error(f"\nâŒ æœªä½¿ç”¨çš„APIç«¯ç‚¹ ({len(report['unused_endpoints'])} ä¸ª):")
        for endpoint in report['unused_endpoints'][:20]:  # åªæ˜¾ç¤ºå‰20ä¸ª
            logger.info(f"   {endpoint['endpoint']} - {endpoint['module']}")
        if len(report['unused_endpoints']) > 20:
            logger.info(f"   ... è¿˜æœ‰ {len(report['unused_endpoints']) - 20} ä¸ª")
    
    def save_report(self, report: Dict[str, Any], filename: str = "api_usage_comprehensive_report.json"):
        """ä¿å­˜æŠ¥å‘Šåˆ°JSONæ–‡ä»¶"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        logger.info(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")

async def main():
    analyzer = APIUsageAnalyzer()
    
    # åˆ†ææ‰€æœ‰ç›®å½•
    analyzer.analyze_directories()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = analyzer.generate_detailed_report()
    
    # æ˜¾ç¤ºæŠ¥å‘Š
    analyzer.print_report(report)
    
    # ä¿å­˜æŠ¥å‘Š
    analyzer.save_report(report)

if __name__ == "__main__":
    setup_logging()
    asyncio.run(main())
