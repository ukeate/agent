#!/usr/bin/env python3
"""
ç®€åŒ–çš„æµ‹è¯•è¿è¡Œå™¨ï¼Œç”¨äºå¿«é€ŸéªŒè¯æ ¸å¿ƒåŠŸèƒ½
"""

import sys
import asyncio
from unittest.mock import AsyncMock, MagicMock, patch

# æ·»åŠ è·¯å¾„
sys.path.append('/Users/runout/awork/code/my_git/agent/apps/api/src')

async def test_annotation_manager_basic():
    """æµ‹è¯•æ³¨è§£ç®¡ç†å™¨åŸºæœ¬åŠŸèƒ½"""
    print("ğŸ” å¼€å§‹æµ‹è¯•æ³¨è§£ç®¡ç†å™¨...")
    
    try:
        # Mockæ•°æ®åº“ä¾èµ–
        with patch('src.ai.training_data_management.annotation.create_engine'):
            from src.ai.training_data_management.annotation import AnnotationManager
            from src.ai.training_data_management.models import AnnotationTask, AnnotationTaskStatus
            
            # åˆ›å»ºmockæ•°æ®åº“ä¼šè¯
            mock_db_session = AsyncMock()
            mock_db_session.add = MagicMock()
            mock_db_session.commit = AsyncMock()
            
            # åˆ›å»ºæ³¨è§£ç®¡ç†å™¨
            manager = AnnotationManager(mock_db_session)
            manager.db = mock_db_session
            
            # æµ‹è¯•åˆ›å»ºä»»åŠ¡
            task_config = {
                'name': 'Test Classification',
                'description': 'Test task',
                'task_type': 'classification',
                'schema': {'type': 'object', 'properties': {'label': {'type': 'string'}}},
                'annotators': ['user1']
            }
            
            from src.ai.training_data_management.models import AnnotationTask
            import uuid
            
            task_obj = AnnotationTask(
                task_id=str(uuid.uuid4()),
                name=task_config['name'],
                description=task_config['description'],
                task_type=task_config['task_type'],
                record_ids=['rec1', 'rec2'],
                schema=task_config['schema'],
                annotators=task_config['annotators']
            )
            
            with patch.object(manager.db, 'add') as mock_add:
                with patch.object(manager.db, 'commit') as mock_commit:
                    with patch.object(manager, 'SessionLocal') as mock_session:
                        # Mockæ•°æ®åº“æŸ¥è¯¢ç»“æœ
                        mock_db = MagicMock()
                        mock_session.return_value.__enter__.return_value = mock_db
                        mock_db.query.return_value.filter.return_value.all.return_value = [
                            MagicMock(record_id='rec1'),
                            MagicMock(record_id='rec2')
                        ]
                        
                        db_id = manager.create_annotation_task(task_obj)
                        task = task_obj  # ä½¿ç”¨åˆ›å»ºçš„ä»»åŠ¡å¯¹è±¡
                    
                    assert task.name == 'Test Classification'
                    assert task.task_type == 'classification'
                    assert task.status == AnnotationTaskStatus.DRAFT  # é»˜è®¤çŠ¶æ€
                    print("âœ… æ³¨è§£ä»»åŠ¡åˆ›å»ºæµ‹è¯•é€šè¿‡")
            
            # æµ‹è¯•åŸºæœ¬æ–¹æ³•å­˜åœ¨æ€§
            assert hasattr(manager, 'create_annotation_task')
            assert hasattr(manager, 'SessionLocal')
            print("âœ… æ³¨è§£ç®¡ç†å™¨åŸºæœ¬æ–¹æ³•æµ‹è¯•é€šè¿‡")
            
        print("ğŸ‰ æ³¨è§£ç®¡ç†å™¨æµ‹è¯•å…¨éƒ¨é€šè¿‡!")
        return True
        
    except Exception as e:
        print(f"âŒ æ³¨è§£ç®¡ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_training_data_api_basic():
    """æµ‹è¯•è®­ç»ƒæ•°æ®APIåŸºæœ¬åŠŸèƒ½"""
    print("ğŸ” å¼€å§‹æµ‹è¯•è®­ç»ƒæ•°æ®API...")
    
    try:
        from src.api.v1.training_data import router, DataSourceCreate, AnnotationTaskCreate
        
        # éªŒè¯è·¯ç”±å™¨åˆ›å»º
        assert router is not None
        assert router.prefix == "/training-data"
        print("âœ… APIè·¯ç”±å™¨åˆ›å»ºæµ‹è¯•é€šè¿‡")
        
        # éªŒè¯Pydanticæ¨¡å‹
        source_data = DataSourceCreate(
            source_id="test-source",
            source_type="file",
            name="Test Source", 
            description="Test description",
            config={"path": "/test/data.json"}
        )
        assert source_data.source_id == "test-source"
        print("âœ… Pydanticæ¨¡å‹æµ‹è¯•é€šè¿‡")
        
        print("ğŸ‰ è®­ç»ƒæ•°æ®APIæµ‹è¯•é€šè¿‡!")
        return True
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒæ•°æ®APIæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """ä¸»æµ‹è¯•å…¥å£"""
    print("ğŸš€ å¼€å§‹è¿è¡Œè®­ç»ƒæ•°æ®ç®¡ç†ç³»ç»Ÿç®€åŒ–æµ‹è¯•...")
    
    results = []
    
    # æµ‹è¯•æ³¨è§£ç®¡ç†å™¨
    results.append(await test_annotation_manager_basic())
    
    # æµ‹è¯•APIè·¯ç”±
    results.append(await test_training_data_api_basic())
    
    # æ±‡æ€»ç»“æœ
    passed = sum(results)
    total = len(results)
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
    print(f"âœ… é€šè¿‡: {passed}/{total}")
    print(f"âŒ å¤±è´¥: {total - passed}/{total}")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†!")
        return 0
    else:
        print("âš ï¸  æœ‰æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥")
        return 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)