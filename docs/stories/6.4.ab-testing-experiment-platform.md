# Story 6.4: A/B测试实验平台

## Status
Done

## Story
**As a** 产品经理和数据分析师,
**I want** 构建完整的A/B测试实验平台，支持实验配置、流量分配、效果评估和统计分析,
**so that** 能够科学地验证产品假设、优化用户体验、并基于数据驱动的方式做出决策

## Acceptance Criteria

1. **实验配置管理系统**
   - 支持创建、编辑、启动、暂停、终止实验
   - 定义实验变体和控制组
   - 配置流量分配比例
   - 设置实验时间窗口和最小样本量

2. **用户分组和流量分配**
   - 实现确定性哈希分组算法
   - 支持多层实验并发运行
   - 用户分组持久化保证一致性
   - 支持黑白名单和定向实验

3. **实验数据收集和存储**
   - 实时事件追踪和记录
   - 支持多种事件类型（点击、浏览、转化等）
   - 数据完整性和准确性保证
   - 高效的数据存储和查询

4. **统计分析引擎**
   - 自动计算统计显著性（p-value）
   - 支持t检验、卡方检验等多种统计方法
   - 计算置信区间和效果大小
   - 统计功效分析和样本量计算

5. **实验监控和报告**
   - 实时实验指标监控
   - 自动生成实验报告
   - 异常检测和告警
   - 可视化仪表板展示

6. **渐进式发布支持**
   - 支持灰度发布策略
   - 自动扩量和收缩机制
   - 风险控制和回滚功能

## Tasks / Subtasks

- [x] **Task 1: 实验配置管理核心实现** (AC: 1)
  - [x] 创建实验配置数据模型和数据库schema
  - [x] 实现实验CRUD API端点
  - [x] 开发实验状态机（草稿->运行->暂停->完成）
  - [x] 实现实验配置验证逻辑
  - [x] 创建实验元数据管理服务

- [x] **Task 2: 用户分组和流量分配系统** (AC: 2)
  - [x] 实现Murmur3哈希函数用于用户分组
  - [x] 创建流量分配算法（支持多变体）
  - [x] 实现分层实验互斥组管理
  - [x] 开发用户分组缓存和持久化机制
  - [x] 实现黑白名单和定向规则引擎

- [x] **Task 3: 事件追踪和数据收集** (AC: 3)
  - [x] 设计事件数据模型和存储schema
  - [x] 实现事件收集API端点
  - [x] 创建事件批量处理和缓冲机制
  - [x] 实现数据去重和质量检查
  - [x] 开发事件流处理pipeline

- [x] **Task 4: 统计分析引擎实现** (AC: 4)
  - [x] 实现基础统计计算（均值、方差、标准差）
  - [x] 开发t检验和卡方检验算法
  - [x] 实现置信区间计算
  - [x] 创建统计功效和样本量计算器
  - [x] 实现多重检验校正（Bonferroni等）

- [x] **Task 5: 实验监控和报告系统** (AC: 5)
  - [x] 创建实验指标实时计算服务
  - [x] 实现实验报告自动生成
  - [x] 开发异常检测算法
  - [x] 创建告警规则引擎
  - [x] 实现报告模板和导出功能

- [x] **Task 6: 前端界面开发** (AC: 1, 5)
  - [x] 创建实验配置界面组件
  - [x] 实现实验列表和管理页面
  - [x] 开发实时监控仪表板
  - [x] 创建实验报告展示页面
  - [x] 实现数据可视化图表

- [x] **Task 7: 渐进式发布功能** (AC: 6)
  - [x] 实现流量渐进调整机制
  - [x] 创建自动扩量规则引擎
  - [x] 开发风险评估和回滚功能
  - [x] 实现发布策略配置管理

- [x] **Task 8: 集成测试和性能优化** (所有AC)
  - [x] 编写完整的单元测试套件
  - [x] 实施集成测试覆盖关键流程
  - [x] 进行负载测试和性能优化
  - [x] 实现监控和日志记录
  - [x] 文档编写和API文档生成

## Dev Notes

### Previous Story Insights
Story 6.1和6.2已经建立了强化学习的基础架构，包括多臂老虎机推荐引擎和Q-Learning智能体。A/B测试平台将与这些系统集成，用于验证和优化强化学习算法的效果。需要特别注意与现有推荐系统的集成点。

### A/B测试平台架构设计
**核心概念** [Source: docs/prd/upgrade-2025/epics/epic-006-reinforcement-learning-personalization.md#ab测试实验框架]:
- 在线实验框架支持并发实验
- 流量分配和用户分组机制
- 实验效果评估和统计显著性检验
- 渐进式推广机制保证安全性

### Data Models
**实验配置数据结构** [Source: 基于Epic 6要求]:
```python
from typing import Dict, List, Optional, Any
from datetime import datetime
from enum import Enum
from pydantic import BaseModel, Field, validator

class ExperimentStatus(str, Enum):
    DRAFT = "draft"
    RUNNING = "running"
    PAUSED = "paused"
    COMPLETED = "completed"
    TERMINATED = "terminated"

class ExperimentVariant(BaseModel):
    """实验变体定义"""
    variant_id: str
    name: str
    description: Optional[str]
    config: Dict[str, Any]  # 变体特定配置
    is_control: bool = False

class TrafficAllocation(BaseModel):
    """流量分配规则"""
    variant_id: str
    percentage: float = Field(ge=0, le=100)
    
    @validator('percentage')
    def validate_percentage(cls, v):
        if not 0 <= v <= 100:
            raise ValueError('Percentage must be between 0 and 100')
        return v

class ExperimentConfig(BaseModel):
    """实验配置"""
    experiment_id: str
    name: str
    description: str
    hypothesis: str  # 实验假设
    owner: str  # 实验负责人
    status: ExperimentStatus = ExperimentStatus.DRAFT
    variants: List[ExperimentVariant]
    traffic_allocation: List[TrafficAllocation]
    start_date: datetime
    end_date: Optional[datetime]
    success_metrics: List[str]  # 成功指标
    guardrail_metrics: List[str]  # 护栏指标
    minimum_sample_size: int
    significance_level: float = 0.05
    power: float = 0.8  # 统计功效
    layers: List[str] = []  # 实验层，用于互斥
    targeting_rules: Optional[Dict[str, Any]]  # 定向规则
    metadata: Dict[str, Any] = {}

class ExperimentAssignment(BaseModel):
    """用户实验分配记录"""
    assignment_id: str
    experiment_id: str
    user_id: str
    variant_id: str
    timestamp: datetime
    context: Dict[str, Any] = {}
    
class ExperimentEvent(BaseModel):
    """实验事件"""
    event_id: str
    experiment_id: str
    user_id: str
    variant_id: str
    event_type: str
    event_value: float = 1.0
    timestamp: datetime
    metadata: Dict[str, Any] = {}

class MetricResult(BaseModel):
    """指标分析结果"""
    metric_name: str
    variant_results: Dict[str, Dict[str, float]]  # variant_id -> stats
    statistical_test: str
    p_value: float
    is_significant: bool
    effect_size: float
    confidence_interval: tuple[float, float]
    sample_size: int
    statistical_power: float
```

### API Specifications
**A/B测试平台API端点** [Source: 推断基于功能需求]:
```python
# 实验管理
POST /api/v1/experiments - 创建新实验
GET /api/v1/experiments - 获取实验列表
GET /api/v1/experiments/{id} - 获取实验详情
PUT /api/v1/experiments/{id} - 更新实验配置
DELETE /api/v1/experiments/{id} - 删除实验
POST /api/v1/experiments/{id}/start - 启动实验
POST /api/v1/experiments/{id}/pause - 暂停实验
POST /api/v1/experiments/{id}/stop - 停止实验

# 流量分配
POST /api/v1/experiments/{id}/assign - 为用户分配实验变体
GET /api/v1/experiments/user/{user_id} - 获取用户的所有实验分配

# 事件追踪
POST /api/v1/experiments/events - 记录实验事件
POST /api/v1/experiments/events/batch - 批量记录事件

# 分析报告
GET /api/v1/experiments/{id}/results - 获取实验结果
GET /api/v1/experiments/{id}/report - 生成实验报告
GET /api/v1/experiments/{id}/metrics/{metric} - 获取特定指标分析

# 监控告警
GET /api/v1/experiments/{id}/monitor - 获取实时监控数据
POST /api/v1/experiments/{id}/alerts - 配置告警规则
```

### Component Specifications
**A/B测试服务架构** [Source: architecture/backend-architecture.md - 推断]:
```python
# 实验管理服务
class ExperimentManager:
    def __init__(self):
        self.experiments = {}
        self.active_experiments = []
        
    async def create_experiment(self, config: ExperimentConfig) -> str:
        """创建新实验"""
        pass
        
    async def start_experiment(self, experiment_id: str):
        """启动实验"""
        pass
        
    async def assign_variant(self, experiment_id: str, user_id: str) -> str:
        """分配用户到实验变体"""
        pass

# 流量分配服务
class TrafficSplitter:
    def __init__(self):
        self.hash_function = self._murmur3_hash
        
    def get_variant(self, user_id: str, experiment_id: str, 
                   allocations: List[TrafficAllocation]) -> str:
        """根据用户ID和实验ID计算变体分配"""
        pass
        
    def _murmur3_hash(self, key: str, seed: int = 0) -> int:
        """Murmur3哈希实现"""
        pass

# 统计分析引擎
class StatisticalAnalyzer:
    def __init__(self):
        self.tests = {
            'ttest': self._perform_ttest,
            'chi2': self._perform_chi2,
            'mann_whitney': self._perform_mann_whitney
        }
        
    async def analyze_metric(self, experiment_id: str, metric: str) -> MetricResult:
        """分析实验指标"""
        pass
        
    def calculate_sample_size(self, effect_size: float, power: float = 0.8,
                             alpha: float = 0.05) -> int:
        """计算所需样本量"""
        pass
        
    def calculate_statistical_power(self, sample_size: int, effect_size: float,
                                   alpha: float = 0.05) -> float:
        """计算统计功效"""
        pass
```

### File Locations
基于项目结构 [Source: architecture/unified-project-structure.md]:
- **后端实现**: `apps/api/src/`
  - `services/ab_testing_service.py` - A/B测试核心服务
  - `services/experiment_manager.py` - 实验管理服务
  - `services/traffic_splitter.py` - 流量分配服务
  - `services/statistical_analyzer.py` - 统计分析引擎
  - `api/v1/experiments.py` - 实验API端点
  - `models/schemas/experiment.py` - 实验数据模型
  - `repositories/experiment_repository.py` - 实验数据访问层
- **前端组件**: `apps/web/src/`
  - `components/experiments/` - 实验管理组件
    - `ExperimentList.tsx` - 实验列表
    - `ExperimentConfig.tsx` - 实验配置
    - `ExperimentMonitor.tsx` - 实验监控
    - `ExperimentReport.tsx` - 实验报告
  - `pages/ExperimentsPage.tsx` - 实验管理页面
  - `services/experimentService.ts` - 前端API服务
- **测试文件**:
  - `apps/api/tests/services/test_ab_testing.py`
  - `apps/api/tests/services/test_statistical_analyzer.py`
  - `apps/web/tests/components/experiments/`

### Technical Constraints
**技术要求** [Source: architecture/tech-stack.md]:
- **Python版本**: 3.11+ (支持最新统计库)
- **统计库**: scipy 1.11+, statsmodels 0.14+
- **数据处理**: pandas 2.0+, numpy 1.24+
- **缓存**: Redis 7.2+ (用户分组缓存)
- **数据库**: PostgreSQL 15+ (实验数据存储)
- **性能要求**: 
  - 变体分配响应时间 < 10ms
  - 支持1000+ QPS事件记录
  - 实验报告生成 < 5秒

### Integration Points
**与现有系统集成**:
1. **强化学习系统集成**: 
   - A/B测试验证RL算法效果
   - 对比不同推荐策略性能
2. **用户系统集成**:
   - 获取用户属性用于定向
   - 用户分组持久化
3. **事件系统集成**:
   - 复用现有事件收集基础设施
   - 与用户行为分析系统共享数据
4. **监控系统集成**:
   - 接入OpenTelemetry追踪
   - 实验指标推送到Prometheus

### Statistical Methods
**统计方法实现要点**:
1. **样本量计算**:
   - 基于效果大小、统计功效、显著性水平
   - 支持连续变量和比例变量
2. **统计检验选择**:
   - 连续变量: t检验、Mann-Whitney U检验
   - 分类变量: 卡方检验、Fisher精确检验
   - 多重比较: Bonferroni校正、FDR控制
3. **实时监控**:
   - Sequential testing避免peek问题
   - 早停规则(futility/efficacy boundaries)

### Testing Requirements
基于测试策略 [Source: architecture/testing-strategy.md]:
- **单元测试**: 
  - 哈希函数的均匀性测试
  - 统计算法正确性验证
  - 流量分配准确性测试
- **集成测试**:
  - 端到端实验流程测试
  - 并发实验互斥性测试
  - 数据一致性验证
- **性能测试**:
  - 高并发事件记录压力测试
  - 大规模数据统计分析性能
- **统计验证**:
  - 使用模拟数据验证统计方法
  - 与标准统计软件对比结果
- **测试覆盖率**: ≥85%

### Testing
**位置**: apps/api/tests/services/ab_testing/
**框架**: pytest + pytest-asyncio + scipy.stats
**覆盖率**: A/B测试模块需要≥85%测试覆盖率
**重点测试**:
- 用户分组算法的确定性和均匀性
- 统计显著性计算的准确性
- 实验状态转换的正确性
- 并发实验的隔离性
- 事件数据的完整性和准确性

## Dev Agent Record

### Agent Model Used
Claude-3.5-Sonnet 用于整个A/B测试平台的设计和实现

### Debug Log References
- 实验流量分配算法优化记录: /tmp/experiment_allocation_debug.log
- 统计分析计算验证记录: /tmp/statistical_analysis_validation.log
- 事件处理性能优化记录: /tmp/event_processing_performance.log

### Completion Notes List
1. **实验配置管理**: 完成了完整的实验CRUD操作和状态管理
2. **流量分配算法**: 实现了Murmur3哈希分组和多变体分配
3. **事件追踪系统**: 建立了实时事件收集和批量处理pipeline
4. **统计分析引擎**: 集成了t检验、卡方检验等多种统计方法
5. **监控报告系统**: 实现了实时监控和自动报告生成
6. **前端界面**: 开发了实验管理、监控、报告的完整UI界面
7. **集成测试**: 通过了端到端实验流程验证
8. **性能优化**: 实现了Redis缓存和批量处理优化

### File List

**后端实现文件**:
- `apps/api/src/services/ab_testing_service.py` - A/B测试核心服务
- `apps/api/src/services/experiment_manager.py` - 实验管理服务  
- `apps/api/src/services/traffic_splitter.py` - 流量分配服务
- `apps/api/src/services/statistical_analyzer.py` - 统计分析引擎
- `apps/api/src/services/experiment_validator.py` - 实验配置验证
- `apps/api/src/services/experiment_metadata_service.py` - 实验元数据管理
- `apps/api/src/services/multi_variant_allocator.py` - 多变体分配器
- `apps/api/src/services/advanced_traffic_allocator.py` - 高级流量分配
- `apps/api/src/services/layered_experiment_manager.py` - 分层实验管理
- `apps/api/src/services/user_assignment_cache.py` - 用户分配缓存
- `apps/api/src/services/targeting_rules_engine.py` - 定向规则引擎
- `apps/api/src/services/event_processing_service.py` - 事件处理服务
- `apps/api/src/services/event_buffer_service.py` - 事件缓冲服务
- `apps/api/src/services/event_batch_manager.py` - 事件批量管理
- `apps/api/src/services/event_stream_pipeline.py` - 事件流处理
- `apps/api/src/services/data_quality_service.py` - 数据质量服务
- `apps/api/src/services/realtime_metrics_service.py` - 实时指标服务
- `apps/api/src/services/report_generation_service.py` - 报告生成服务
- `apps/api/src/services/anomaly_detection_service.py` - 异常检测服务
- `apps/api/src/services/alert_rules_service.py` - 告警规则服务
- `apps/api/src/api/v1/experiments.py` - 实验API端点
- `apps/api/src/api/v1/layered_experiments.py` - 分层实验API
- `apps/api/src/api/v1/assignment_cache.py` - 分配缓存API
- `apps/api/src/api/v1/targeting_rules.py` - 定向规则API
- `apps/api/src/api/v1/event_tracking.py` - 事件追踪API
- `apps/api/src/api/v1/realtime_metrics.py` - 实时指标API
- `apps/api/src/api/v1/report_generation.py` - 报告生成API
- `apps/api/src/api/v1/anomaly_detection.py` - 异常检测API
- `apps/api/src/api/v1/alert_rules.py` - 告警规则API
- `apps/api/src/models/schemas/experiment.py` - 实验数据模型
- `apps/api/src/repositories/experiment_repository.py` - 实验数据访问层
- `apps/api/src/repositories/event_tracking_repository.py` - 事件追踪仓库
- `apps/api/src/alembic/versions/002_create_experiment_tables.py` - 实验表迁移
- `apps/api/src/alembic/versions/003_create_event_tracking_tables.py` - 事件追踪表迁移

**前端实现文件**:
- `apps/web/src/components/experiment/ExperimentCard.tsx` - 实验卡片组件
- `apps/web/src/components/experiment/ExperimentConfigForm.tsx` - 实验配置表单
- `apps/web/src/pages/ExperimentListPage.tsx` - 实验列表页面
- `apps/web/src/pages/ExperimentDashboardPage.tsx` - 实验监控仪表板
- `apps/web/src/pages/ExperimentReportPage.tsx` - 实验报告页面
- `apps/web/src/services/experimentService.ts` - 前端API服务

**测试文件**:
- `apps/api/src/tests/services/test_experiment_service.py` - 实验服务单元测试
- `apps/api/src/tests/integration/test_experiment_workflow.py` - 实验流程集成测试

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-08-19 | 1.0 | Initial story creation for A/B testing platform | Bob (Scrum Master) |

## QA Results

### Review Date: 2025-08-21

### Reviewed By: Quinn (Senior Developer QA)

### Code Quality Assessment

经过详细的代码审查，A/B测试实验平台实现了完整的功能架构，包含实验管理、流量分配、事件追踪和统计分析等核心模块。代码整体结构清晰，符合企业级开发标准。

**整体评级: B+ (良好，有改进空间)**

### 主要优点

1. **架构完整**: 实现了完整的A/B测试生命周期管理
2. **数据模型规范**: Pydantic模型定义清晰，验证逻辑完善
3. **服务分层**: 服务、仓库、API层次分明，符合DDD架构
4. **统计算法**: 实现了多种统计检验方法，具备专业性
5. **缓存策略**: Redis缓存用户分组，提高性能
6. **测试覆盖**: 包含单元测试和集成测试

### Refactoring Performed

- **File**: apps/api/src/services/ab_testing_service.py
  - **Change**: 修复了异步方法调用问题，统一错误处理模式
  - **Why**: 原代码中部分repository调用缺少await关键字
  - **How**: 添加了正确的异步调用，提高了代码的健壮性

- **File**: apps/api/src/services/statistical_analyzer.py
  - **Change**: 优化了置信区间计算，添加了边界检查
  - **Why**: 原实现在样本量过小时可能产生不稳定结果
  - **How**: 增加最小样本量检查，使用更稳健的统计方法

### Compliance Check

- Coding Standards: ✓ 符合PEP8规范，类型注解完整
- Project Structure: ✓ 文件组织符合DDD架构模式
- Testing Strategy: ✓ 具备单元测试和集成测试覆盖
- All ACs Met: ✓ 所有acceptance criteria都有对应实现

### Improvements Checklist

- [x] 修复异步调用问题 (services/ab_testing_service.py)
- [x] 优化统计计算边界检查 (services/statistical_analyzer.py)
- [x] 添加缺失的错误处理 (api/v1/experiments.py)
- [ ] 考虑添加实验配置的版本控制机制
- [ ] 增加实验冲突检测算法优化
- [ ] 补充性能测试用例覆盖大规模场景
- [ ] 添加实验A/A测试验证功能
- [ ] 实现实验结果的置信区间可视化

### Security Review

✓ **通过** - 代码中未发现安全漏洞：
- 输入验证: Pydantic模型提供了完善的数据验证
- SQL注入防护: 使用SQLAlchemy ORM，参数化查询
- 权限控制: API端点包含适当的权限检查机制

### Performance Considerations

✓ **良好** - 性能设计合理：
- 缓存策略: Redis缓存用户分组，减少数据库查询
- 批量处理: 事件记录支持批量操作
- 索引优化: 数据库表设计包含适当索引
- **建议**: 考虑添加分页查询支持大量实验列表

### Statistical Validity Review

✓ **专业** - 统计方法实现正确：
- 支持t检验、卡方检验、Mann-Whitney U检验
- 正确实现了Bonferroni多重比较校正
- 样本量计算基于统计功效分析
- 置信区间计算使用标准统计公式

### Architecture Review

**优点**:
- 服务分层清晰，依赖注入合理
- 数据模型与业务逻辑分离
- 支持多层实验并发运行

**建议**:
- 考虑添加事件溯源(Event Sourcing)支持实验状态历史追踪
- 实验配置可考虑使用策略模式优化变体分配算法

### Final Status

**✓ Approved - Ready for Done**

**总结**: A/B测试平台实现质量良好，核心功能完整，代码结构合理。已修复发现的技术问题，建议项目可以进入Done状态。后续可根据Improvements Checklist中的未完成项目进行增量优化。