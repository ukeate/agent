# Story 8.7: 系统优化和部署

## Status
Ready for Development

## Story
**As a** DevOps工程师和系统架构师,
**I want** 完成知识图谱系统的性能优化和生产环境部署，
**so that** 可以确保系统在生产环境中稳定运行，满足性能指标要求，并具备完善的监控告警和扩容能力

## Acceptance Criteria

1. **性能调优和扩容准备**
   - 完成所有知识图谱组件的性能基准测试和优化
   - 实现数据库连接池优化、缓存策略调优、查询性能优化
   - 设计水平扩容和负载均衡方案，支持多实例部署
   - 系统整体性能满足Epic 8定义的所有技术指标

2. **集成测试和质量保证**  
   - 执行完整的系统集成测试，覆盖所有Epic 8功能模块
   - 实现自动化测试流水线，包含单元测试、集成测试、E2E测试
   - 完成性能压力测试，验证系统在高负载下的稳定性
   - 测试覆盖率≥85%，所有关键路径测试通过率100%

3. **监控告警系统集成**
   - 集成Prometheus监控和Grafana仪表板
   - 实现业务指标监控(查询QPS、准确率、响应时间)
   - 配置告警规则和通知机制(邮件、钉钉、短信)
   - 监控数据保留期≥30天，告警响应时间<5分钟

4. **生产环境部署**
   - 完成Docker容器化和Kubernetes编排配置
   - 实现CI/CD流水线和自动化部署
   - 配置生产环境的安全策略和权限控制
   - 系统可用性≥99.5%，RTO≤15分钟，RPO≤5分钟

5. **文档和运维支持**
   - 编写完整的部署文档、运维手册、故障排查指南
   - 提供API文档、用户手册、开发者指南
   - 实现日志聚合和分析系统
   - 建立运维知识库和问题答疑体系

## Tasks / Subtasks

- [ ] **Task 1: 性能基准测试和优化** (AC: 1)
  - [ ] 创建`apps/api/performance/benchmark_suite.py`性能测试套件
  - [ ] 执行各组件性能基准测试(实体抽取、图谱查询、GraphRAG等)
  - [ ] 进行数据库查询优化、索引调优、连接池配置
  - [ ] 实现缓存策略优化和内存使用优化
  - [ ] 完成负载均衡和扩容方案设计

- [ ] **Task 2: 集成测试和CI/CD流水线** (AC: 2)
  - [ ] 创建`apps/api/tests/integration/test_full_system.py`系统集成测试
  - [ ] 配置GitHub Actions或Jenkins的CI/CD流水线
  - [ ] 实现自动化测试执行和结果报告
  - [ ] 添加性能回归测试和压力测试
  - [ ] 设置测试覆盖率监控和质量门禁

- [ ] **Task 3: 监控和告警系统** (AC: 3)
  - [ ] 创建`infrastructure/monitoring/prometheus-config.yml`监控配置
  - [ ] 设计Grafana仪表板和业务指标监控
  - [ ] 配置告警规则和通知渠道
  - [ ] 实现日志聚合和分析系统(ELK Stack)
  - [ ] 添加健康检查和存活探针

- [ ] **Task 4: 容器化和Kubernetes部署** (AC: 4)
  - [ ] 创建`infrastructure/docker/`容器镜像配置
  - [ ] 设计Kubernetes部署清单和服务配置
  - [ ] 实现ConfigMap和Secret管理
  - [ ] 配置服务网格和流量管理
  - [ ] 设置备份恢复和灾难恢复方案

- [ ] **Task 5: 安全和权限配置** (AC: 4)
  - [ ] 创建`infrastructure/security/`安全策略配置
  - [ ] 实现网络安全策略和防火墙规则
  - [ ] 配置TLS证书和HTTPS加密
  - [ ] 设置访问控制和身份认证
  - [ ] 实现安全扫描和漏洞监控

- [ ] **Task 6: 部署自动化和环境管理** (AC: 4)
  - [ ] 创建`infrastructure/deployment/`部署脚本
  - [ ] 实现多环境配置管理(开发、测试、生产)
  - [ ] 设置蓝绿部署和滚动更新策略
  - [ ] 配置数据迁移和版本升级流程
  - [ ] 实现回滚机制和故障恢复

- [ ] **Task 7: 文档和知识库建设** (AC: 5)
  - [ ] 编写`docs/deployment/`部署和运维文档
  - [ ] 创建API文档和用户使用手册
  - [ ] 建立故障排查指南和FAQ
  - [ ] 设置运维知识库和最佳实践
  - [ ] 提供培训材料和技术支持

- [ ] **Task 8: 生产环境验证和交付** (AC: 1, 2, 3, 4, 5)
  - [ ] 执行生产环境的全面功能验证
  - [ ] 进行性能压力测试和稳定性验证
  - [ ] 完成安全渗透测试和合规检查
  - [ ] 验证监控告警和运维流程
  - [ ] 完成系统交付和知识转移

## Dev Notes

### Epic Context
这是Epic 8: 动态知识图谱系统的最后一个故事，承担整个系统的性能优化、集成测试、生产部署的关键任务。基于前面构建的所有组件(8.1-8.6)，现在需要确保系统在生产环境中的稳定性、性能和可维护性。

### Tech Stack Requirements
**部署和运维技术栈** [Source: docs/prd/upgrade-2025/epics/epic-008-dynamic-knowledge-graph.md]:
- **容器化**: Docker、Docker Compose
- **编排平台**: Kubernetes、Helm Charts
- **CI/CD**: GitHub Actions、Jenkins、GitLab CI
- **监控系统**: Prometheus、Grafana、Jaeger、ELK Stack
- **负载均衡**: Nginx、HAProxy、Istio Service Mesh
- **安全工具**: Vault、cert-manager、Falco

### Deployment Architecture
**部署架构设计** [Source: Epic 8技术实现]:
```yaml
# Kubernetes部署架构
apiVersion: v1
kind: Namespace
metadata:
  name: knowledge-graph-system

---
# API服务部署
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kg-api
  namespace: knowledge-graph-system
spec:
  replicas: 3
  selector:
    matchLabels:
      app: kg-api
  template:
    metadata:
      labels:
        app: kg-api
    spec:
      containers:
      - name: api
        image: knowledge-graph/api:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: kg-secrets
              key: database-url
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: kg-secrets
              key: redis-url
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
# Web服务部署
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kg-web
  namespace: knowledge-graph-system
spec:
  replicas: 2
  selector:
    matchLabels:
      app: kg-web
  template:
    metadata:
      labels:
        app: kg-web
    spec:
      containers:
      - name: web
        image: knowledge-graph/web:latest
        ports:
        - containerPort: 3000
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "1Gi"
            cpu: "500m"

---
# 图数据库部署(Neo4j)
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: neo4j
  namespace: knowledge-graph-system
spec:
  serviceName: neo4j
  replicas: 1
  selector:
    matchLabels:
      app: neo4j
  template:
    metadata:
      labels:
        app: neo4j
    spec:
      containers:
      - name: neo4j
        image: neo4j:5.0-enterprise
        ports:
        - containerPort: 7474
        - containerPort: 7687
        env:
        - name: NEO4J_AUTH
          valueFrom:
            secretKeyRef:
              name: kg-secrets
              key: neo4j-auth
        - name: NEO4J_ACCEPT_LICENSE_AGREEMENT
          value: "yes"
        volumeMounts:
        - name: neo4j-data
          mountPath: /data
        - name: neo4j-logs
          mountPath: /logs
        resources:
          requests:
            memory: "2Gi"
            cpu: "500m"
          limits:
            memory: "8Gi"
            cpu: "2000m"
  volumeClaimTemplates:
  - metadata:
      name: neo4j-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 100Gi
  - metadata:
      name: neo4j-logs
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi

---
# Redis缓存部署
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
  namespace: knowledge-graph-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        volumeMounts:
        - name: redis-data
          mountPath: /data
      volumes:
      - name: redis-data
        emptyDir: {}
```

### Performance Optimization Configuration
**性能优化配置**:
```python
# 性能优化配置
PERFORMANCE_CONFIG = {
    # 数据库连接池优化
    "database": {
        "pool_size": 20,
        "max_overflow": 30,
        "pool_timeout": 30,
        "pool_recycle": 3600,
        "echo": False
    },
    
    # Redis缓存配置
    "cache": {
        "redis_max_connections": 50,
        "default_timeout": 3600,
        "key_prefix": "kg:",
        "compress_threshold": 1024
    },
    
    # API性能配置
    "api": {
        "worker_processes": 4,
        "worker_connections": 1000,
        "keepalive_timeout": 65,
        "max_request_size": "10MB",
        "request_timeout": 30
    },
    
    # 图谱查询优化
    "graph_query": {
        "query_timeout": 30,
        "max_result_size": 10000,
        "enable_query_cache": True,
        "cache_ttl": 1800,
        "connection_pool_size": 10
    },
    
    # GraphRAG优化
    "graphrag": {
        "max_concurrent_queries": 10,
        "vector_cache_size": 1000,
        "reasoning_timeout": 20,
        "max_reasoning_depth": 3
    }
}

# 监控指标配置
MONITORING_METRICS = {
    "api_metrics": [
        "http_requests_total",
        "http_request_duration_seconds",
        "http_requests_in_flight",
        "http_response_size_bytes"
    ],
    
    "business_metrics": [
        "kg_entities_total",
        "kg_relations_total", 
        "kg_queries_per_second",
        "kg_query_accuracy_ratio",
        "kg_graphrag_performance_ratio"
    ],
    
    "system_metrics": [
        "process_cpu_usage",
        "process_memory_usage",
        "database_connections_active",
        "cache_hit_ratio"
    ]
}
```

### File Locations
基于项目结构 [Source: architecture/unified-project-structure.md]:
- **性能测试**: `apps/api/performance/`
  - `benchmark_suite.py` - 性能测试套件（新建）
  - `load_testing.py` - 负载测试（新建）
  - `optimization_config.py` - 优化配置（新建）
- **集成测试**: `apps/api/tests/integration/`
  - `test_full_system.py` - 系统集成测试（新建）
  - `test_performance_regression.py` - 性能回归测试（新建）
- **基础设施**: `infrastructure/`
  - `docker/` - Docker镜像配置（新建）
  - `kubernetes/` - K8s部署配置（新建）
  - `monitoring/` - 监控配置（新建）
  - `security/` - 安全策略（新建）
  - `deployment/` - 部署脚本（新建）
- **CI/CD**: `.github/workflows/`
  - `ci-cd-pipeline.yml` - CI/CD流水线（新建）
  - `performance-test.yml` - 性能测试流水线（新建）
- **文档**: `docs/`
  - `deployment/` - 部署文档（新建）
  - `operations/` - 运维手册（新建）
  - `troubleshooting/` - 故障排查（新建）

### Technical Constraints
**系统优化和部署要求** [Source: Epic 8成功标准]:
- **技术指标**: 实体识别准确率>90%、关系抽取F1>85%、图谱查询延迟<500ms、多跳推理准确率>80%、GraphRAG提升>25%
- **功能指标**: 支持20+实体类型、50+关系类型、中英文双语、1000+并发查询、百万级实体规模
- **质量标准**: 测试覆盖率≥85%、图谱质量分数>8.0/10.0、系统稳定性99.5%、MTTR<15分钟、知识时效性90%在24小时内更新

### Performance Benchmark Suite
**性能基准测试套件**:
```python
import asyncio
import time
import statistics
from typing import Dict, List, Any
from concurrent.futures import ThreadPoolExecutor
import psutil
import aiohttp

class KnowledgeGraphBenchmark:
    """知识图谱系统性能基准测试"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.results = {}
        
    async def run_full_benchmark(self) -> Dict[str, Any]:
        """运行完整的性能基准测试"""
        print("🚀 Starting Knowledge Graph System Benchmark...")
        
        # 1. 实体抽取性能测试
        entity_results = await self.benchmark_entity_extraction()
        
        # 2. 图谱查询性能测试
        query_results = await self.benchmark_graph_queries()
        
        # 3. GraphRAG性能测试
        graphrag_results = await self.benchmark_graphrag()
        
        # 4. SPARQL查询性能测试
        sparql_results = await self.benchmark_sparql_queries()
        
        # 5. 并发性能测试
        concurrency_results = await self.benchmark_concurrency()
        
        # 6. 系统资源使用测试
        resource_results = self.benchmark_resource_usage()
        
        benchmark_summary = {
            "timestamp": time.time(),
            "entity_extraction": entity_results,
            "graph_queries": query_results,
            "graphrag_performance": graphrag_results,
            "sparql_queries": sparql_results,
            "concurrency_performance": concurrency_results,
            "resource_usage": resource_results,
            "overall_score": self.calculate_overall_score([
                entity_results, query_results, graphrag_results,
                sparql_results, concurrency_results
            ])
        }
        
        self.generate_benchmark_report(benchmark_summary)
        return benchmark_summary
    
    async def benchmark_entity_extraction(self) -> Dict[str, float]:
        """实体抽取性能测试"""
        test_texts = [
            "Apple Inc. was founded by Steve Jobs in Cupertino, California.",
            "Microsoft Corporation is headquartered in Redmond, Washington.",
            "Tesla, Inc. is an electric vehicle company led by Elon Musk."
        ] * 100  # 300个测试样本
        
        start_time = time.time()
        
        async with aiohttp.ClientSession() as session:
            tasks = []
            for text in test_texts:
                task = self.post_json(session, "/api/v1/kg/entities/extract", {
                    "text": text
                })
                tasks.append(task)
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
        
        end_time = time.time()
        
        # 计算性能指标
        successful_results = [r for r in results if not isinstance(r, Exception)]
        accuracy_scores = []
        
        for result in successful_results:
            if result and 'accuracy' in result:
                accuracy_scores.append(result['accuracy'])
        
        return {
            "total_time": end_time - start_time,
            "throughput": len(successful_results) / (end_time - start_time),
            "average_accuracy": statistics.mean(accuracy_scores) if accuracy_scores else 0.0,
            "success_rate": len(successful_results) / len(test_texts),
            "avg_response_time": (end_time - start_time) / len(test_texts)
        }
    
    async def benchmark_graphrag(self) -> Dict[str, float]:
        """GraphRAG性能测试"""
        test_queries = [
            "What is the relationship between Apple and Steve Jobs?",
            "How is Microsoft connected to artificial intelligence?",
            "Explain the connection between Tesla and renewable energy."
        ] * 50  # 150个测试查询
        
        start_time = time.time()
        
        async with aiohttp.ClientSession() as session:
            tasks = []
            for query in test_queries:
                task = self.post_json(session, "/api/v1/graphrag/query", {
                    "query": query,
                    "retrieval_mode": "hybrid",
                    "include_reasoning": True,
                    "max_docs": 10
                })
                tasks.append(task)
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
        
        end_time = time.time()
        
        successful_results = [r for r in results if not isinstance(r, Exception)]
        accuracy_improvements = []
        
        for result in successful_results:
            if result and 'performance_metrics' in result:
                # 假设有与传统RAG的对比结果
                improvement = result.get('accuracy_improvement', 0)
                accuracy_improvements.append(improvement)
        
        return {
            "total_time": end_time - start_time,
            "avg_query_time": (end_time - start_time) / len(test_queries),
            "qps": len(successful_results) / (end_time - start_time),
            "success_rate": len(successful_results) / len(test_queries),
            "avg_accuracy_improvement": statistics.mean(accuracy_improvements) if accuracy_improvements else 0.0
        }
    
    async def benchmark_concurrency(self) -> Dict[str, float]:
        """并发性能测试"""
        concurrent_levels = [10, 50, 100, 200, 500]
        results = {}
        
        for level in concurrent_levels:
            print(f"Testing concurrency level: {level}")
            
            start_time = time.time()
            
            async with aiohttp.ClientSession() as session:
                tasks = []
                for i in range(level):
                    task = self.get_json(session, "/api/v1/kg/stats/summary")
                    tasks.append(task)
                
                responses = await asyncio.gather(*tasks, return_exceptions=True)
            
            end_time = time.time()
            
            successful = len([r for r in responses if not isinstance(r, Exception)])
            
            results[f"level_{level}"] = {
                "success_rate": successful / level,
                "avg_response_time": (end_time - start_time) / level,
                "qps": successful / (end_time - start_time)
            }
        
        return results
    
    def benchmark_resource_usage(self) -> Dict[str, float]:
        """系统资源使用测试"""
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        return {
            "cpu_usage_percent": cpu_percent,
            "memory_usage_percent": memory.percent,
            "memory_available_gb": memory.available / (1024**3),
            "disk_usage_percent": disk.percent,
            "disk_free_gb": disk.free / (1024**3)
        }
    
    def calculate_overall_score(self, test_results: List[Dict]) -> float:
        """计算综合性能评分"""
        scores = []
        
        # 基于Epic 8的成功标准计算评分
        for result in test_results:
            if 'average_accuracy' in result:
                # 实体识别准确率评分 (目标>90%)
                accuracy_score = min(100, (result['average_accuracy'] / 0.9) * 100)
                scores.append(accuracy_score)
            
            if 'avg_response_time' in result:
                # 响应时间评分 (目标<500ms)
                time_score = max(0, 100 - (result['avg_response_time'] * 1000 / 500) * 100)
                scores.append(time_score)
            
            if 'qps' in result:
                # QPS评分 (目标>100)
                qps_score = min(100, (result['qps'] / 100) * 100)
                scores.append(qps_score)
        
        return statistics.mean(scores) if scores else 0.0
    
    def generate_benchmark_report(self, results: Dict[str, Any]):
        """生成基准测试报告"""
        report = f"""
# Knowledge Graph System Performance Benchmark Report

## Test Summary
- **Test Date**: {time.strftime('%Y-%m-%d %H:%M:%S')}
- **Overall Score**: {results['overall_score']:.2f}/100

## Performance Results

### Entity Extraction Performance
- **Throughput**: {results['entity_extraction']['throughput']:.2f} requests/sec
- **Average Accuracy**: {results['entity_extraction']['average_accuracy']:.4f}
- **Response Time**: {results['entity_extraction']['avg_response_time']:.3f}s

### GraphRAG Performance  
- **QPS**: {results['graphrag_performance']['qps']:.2f}
- **Average Query Time**: {results['graphrag_performance']['avg_query_time']:.3f}s
- **Accuracy Improvement**: {results['graphrag_performance']['avg_accuracy_improvement']:.2f}%

### System Resource Usage
- **CPU Usage**: {results['resource_usage']['cpu_usage_percent']:.1f}%
- **Memory Usage**: {results['resource_usage']['memory_usage_percent']:.1f}%
- **Available Memory**: {results['resource_usage']['memory_available_gb']:.2f}GB

## Epic 8 Success Criteria Validation
- ✅ Entity Recognition Accuracy: {results['entity_extraction']['average_accuracy']:.1%} (Target: >90%)
- ✅ Graph Query Latency: {results['graph_queries'].get('avg_response_time', 0)*1000:.0f}ms (Target: <500ms)  
- ✅ GraphRAG Improvement: {results['graphrag_performance']['avg_accuracy_improvement']:.1f}% (Target: >25%)
- ✅ Concurrent Query Support: {results['concurrency_performance'].get('level_1000', {}).get('success_rate', 0):.1%} (Target: 1000+ concurrent)

## Recommendations
Based on the benchmark results, consider the following optimizations:
1. Database connection pool tuning for better concurrent performance
2. Query result caching for frequently accessed graph patterns
3. Vector embedding cache optimization for GraphRAG queries
4. Memory usage optimization for large-scale graph processing
        """
        
        with open('benchmark_report.md', 'w') as f:
            f.write(report)
        
        print("📊 Benchmark report generated: benchmark_report.md")
    
    async def post_json(self, session: aiohttp.ClientSession, url: str, data: Dict):
        """POST JSON请求"""
        try:
            async with session.post(f"{self.base_url}{url}", json=data) as response:
                return await response.json()
        except Exception as e:
            return e
    
    async def get_json(self, session: aiohttp.ClientSession, url: str):
        """GET JSON请求"""  
        try:
            async with session.get(f"{self.base_url}{url}") as response:
                return await response.json()
        except Exception as e:
            return e

# 运行基准测试
async def main():
    benchmark = KnowledgeGraphBenchmark()
    results = await benchmark.run_full_benchmark()
    print(f"🎉 Benchmark completed with overall score: {results['overall_score']:.2f}/100")

if __name__ == "__main__":
    asyncio.run(main())
```

### Monitoring and Alerting Configuration
**监控和告警配置**:
```yaml
# Prometheus监控配置
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: knowledge-graph-system
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
    
    rule_files:
      - "/etc/prometheus/rules/*.yml"
    
    scrape_configs:
    - job_name: 'knowledge-graph-api'
      static_configs:
      - targets: ['kg-api:8000']
      metrics_path: '/metrics'
      scrape_interval: 10s
    
    - job_name: 'neo4j'
      static_configs:
      - targets: ['neo4j:2004']
      
    - job_name: 'redis'
      static_configs:
      - targets: ['redis-exporter:9121']

  alert_rules.yml: |
    groups:
    - name: knowledge_graph_alerts
      rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status!~"2.."}[5m]) > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is above 10% for 5 minutes"
      
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 0.5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is above 500ms"
      
      - alert: LowGraphRAGAccuracy
        expr: kg_graphrag_accuracy_ratio < 0.8
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "GraphRAG accuracy is low"
          description: "GraphRAG accuracy has been below 80% for 10 minutes"

---
# Grafana仪表板配置
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboard
  namespace: knowledge-graph-system
data:
  knowledge_graph_dashboard.json: |
    {
      "dashboard": {
        "title": "Knowledge Graph System Dashboard",
        "panels": [
          {
            "title": "API Request Rate",
            "type": "graph",
            "targets": [
              {
                "expr": "rate(http_requests_total[5m])",
                "legendFormat": "{{method}} {{endpoint}}"
              }
            ]
          },
          {
            "title": "Response Time Distribution", 
            "type": "heatmap",
            "targets": [
              {
                "expr": "rate(http_request_duration_seconds_bucket[5m])",
                "legendFormat": "{{le}}"
              }
            ]
          },
          {
            "title": "Graph Query Performance",
            "type": "stat",
            "targets": [
              {
                "expr": "avg(kg_query_duration_seconds)",
                "legendFormat": "Avg Query Time"
              }
            ]
          },
          {
            "title": "Knowledge Graph Statistics",
            "type": "table",
            "targets": [
              {
                "expr": "kg_entities_total",
                "legendFormat": "Total Entities"
              },
              {
                "expr": "kg_relations_total", 
                "legendFormat": "Total Relations"
              }
            ]
          }
        ]
      }
    }
```

### Performance Optimization
**性能优化策略**:
- **数据库优化**: 索引优化、查询计划调优、连接池配置
- **缓存策略**: Redis缓存、查询结果缓存、图谱片段缓存
- **负载均衡**: Nginx反向代理、K8s服务负载均衡、数据库读写分离
- **资源管理**: CPU/内存限制、自动扩缩容、资源监控
- **网络优化**: CDN加速、HTTP/2、gRPC通信

### Testing Requirements
基于测试策略 [Source: architecture/testing-strategy.md]:
- **性能测试**: 基准测试、压力测试、负载测试、容量测试
- **集成测试**: 端到端流程测试、系统集成验证、API接口测试
- **稳定性测试**: 长时间运行测试、故障注入测试、恢复能力测试
- **安全测试**: 渗透测试、漏洞扫描、权限验证、数据保护测试
- **兼容性测试**: 多环境兼容、版本兼容、浏览器兼容测试

### Testing
**位置**: apps/api/performance/ 和 apps/api/tests/integration/
**框架**: pytest + pytest-benchmark + locust + k6
**覆盖率**: 系统集成测试需要≥85%功能覆盖率
**重点测试**:
- Epic 8所有技术指标的性能验证
- 系统在高并发场景下的稳定性测试
- 故障恢复和灾难恢复能力验证
- 监控告警系统的及时性和准确性测试
- 生产环境部署流程的完整性验证

## Dev Agent Record

### Agent Model Used
[待开发时填写]

### Debug Log References
[待开发时填写]

### Completion Notes List
[待开发时填写]

### File List
[待开发时填写]

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-08-22 | 1.0 | Initial story creation for system optimization and deployment | Bob (Scrum Master) |

## QA Results
[待QA审查后填写]