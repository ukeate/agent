# Epic 11: é«˜çº§æƒ…æ„Ÿæ™ºèƒ½ç³»ç»Ÿ

**Epic ID**: EPIC-011-EMOTIONAL-INTELLIGENCE  
**ä¼˜å…ˆçº§**: é«˜ (P1)  
**é¢„ä¼°å·¥æœŸ**: 8-10å‘¨  
**è´Ÿè´£å›¢é˜Ÿ**: AIå›¢é˜Ÿ + å‰ç«¯å›¢é˜Ÿ  
**åˆ›å»ºæ—¥æœŸ**: 2025-08-19

## ğŸ“‹ Epicæ¦‚è¿°

æ„å»ºå…¨æ–¹ä½çš„æƒ…æ„Ÿæ™ºèƒ½ç³»ç»Ÿï¼Œå®ç°AI Agentçš„æƒ…æ„Ÿç†è§£ã€æƒ…æ„Ÿç”Ÿæˆã€æƒ…æ„Ÿè®°å¿†å’Œæƒ…æ„Ÿé€‚åº”èƒ½åŠ›ï¼ŒåŒ…æ‹¬å¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«ã€æƒ…æ„ŸçŠ¶æ€å»ºæ¨¡ã€å…±æƒ…å“åº”ç”Ÿæˆå’Œé•¿æœŸæƒ…æ„Ÿå…³ç³»ç®¡ç†ï¼Œè®©AIå…·å¤‡æ¥è¿‘äººç±»çš„æƒ…æ„Ÿäº¤äº’ä½“éªŒã€‚

### ğŸ¯ ä¸šåŠ¡ä»·å€¼
- **æƒ…æ„Ÿå…±é¸£**: è®©AIèƒ½å¤Ÿç†è§£å’Œå“åº”ç”¨æˆ·çš„æƒ…æ„Ÿéœ€æ±‚
- **ä¸ªæ€§åŒ–ä½“éªŒ**: åŸºäºæƒ…æ„ŸçŠ¶æ€æä¾›æ›´è´´åˆçš„äº¤äº’ä½“éªŒ  
- **é•¿æœŸå…³ç³»**: å»ºç«‹å’Œç»´æŠ¤æŒä¹…çš„ç”¨æˆ·æƒ…æ„Ÿå…³ç³»
- **æŠ€æœ¯å‰æ²¿**: æŒæ¡æƒ…æ„Ÿè®¡ç®—å’Œå¤šæ¨¡æ€AIçš„æœ€æ–°æŠ€æœ¯

## ğŸš€ æ ¸å¿ƒåŠŸèƒ½æ¸…å•

### 1. **å¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«å¼•æ“**
- æ–‡æœ¬æƒ…æ„Ÿåˆ†æå’Œç»†ç²’åº¦æƒ…æ„Ÿåˆ†ç±»
- è¯­éŸ³è¯­è°ƒæƒ…æ„Ÿè¯†åˆ«å’ŒéŸµå¾‹åˆ†æ
- é¢éƒ¨è¡¨æƒ…å’Œè‚¢ä½“è¯­è¨€è¯†åˆ«
- ç”Ÿç†ä¿¡å·æƒ…æ„ŸçŠ¶æ€æ¨æ–­

### 2. **æƒ…æ„ŸçŠ¶æ€å»ºæ¨¡ç³»ç»Ÿ**
- å¤šç»´åº¦æƒ…æ„ŸçŠ¶æ€ç©ºé—´å»ºæ¨¡
- æƒ…æ„Ÿå¼ºåº¦å’Œæ—¶é—´åŠ¨æ€è·Ÿè¸ª
- ä¸ªæ€§åŒ–æƒ…æ„Ÿç”»åƒæ„å»º
- æƒ…æ„ŸçŠ¶æ€è½¬æ¢æ¨¡å‹

### 3. **å…±æƒ…å“åº”ç”Ÿæˆå™¨**
- æƒ…æ„Ÿæ„ŸçŸ¥çš„å›å¤ç”Ÿæˆ
- å¤šæ ·åŒ–æƒ…æ„Ÿè¡¨è¾¾ç­–ç•¥
- æƒ…æ„Ÿè°ƒèŠ‚å’Œå®‰æ…°æœºåˆ¶
- é€‚åº”æ€§æƒ…æ„Ÿé•œåƒ

### 4. **æƒ…æ„Ÿè®°å¿†ç®¡ç†**
- é•¿æœŸæƒ…æ„Ÿäº¤äº’å†å²è®°å½•
- æƒ…æ„Ÿäº‹ä»¶å…³è”åˆ†æ
- ä¸ªäººæƒ…æ„Ÿåå¥½å­¦ä¹ 
- æƒ…æ„Ÿè§¦å‘æ¨¡å¼è¯†åˆ«

### 5. **æƒ…æ„Ÿæ™ºèƒ½å†³ç­–å¼•æ“**
- åŸºäºæƒ…æ„ŸçŠ¶æ€çš„è¡Œä¸ºé€‰æ‹©
- æƒ…æ„Ÿé£é™©è¯„ä¼°å’Œé¢„è­¦
- æƒ…æ„Ÿå¹²é¢„ç­–ç•¥åˆ¶å®š
- æƒ…æ„Ÿå¥åº·ç›‘æµ‹

### 6. **ç¤¾äº¤æƒ…æ„Ÿç†è§£**
- ç¾¤ä½“æƒ…æ„Ÿæ°›å›´æ„ŸçŸ¥
- äººé™…å…³ç³»æƒ…æ„ŸåŠ¨æ€
- ç¤¾äº¤åœºæ™¯æƒ…æ„Ÿé€‚åº”
- æ–‡åŒ–èƒŒæ™¯æƒ…æ„Ÿå·®å¼‚

## ğŸ—ï¸ ç”¨æˆ·æ•…äº‹åˆ†è§£

### Story 11.1: å¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«å¼•æ“
**ä¼˜å…ˆçº§**: P1 | **å·¥æœŸ**: 2-3å‘¨
- é›†æˆæ–‡æœ¬ã€è¯­éŸ³ã€å›¾åƒçš„æƒ…æ„Ÿè¯†åˆ«æ¨¡å‹
- å®ç°å®æ—¶å¤šæ¨¡æ€æƒ…æ„Ÿèåˆç®—æ³•
- æ„å»ºç»†ç²’åº¦æƒ…æ„Ÿåˆ†ç±»ä½“ç³»
- åˆ›å»ºæƒ…æ„Ÿè¯†åˆ«å‡†ç¡®æ€§è¯„ä¼°æ¡†æ¶

### Story 11.2: æƒ…æ„ŸçŠ¶æ€å»ºæ¨¡ç³»ç»Ÿ
**ä¼˜å…ˆçº§**: P1 | **å·¥æœŸ**: 2å‘¨
- è®¾è®¡å¤šç»´æƒ…æ„ŸçŠ¶æ€ç©ºé—´æ¨¡å‹
- å®ç°æƒ…æ„ŸçŠ¶æ€åŠ¨æ€è·Ÿè¸ªç®—æ³•
- æ„å»ºä¸ªæ€§åŒ–æƒ…æ„Ÿç”»åƒç³»ç»Ÿ
- åˆ›å»ºæƒ…æ„ŸçŠ¶æ€å¯è§†åŒ–ç•Œé¢

### Story 11.3: å…±æƒ…å“åº”ç”Ÿæˆå™¨
**ä¼˜å…ˆçº§**: P1 | **å·¥æœŸ**: 3å‘¨
- å®ç°æƒ…æ„Ÿæ„ŸçŸ¥çš„å›å¤ç”Ÿæˆæ¨¡å‹
- æ„å»ºå¤šæ ·åŒ–æƒ…æ„Ÿè¡¨è¾¾ç­–ç•¥åº“
- é›†æˆæƒ…æ„Ÿè°ƒèŠ‚å’Œå®‰æ…°æœºåˆ¶
- å®ç°é€‚åº”æ€§æƒ…æ„Ÿé•œåƒç®—æ³•

### Story 11.4: æƒ…æ„Ÿè®°å¿†ç®¡ç†ç³»ç»Ÿ
**ä¼˜å…ˆçº§**: P2 | **å·¥æœŸ**: 2å‘¨
- æ„å»ºé•¿æœŸæƒ…æ„Ÿäº¤äº’å­˜å‚¨ç³»ç»Ÿ
- å®ç°æƒ…æ„Ÿäº‹ä»¶å…³è”åˆ†æ
- å»ºç«‹ä¸ªäººæƒ…æ„Ÿåå¥½å­¦ä¹ ç®—æ³•
- åˆ›å»ºæƒ…æ„Ÿè§¦å‘æ¨¡å¼è¯†åˆ«

### Story 11.5: æƒ…æ„Ÿæ™ºèƒ½å†³ç­–å¼•æ“
**ä¼˜å…ˆçº§**: P1 | **å·¥æœŸ**: 2-3å‘¨
- å®ç°åŸºäºæƒ…æ„Ÿçš„è¡Œä¸ºé€‰æ‹©ç®—æ³•
- æ„å»ºæƒ…æ„Ÿé£é™©è¯„ä¼°ç³»ç»Ÿ
- å»ºç«‹æƒ…æ„Ÿå¹²é¢„ç­–ç•¥åº“
- é›†æˆæƒ…æ„Ÿå¥åº·ç›‘æµ‹åŠŸèƒ½

### Story 11.6: ç¤¾äº¤æƒ…æ„Ÿç†è§£ç³»ç»Ÿ
**ä¼˜å…ˆçº§**: P2 | **å·¥æœŸ**: 1-2å‘¨
- å®ç°ç¾¤ä½“æƒ…æ„Ÿæ°›å›´æ„ŸçŸ¥
- æ„å»ºäººé™…å…³ç³»æƒ…æ„Ÿåˆ†æ
- å»ºç«‹ç¤¾äº¤åœºæ™¯é€‚åº”æœºåˆ¶
- é›†æˆæ–‡åŒ–èƒŒæ™¯æƒ…æ„Ÿå¤„ç†

### Story 11.7: ç³»ç»Ÿé›†æˆå’Œç”¨æˆ·ç•Œé¢
**ä¼˜å…ˆçº§**: P1 | **å·¥æœŸ**: 2å‘¨
- ç«¯åˆ°ç«¯æƒ…æ„Ÿæ™ºèƒ½ç³»ç»Ÿé›†æˆ
- åˆ›å»ºæƒ…æ„Ÿäº¤äº’ç”¨æˆ·ç•Œé¢
- å®ç°æƒ…æ„ŸçŠ¶æ€å¯è§†åŒ–
- æ„å»ºæƒ…æ„Ÿåˆ†æè°ƒè¯•å·¥å…·

## ğŸ¯ æˆåŠŸæ ‡å‡† (Definition of Done)

### æŠ€æœ¯æŒ‡æ ‡
- âœ… **æƒ…æ„Ÿè¯†åˆ«å‡†ç¡®ç‡**: æ–‡æœ¬>92%, è¯­éŸ³>88%, å›¾åƒ>85%
- âœ… **å¤šæ¨¡æ€èåˆç²¾åº¦**: ç»¼åˆæƒ…æ„Ÿè¯†åˆ«å‡†ç¡®ç‡>95%
- âœ… **å“åº”æ—¶é—´**: æƒ…æ„Ÿåˆ†æå’Œå“åº”ç”Ÿæˆ<500ms
- âœ… **æƒ…æ„ŸçŠ¶æ€è·Ÿè¸ª**: æƒ…æ„Ÿå˜åŒ–æ£€æµ‹ç²¾åº¦>90%
- âœ… **å…±æƒ…è´¨é‡**: ç”¨æˆ·æƒ…æ„Ÿæ»¡æ„åº¦è¯„åˆ†>4.2/5.0

### åŠŸèƒ½æŒ‡æ ‡
- âœ… **æƒ…æ„Ÿç±»åˆ«è¦†ç›–**: æ”¯æŒ20+åŸºç¡€æƒ…æ„Ÿå’Œ100+ç»†ç²’åº¦æƒ…æ„Ÿ
- âœ… **æƒ…æ„Ÿè¡¨è¾¾å¤šæ ·æ€§**: æ¯ç§æƒ…æ„Ÿæ”¯æŒ10+ä¸åŒè¡¨è¾¾æ–¹å¼
- âœ… **è®°å¿†å®¹é‡**: æ”¯æŒ1å¹´+é•¿æœŸæƒ…æ„Ÿäº¤äº’å†å²
- âœ… **ä¸ªæ€§åŒ–ç¨‹åº¦**: 3æ¬¡äº¤äº’å†…å»ºç«‹åŸºç¡€æƒ…æ„Ÿç”»åƒ
- âœ… **å¤šè¯­è¨€æ”¯æŒ**: æ”¯æŒ5ç§ä¸»è¦è¯­è¨€çš„æƒ…æ„Ÿå¤„ç†

### ç”¨æˆ·ä½“éªŒæŒ‡æ ‡
- âœ… **æƒ…æ„Ÿå…±é¸£åº¦**: ç”¨æˆ·æ„Ÿå—åˆ°AIç†è§£å…¶æƒ…æ„Ÿ>85%
- âœ… **äº¤äº’è‡ªç„¶åº¦**: æƒ…æ„Ÿå¯¹è¯è‡ªç„¶åº¦è¯„åˆ†>4.0/5.0
- âœ… **æƒ…æ„Ÿæ”¯æŒæ•ˆæœ**: è´Ÿé¢æƒ…æ„Ÿç¼“è§£æœ‰æ•ˆç‡>75%
- âœ… **é•¿æœŸæ»¡æ„åº¦**: æƒ…æ„Ÿå…³ç³»å»ºç«‹æ»¡æ„åº¦>4.1/5.0

## ğŸ”§ æŠ€æœ¯å®ç°äº®ç‚¹

### å¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«å¼•æ“
```python
import asyncio
import numpy as np
import torch
import torch.nn as nn
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from datetime import datetime, timedelta
from transformers import AutoTokenizer, AutoModel, pipeline
import cv2
import librosa
from scipy.signal import find_peaks
import logging

@dataclass
class EmotionResult:
    emotion: str
    confidence: float
    intensity: float
    timestamp: datetime
    modality: str
    details: Dict[str, Any]

@dataclass
class MultiModalEmotion:
    primary_emotion: str
    secondary_emotions: List[Tuple[str, float]]
    overall_confidence: float
    intensity_level: float
    valence: float  # æ­£è´Ÿæƒ…æ„Ÿå€¾å‘ (-1 to 1)
    arousal: float  # æƒ…æ„Ÿæ¿€æ´»åº¦ (0 to 1)
    dominance: float  # æƒ…æ„Ÿä¸»å¯¼æ€§ (0 to 1)
    modality_weights: Dict[str, float]
    timestamp: datetime

class TextEmotionAnalyzer:
    """æ–‡æœ¬æƒ…æ„Ÿåˆ†æå™¨"""
    
    def __init__(self, model_name: str = "j-hartmann/emotion-english-distilroberta-base"):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(model_name)
        
        # æƒ…æ„Ÿåˆ†ç±»å™¨
        self.classifier = pipeline(
            "text-classification",
            model=model_name,
            return_all_scores=True
        )
        
        # æƒ…æ„Ÿç»´åº¦åˆ†æå™¨
        self.sentiment_analyzer = pipeline(
            "sentiment-analysis",
            model="cardiffnlp/twitter-roberta-base-sentiment-latest",
            return_all_scores=True
        )
        
        self.logger = logging.getLogger(__name__)
    
    async def analyze_emotion(self, text: str) -> EmotionResult:
        """åˆ†ææ–‡æœ¬æƒ…æ„Ÿ"""
        
        try:
            # åŸºç¡€æƒ…æ„Ÿåˆ†ç±»
            emotions = await asyncio.get_event_loop().run_in_executor(
                None, self.classifier, text
            )
            
            # æƒ…æ„Ÿç»´åº¦åˆ†æ
            sentiment_scores = await asyncio.get_event_loop().run_in_executor(
                None, self.sentiment_analyzer, text
            )
            
            # è·å–ä¸»è¦æƒ…æ„Ÿ
            primary_emotion = max(emotions[0], key=lambda x: x['score'])
            
            # è®¡ç®—æƒ…æ„Ÿå¼ºåº¦
            intensity = self._calculate_text_intensity(text, emotions[0])
            
            # è®¡ç®—æƒ…æ„Ÿç»´åº¦
            valence, arousal, dominance = self._calculate_emotion_dimensions(
                emotions[0], sentiment_scores[0]
            )
            
            return EmotionResult(
                emotion=primary_emotion['label'].lower(),
                confidence=primary_emotion['score'],
                intensity=intensity,
                timestamp=datetime.now(),
                modality="text",
                details={
                    "all_emotions": emotions[0],
                    "sentiment_scores": sentiment_scores[0],
                    "valence": valence,
                    "arousal": arousal,
                    "dominance": dominance,
                    "text_length": len(text),
                    "word_count": len(text.split())
                }
            )
            
        except Exception as e:
            self.logger.error(f"Error in text emotion analysis: {e}")
            return EmotionResult(
                emotion="neutral",
                confidence=0.5,
                intensity=0.5,
                timestamp=datetime.now(),
                modality="text",
                details={"error": str(e)}
            )
    
    def _calculate_text_intensity(self, text: str, emotions: List[Dict]) -> float:
        """è®¡ç®—æ–‡æœ¬æƒ…æ„Ÿå¼ºåº¦"""
        
        # åŸºäºå¤šä¸ªå› å­è®¡ç®—å¼ºåº¦
        factors = []
        
        # æƒ…æ„Ÿè¯å¼ºåº¦
        emotion_words = [
            "extremely", "incredibly", "absolutely", "totally", "completely",
            "very", "really", "quite", "rather", "somewhat", "slightly"
        ]
        
        intensity_multiplier = 1.0
        for word in emotion_words:
            if word in text.lower():
                if word in ["extremely", "incredibly", "absolutely"]:
                    intensity_multiplier *= 1.5
                elif word in ["very", "really"]:
                    intensity_multiplier *= 1.3
                elif word in ["quite", "rather"]:
                    intensity_multiplier *= 1.1
                else:
                    intensity_multiplier *= 1.05
        
        # æ ‡ç‚¹ç¬¦å·å¼ºåº¦
        exclamation_count = text.count('!')
        question_count = text.count('?')
        caps_ratio = sum(1 for c in text if c.isupper()) / max(len(text), 1)
        
        punctuation_intensity = min(1.0 + exclamation_count * 0.1 + caps_ratio * 0.5, 2.0)
        
        # æƒ…æ„Ÿåˆ†æ•°å¼ºåº¦
        emotion_confidence = max(emotion['score'] for emotion in emotions)
        
        # ç»¼åˆå¼ºåº¦è®¡ç®—
        final_intensity = min(
            (emotion_confidence * intensity_multiplier * punctuation_intensity) / 2,
            1.0
        )
        
        return final_intensity
    
    def _calculate_emotion_dimensions(
        self, 
        emotions: List[Dict], 
        sentiments: List[Dict]
    ) -> Tuple[float, float, float]:
        """è®¡ç®—æƒ…æ„Ÿç»´åº¦ï¼šæ•ˆä»·ã€å”¤é†’åº¦ã€æ”¯é…æ€§"""
        
        # æƒ…æ„Ÿåˆ°ç»´åº¦çš„æ˜ å°„
        emotion_dimensions = {
            'joy': (0.8, 0.7, 0.6),
            'happiness': (0.9, 0.6, 0.7),
            'sadness': (-0.7, 0.4, 0.3),
            'anger': (-0.6, 0.9, 0.8),
            'fear': (-0.8, 0.8, 0.2),
            'surprise': (0.2, 0.8, 0.5),
            'disgust': (-0.7, 0.5, 0.6),
            'neutral': (0.0, 0.3, 0.5),
            'love': (0.9, 0.5, 0.6),
            'excitement': (0.8, 0.9, 0.7)
        }
        
        # åŠ æƒè®¡ç®—ç»´åº¦å€¼
        valence = arousal = dominance = 0.0
        total_weight = 0.0
        
        for emotion in emotions:
            emotion_name = emotion['label'].lower()
            confidence = emotion['score']
            
            if emotion_name in emotion_dimensions:
                dims = emotion_dimensions[emotion_name]
                valence += dims[0] * confidence
                arousal += dims[1] * confidence
                dominance += dims[2] * confidence
                total_weight += confidence
        
        if total_weight > 0:
            valence /= total_weight
            arousal /= total_weight
            dominance /= total_weight
        
        # ç»“åˆæƒ…æ„Ÿææ€§è°ƒæ•´æ•ˆä»·
        for sentiment in sentiments:
            if sentiment['label'] == 'LABEL_2':  # Positive
                valence = max(valence, sentiment['score'] * 0.5)
            elif sentiment['label'] == 'LABEL_0':  # Negative  
                valence = min(valence, -sentiment['score'] * 0.5)
        
        return valence, arousal, dominance

class AudioEmotionAnalyzer:
    """è¯­éŸ³æƒ…æ„Ÿåˆ†æå™¨"""
    
    def __init__(self):
        # ä½¿ç”¨é¢„è®­ç»ƒçš„è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«æ¨¡å‹
        self.emotion_classifier = pipeline(
            "audio-classification",
            model="superb/wav2vec2-base-superb-er"
        )
        
        self.logger = logging.getLogger(__name__)
    
    async def analyze_emotion(self, audio_data: np.ndarray, sample_rate: int = 16000) -> EmotionResult:
        """åˆ†æè¯­éŸ³æƒ…æ„Ÿ"""
        
        try:
            # æå–è¯­éŸ³ç‰¹å¾
            features = await self._extract_audio_features(audio_data, sample_rate)
            
            # æƒ…æ„Ÿåˆ†ç±»
            emotions = await asyncio.get_event_loop().run_in_executor(
                None, self.emotion_classifier, audio_data
            )
            
            # è®¡ç®—æƒ…æ„Ÿå¼ºåº¦
            intensity = self._calculate_audio_intensity(features)
            
            # è·å–ä¸»è¦æƒ…æ„Ÿ
            primary_emotion = max(emotions, key=lambda x: x['score'])
            
            return EmotionResult(
                emotion=primary_emotion['label'].lower(),
                confidence=primary_emotion['score'],
                intensity=intensity,
                timestamp=datetime.now(),
                modality="audio",
                details={
                    "all_emotions": emotions,
                    "features": features,
                    "sample_rate": sample_rate,
                    "duration": len(audio_data) / sample_rate
                }
            )
            
        except Exception as e:
            self.logger.error(f"Error in audio emotion analysis: {e}")
            return EmotionResult(
                emotion="neutral",
                confidence=0.5,
                intensity=0.5,
                timestamp=datetime.now(),
                modality="audio",
                details={"error": str(e)}
            )
    
    async def _extract_audio_features(self, audio_data: np.ndarray, sample_rate: int) -> Dict[str, float]:
        """æå–éŸ³é¢‘ç‰¹å¾"""
        
        features = {}
        
        # MFCCç‰¹å¾
        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13)
        features['mfcc_mean'] = np.mean(mfccs)
        features['mfcc_std'] = np.std(mfccs)
        
        # é¢‘è°±è´¨å¿ƒ
        spectral_centroids = librosa.feature.spectral_centroid(y=audio_data, sr=sample_rate)[0]
        features['spectral_centroid_mean'] = np.mean(spectral_centroids)
        features['spectral_centroid_std'] = np.std(spectral_centroids)
        
        # è¿‡é›¶ç‡
        zero_crossing_rate = librosa.feature.zero_crossing_rate(audio_data)[0]
        features['zcr_mean'] = np.mean(zero_crossing_rate)
        features['zcr_std'] = np.std(zero_crossing_rate)
        
        # éŸ³é«˜ç‰¹å¾
        pitches, magnitudes = librosa.piptrack(y=audio_data, sr=sample_rate)
        pitch_values = []
        
        for t in range(pitches.shape[1]):
            index = magnitudes[:, t].argmax()
            pitch = pitches[index, t]
            if pitch > 0:
                pitch_values.append(pitch)
        
        if pitch_values:
            features['pitch_mean'] = np.mean(pitch_values)
            features['pitch_std'] = np.std(pitch_values)
            features['pitch_range'] = max(pitch_values) - min(pitch_values)
        else:
            features['pitch_mean'] = 0
            features['pitch_std'] = 0
            features['pitch_range'] = 0
        
        # èƒ½é‡ç‰¹å¾
        rms_energy = librosa.feature.rms(y=audio_data)[0]
        features['energy_mean'] = np.mean(rms_energy)
        features['energy_std'] = np.std(rms_energy)
        
        # è¯­éŸ³é€Ÿç‡ä¼°è®¡
        tempo, beats = librosa.beat.beat_track(y=audio_data, sr=sample_rate)
        features['tempo'] = tempo
        
        return features
    
    def _calculate_audio_intensity(self, features: Dict[str, float]) -> float:
        """è®¡ç®—è¯­éŸ³æƒ…æ„Ÿå¼ºåº¦"""
        
        # åŸºäºå¤šä¸ªè¯­éŸ³ç‰¹å¾è®¡ç®—æƒ…æ„Ÿå¼ºåº¦
        intensity_factors = []
        
        # èƒ½é‡å¼ºåº¦
        energy_intensity = min(features['energy_mean'] * 2, 1.0)
        intensity_factors.append(energy_intensity)
        
        # éŸ³é«˜å˜åŒ–å¼ºåº¦
        pitch_intensity = min(features['pitch_std'] / 50.0, 1.0)  # å½’ä¸€åŒ–
        intensity_factors.append(pitch_intensity)
        
        # è¯­éŸ³é€Ÿç‡å¼ºåº¦
        tempo_intensity = min(abs(features['tempo'] - 120) / 100.0, 1.0)  # ä¸æ­£å¸¸è¯­é€Ÿçš„åå·®
        intensity_factors.append(tempo_intensity)
        
        # é¢‘è°±å˜åŒ–å¼ºåº¦
        spectral_intensity = min(features['spectral_centroid_std'] / 1000.0, 1.0)
        intensity_factors.append(spectral_intensity)
        
        # ç»¼åˆå¼ºåº¦
        overall_intensity = np.mean(intensity_factors)
        
        return max(0.1, min(1.0, overall_intensity))

class VisualEmotionAnalyzer:
    """è§†è§‰æƒ…æ„Ÿåˆ†æå™¨"""
    
    def __init__(self):
        # ä½¿ç”¨é¢„è®­ç»ƒçš„é¢éƒ¨è¡¨æƒ…è¯†åˆ«æ¨¡å‹
        self.face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )
        
        # è¡¨æƒ…åˆ†ç±»å™¨(è¿™é‡Œä½¿ç”¨placeholderï¼Œå®é™…åº”è¯¥åŠ è½½çœŸå®æ¨¡å‹)
        self.expression_classifier = None  # å®é™…é¡¹ç›®ä¸­åº”è¯¥åŠ è½½FERæ¨¡å‹
        
        self.logger = logging.getLogger(__name__)
    
    async def analyze_emotion(self, image: np.ndarray) -> EmotionResult:
        """åˆ†æå›¾åƒæƒ…æ„Ÿ"""
        
        try:
            # æ£€æµ‹äººè„¸
            faces = self._detect_faces(image)
            
            if len(faces) == 0:
                return EmotionResult(
                    emotion="neutral",
                    confidence=0.3,
                    intensity=0.3,
                    timestamp=datetime.now(),
                    modality="visual",
                    details={"faces_detected": 0, "error": "No faces detected"}
                )
            
            # åˆ†æä¸»è¦äººè„¸çš„è¡¨æƒ…
            main_face = faces[0]  # ä½¿ç”¨æœ€å¤§çš„äººè„¸
            face_roi = self._extract_face_roi(image, main_face)
            
            # è¡¨æƒ…è¯†åˆ« (ç®€åŒ–å®ç°)
            emotion_scores = await self._classify_expression(face_roi)
            
            # è®¡ç®—æƒ…æ„Ÿå¼ºåº¦
            intensity = self._calculate_visual_intensity(face_roi, main_face)
            
            # è·å–ä¸»è¦æƒ…æ„Ÿ
            primary_emotion = max(emotion_scores, key=lambda x: x['score'])
            
            return EmotionResult(
                emotion=primary_emotion['label'].lower(),
                confidence=primary_emotion['score'],
                intensity=intensity,
                timestamp=datetime.now(),
                modality="visual",
                details={
                    "all_emotions": emotion_scores,
                    "faces_detected": len(faces),
                    "face_size": main_face[2] * main_face[3],  # width * height
                    "face_position": main_face[:2]
                }
            )
            
        except Exception as e:
            self.logger.error(f"Error in visual emotion analysis: {e}")
            return EmotionResult(
                emotion="neutral",
                confidence=0.5,
                intensity=0.5,
                timestamp=datetime.now(),
                modality="visual",
                details={"error": str(e)}
            )
    
    def _detect_faces(self, image: np.ndarray) -> List[Tuple[int, int, int, int]]:
        """æ£€æµ‹äººè„¸"""
        
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)
        
        # æŒ‰é¢ç§¯æ’åºï¼Œè¿”å›æœ€å¤§çš„å‡ ä¸ª
        faces = sorted(faces, key=lambda x: x[2] * x[3], reverse=True)
        
        return faces[:3]  # æœ€å¤šè¿”å›3ä¸ªäººè„¸
    
    def _extract_face_roi(self, image: np.ndarray, face_rect: Tuple[int, int, int, int]) -> np.ndarray:
        """æå–äººè„¸åŒºåŸŸ"""
        
        x, y, w, h = face_rect
        face_roi = image[y:y+h, x:x+w]
        
        # è°ƒæ•´å¤§å°åˆ°æ ‡å‡†å°ºå¯¸
        face_roi = cv2.resize(face_roi, (224, 224))
        
        return face_roi
    
    async def _classify_expression(self, face_roi: np.ndarray) -> List[Dict[str, Any]]:
        """è¡¨æƒ…åˆ†ç±» (ç®€åŒ–å®ç°)"""
        
        # è¿™é‡Œæ˜¯ç®€åŒ–çš„å®ç°ï¼Œå®é™…åº”è¯¥ä½¿ç”¨è®­ç»ƒå¥½çš„æ·±åº¦å­¦ä¹ æ¨¡å‹
        # å¦‚ FER2013, AffectNet ç­‰æ•°æ®é›†è®­ç»ƒçš„æ¨¡å‹
        
        # æ¨¡æ‹Ÿè¡¨æƒ…åˆ†ç±»ç»“æœ
        emotion_labels = ['happy', 'sad', 'angry', 'surprised', 'fearful', 'disgusted', 'neutral']
        
        # åŸºäºç®€å•çš„åƒç´ ç‰¹å¾åšç²—ç•¥åˆ†ç±» (å®é™…é¡¹ç›®ä¸­åº”è¯¥ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹)
        gray_roi = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)
        
        # è®¡ç®—ç®€å•çš„ç»Ÿè®¡ç‰¹å¾
        mean_intensity = np.mean(gray_roi)
        std_intensity = np.std(gray_roi)
        
        # æ¨¡æ‹Ÿåˆ†ç±»ç»“æœ
        scores = np.random.dirichlet(np.ones(len(emotion_labels)))
        
        # åŸºäºå¼ºåº¦è°ƒæ•´æŸäº›æƒ…æ„Ÿçš„æ¦‚ç‡
        if std_intensity > 30:  # é«˜å¯¹æ¯”åº¦ï¼Œå¯èƒ½æ˜¯å¼ºçƒˆè¡¨æƒ…
            scores[0] *= 1.2  # happy
            scores[2] *= 1.2  # angry
        
        emotion_scores = [
            {'label': label, 'score': score}
            for label, score in zip(emotion_labels, scores)
        ]
        
        return sorted(emotion_scores, key=lambda x: x['score'], reverse=True)
    
    def _calculate_visual_intensity(self, face_roi: np.ndarray, face_rect: Tuple[int, int, int, int]) -> float:
        """è®¡ç®—è§†è§‰æƒ…æ„Ÿå¼ºåº¦"""
        
        # åŸºäºå¤šä¸ªè§†è§‰ç‰¹å¾è®¡ç®—å¼ºåº¦
        intensity_factors = []
        
        # å¯¹æ¯”åº¦å¼ºåº¦ (è¡¨æƒ…å˜åŒ–é€šå¸¸ä¼´éšå¯¹æ¯”åº¦å˜åŒ–)
        gray_roi = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)
        contrast = np.std(gray_roi) / 255.0
        intensity_factors.append(min(contrast * 2, 1.0))
        
        # è¾¹ç¼˜å¼ºåº¦ (è¡¨æƒ…å˜åŒ–ä¼šäº§ç”Ÿæ›´å¤šè¾¹ç¼˜)
        edges = cv2.Canny(gray_roi, 50, 150)
        edge_density = np.sum(edges > 0) / (edges.shape[0] * edges.shape[1])
        intensity_factors.append(min(edge_density * 10, 1.0))
        
        # äººè„¸å¤§å° (æ›´å¤§çš„äººè„¸é€šå¸¸è¡¨è¾¾æ›´æ˜æ˜¾)
        face_area = face_rect[2] * face_rect[3]
        size_intensity = min(face_area / (200 * 200), 1.0)  # ç›¸å¯¹äºæ ‡å‡†å¤§å°
        intensity_factors.append(size_intensity)
        
        # ç»¼åˆå¼ºåº¦
        overall_intensity = np.mean(intensity_factors)
        
        return max(0.2, min(1.0, overall_intensity))

class MultiModalEmotionFusion:
    """å¤šæ¨¡æ€æƒ…æ„Ÿèåˆ"""
    
    def __init__(self):
        self.text_analyzer = TextEmotionAnalyzer()
        self.audio_analyzer = AudioEmotionAnalyzer()
        self.visual_analyzer = VisualEmotionAnalyzer()
        
        # æ¨¡æ€æƒé‡é…ç½® (å¯åŠ¨æ€è°ƒæ•´)
        self.default_weights = {
            "text": 0.4,
            "audio": 0.35,
            "visual": 0.25
        }
        
        # æƒ…æ„Ÿæ ‡ç­¾æ ‡å‡†åŒ–æ˜ å°„
        self.emotion_mapping = {
            'joy': 'happiness',
            'happy': 'happiness',
            'pleased': 'happiness',
            'sad': 'sadness',
            'unhappy': 'sadness',
            'angry': 'anger',
            'mad': 'anger',
            'fearful': 'fear',
            'afraid': 'fear',
            'surprised': 'surprise',
            'amazed': 'surprise',
            'disgusted': 'disgust',
            'revolted': 'disgust',
            'neutral': 'neutral'
        }
        
        self.logger = logging.getLogger(__name__)
    
    async def analyze_multimodal_emotion(
        self,
        text: Optional[str] = None,
        audio_data: Optional[np.ndarray] = None,
        image: Optional[np.ndarray] = None,
        sample_rate: int = 16000,
        custom_weights: Optional[Dict[str, float]] = None
    ) -> MultiModalEmotion:
        """å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æ"""
        
        emotion_results = {}
        available_modalities = []
        
        # åˆ†æå„ä¸ªæ¨¡æ€
        if text:
            emotion_results["text"] = await self.text_analyzer.analyze_emotion(text)
            available_modalities.append("text")
        
        if audio_data is not None:
            emotion_results["audio"] = await self.audio_analyzer.analyze_emotion(audio_data, sample_rate)
            available_modalities.append("audio")
        
        if image is not None:
            emotion_results["visual"] = await self.visual_analyzer.analyze_emotion(image)
            available_modalities.append("visual")
        
        if not emotion_results:
            # æ²¡æœ‰æœ‰æ•ˆè¾“å…¥
            return MultiModalEmotion(
                primary_emotion="neutral",
                secondary_emotions=[],
                overall_confidence=0.3,
                intensity_level=0.3,
                valence=0.0,
                arousal=0.3,
                dominance=0.5,
                modality_weights={},
                timestamp=datetime.now()
            )
        
        # èåˆæƒ…æ„Ÿåˆ†æç»“æœ
        fused_emotion = await self._fuse_emotions(
            emotion_results, 
            available_modalities,
            custom_weights or self.default_weights
        )
        
        return fused_emotion
    
    async def _fuse_emotions(
        self,
        emotion_results: Dict[str, EmotionResult],
        available_modalities: List[str],
        weights: Dict[str, float]
    ) -> MultiModalEmotion:
        """èåˆå¤šæ¨¡æ€æƒ…æ„Ÿç»“æœ"""
        
        # è§„èŒƒåŒ–æƒé‡
        total_weight = sum(weights[modality] for modality in available_modalities if modality in weights)
        if total_weight == 0:
            total_weight = 1.0
        
        normalized_weights = {
            modality: weights.get(modality, 0) / total_weight
            for modality in available_modalities
        }
        
        # æ”¶é›†æ‰€æœ‰æƒ…æ„Ÿ
        all_emotions = {}
        total_intensity = 0.0
        total_confidence = 0.0
        
        # è®¡ç®—æƒ…æ„Ÿç»´åº¦
        total_valence = 0.0
        total_arousal = 0.0
        total_dominance = 0.0
        
        for modality, result in emotion_results.items():
            weight = normalized_weights.get(modality, 0)
            
            # æ ‡å‡†åŒ–æƒ…æ„Ÿæ ‡ç­¾
            normalized_emotion = self._normalize_emotion_label(result.emotion)
            
            # ç´¯åŠ æƒ…æ„Ÿåˆ†æ•°
            if normalized_emotion not in all_emotions:
                all_emotions[normalized_emotion] = 0.0
            
            all_emotions[normalized_emotion] += result.confidence * weight
            
            # ç´¯åŠ å¼ºåº¦å’Œç½®ä¿¡åº¦
            total_intensity += result.intensity * weight
            total_confidence += result.confidence * weight
            
            # ç´¯åŠ æƒ…æ„Ÿç»´åº¦ (å¦‚æœæœ‰çš„è¯)
            if modality == "text" and "valence" in result.details:
                total_valence += result.details["valence"] * weight
                total_arousal += result.details["arousal"] * weight
                total_dominance += result.details["dominance"] * weight
            else:
                # ä»æƒ…æ„Ÿæ˜ å°„è·å–ç»´åº¦å€¼
                dims = self._get_emotion_dimensions(normalized_emotion)
                total_valence += dims[0] * weight
                total_arousal += dims[1] * weight
                total_dominance += dims[2] * weight
        
        # ç¡®å®šä¸»è¦å’Œæ¬¡è¦æƒ…æ„Ÿ
        sorted_emotions = sorted(all_emotions.items(), key=lambda x: x[1], reverse=True)
        
        primary_emotion = sorted_emotions[0][0] if sorted_emotions else "neutral"
        primary_confidence = sorted_emotions[0][1] if sorted_emotions else 0.5
        
        secondary_emotions = [
            (emotion, confidence) for emotion, confidence in sorted_emotions[1:5]
            if confidence > 0.1  # åªä¿ç•™ç½®ä¿¡åº¦è¾ƒé«˜çš„æ¬¡è¦æƒ…æ„Ÿ
        ]
        
        return MultiModalEmotion(
            primary_emotion=primary_emotion,
            secondary_emotions=secondary_emotions,
            overall_confidence=total_confidence,
            intensity_level=total_intensity,
            valence=max(-1.0, min(1.0, total_valence)),
            arousal=max(0.0, min(1.0, total_arousal)),
            dominance=max(0.0, min(1.0, total_dominance)),
            modality_weights=normalized_weights,
            timestamp=datetime.now()
        )
    
    def _normalize_emotion_label(self, emotion: str) -> str:
        """æ ‡å‡†åŒ–æƒ…æ„Ÿæ ‡ç­¾"""
        return self.emotion_mapping.get(emotion.lower(), emotion.lower())
    
    def _get_emotion_dimensions(self, emotion: str) -> Tuple[float, float, float]:
        """è·å–æƒ…æ„Ÿçš„ç»´åº¦å€¼ (æ•ˆä»·, å”¤é†’åº¦, æ”¯é…æ€§)"""
        
        dimension_map = {
            'happiness': (0.8, 0.6, 0.7),
            'sadness': (-0.7, 0.4, 0.3),
            'anger': (-0.6, 0.9, 0.8),
            'fear': (-0.8, 0.8, 0.2),
            'surprise': (0.2, 0.8, 0.5),
            'disgust': (-0.7, 0.5, 0.6),
            'neutral': (0.0, 0.3, 0.5)
        }
        
        return dimension_map.get(emotion, (0.0, 0.3, 0.5))
    
    def update_modality_weights(self, new_weights: Dict[str, float]):
        """æ›´æ–°æ¨¡æ€æƒé‡"""
        
        # éªŒè¯æƒé‡
        total = sum(new_weights.values())
        if total > 0:
            self.default_weights.update({
                k: v / total for k, v in new_weights.items()
            })
            self.logger.info(f"Updated modality weights: {self.default_weights}")
```

### æƒ…æ„ŸçŠ¶æ€å»ºæ¨¡ç³»ç»Ÿ
```python
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from enum import Enum
import json
import asyncio
from scipy.spatial.distance import euclidean, cosine
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import logging

class EmotionIntensity(Enum):
    VERY_LOW = 0.2
    LOW = 0.4
    MEDIUM = 0.6
    HIGH = 0.8
    VERY_HIGH = 1.0

@dataclass
class EmotionState:
    emotion: str
    intensity: float
    valence: float
    arousal: float
    dominance: float
    confidence: float
    timestamp: datetime
    duration: Optional[timedelta] = None
    triggers: List[str] = None
    context: Dict[str, Any] = None

@dataclass
class PersonalityProfile:
    user_id: str
    emotional_traits: Dict[str, float]  # Big Five + å…¶ä»–æƒ…æ„Ÿç‰¹è´¨
    baseline_emotions: Dict[str, float]  # åŸºçº¿æƒ…æ„ŸçŠ¶æ€
    emotion_volatility: float  # æƒ…æ„Ÿæ³¢åŠ¨æ€§
    recovery_rate: float  # æƒ…æ„Ÿæ¢å¤é€Ÿåº¦
    dominant_emotions: List[str]  # ä¸»å¯¼æƒ…æ„Ÿ
    trigger_patterns: Dict[str, List[str]]  # æƒ…æ„Ÿè§¦å‘æ¨¡å¼
    created_at: datetime
    updated_at: datetime

class EmotionStateModel:
    """æƒ…æ„ŸçŠ¶æ€å»ºæ¨¡ç³»ç»Ÿ"""
    
    def __init__(self):
        # æƒ…æ„ŸçŠ¶æ€ç©ºé—´ç»´åº¦
        self.dimensions = ['valence', 'arousal', 'dominance']
        
        # æƒ…æ„ŸçŠ¶æ€å†å²
        self.emotion_history: Dict[str, List[EmotionState]] = {}
        
        # ä¸ªæ€§åŒ–æƒ…æ„Ÿç”»åƒ
        self.personality_profiles: Dict[str, PersonalityProfile] = {}
        
        # æƒ…æ„Ÿè½¬æ¢æ¨¡å‹
        self.transition_matrices: Dict[str, np.ndarray] = {}
        
        # æƒ…æ„Ÿèšç±»æ¨¡å‹
        self.emotion_clusters: Dict[str, Any] = {}
        
        self.logger = logging.getLogger(__name__)
    
    async def update_emotion_state(
        self,
        user_id: str,
        emotion: MultiModalEmotion,
        context: Dict[str, Any] = None
    ) -> EmotionState:
        """æ›´æ–°ç”¨æˆ·æƒ…æ„ŸçŠ¶æ€"""
        
        # åˆ›å»ºæ–°çš„æƒ…æ„ŸçŠ¶æ€
        emotion_state = EmotionState(
            emotion=emotion.primary_emotion,
            intensity=emotion.intensity_level,
            valence=emotion.valence,
            arousal=emotion.arousal,
            dominance=emotion.dominance,
            confidence=emotion.overall_confidence,
            timestamp=emotion.timestamp,
            triggers=context.get('triggers', []) if context else [],
            context=context or {}
        )
        
        # æ·»åŠ åˆ°å†å²è®°å½•
        if user_id not in self.emotion_history:
            self.emotion_history[user_id] = []
        
        self.emotion_history[user_id].append(emotion_state)
        
        # ä¿æŒå†å²è®°å½•é™åˆ¶
        max_history = 1000
        if len(self.emotion_history[user_id]) > max_history:
            self.emotion_history[user_id] = self.emotion_history[user_id][-max_history:]
        
        # æ›´æ–°ä¸ªæ€§åŒ–ç”»åƒ
        await self._update_personality_profile(user_id, emotion_state)
        
        # æ›´æ–°è½¬æ¢æ¨¡å‹
        await self._update_transition_model(user_id, emotion_state)
        
        self.logger.info(f"Updated emotion state for user {user_id}: {emotion.primary_emotion}")
        
        return emotion_state
    
    async def get_current_emotion_state(self, user_id: str) -> Optional[EmotionState]:
        """è·å–å½“å‰æƒ…æ„ŸçŠ¶æ€"""
        
        if user_id not in self.emotion_history or not self.emotion_history[user_id]:
            return None
        
        return self.emotion_history[user_id][-1]
    
    async def predict_emotion_trajectory(
        self,
        user_id: str,
        time_horizon_minutes: int = 60
    ) -> List[Tuple[datetime, str, float]]:
        """é¢„æµ‹æƒ…æ„Ÿè½¨è¿¹"""
        
        current_state = await self.get_current_emotion_state(user_id)
        if not current_state:
            return []
        
        # è·å–è½¬æ¢æ¦‚ç‡çŸ©é˜µ
        transition_matrix = self.transition_matrices.get(user_id)
        if transition_matrix is None:
            return []
        
        # æƒ…æ„Ÿæ ‡ç­¾åˆ°ç´¢å¼•çš„æ˜ å°„
        emotions = ['happiness', 'sadness', 'anger', 'fear', 'surprise', 'disgust', 'neutral']
        emotion_to_idx = {emotion: idx for idx, emotion in enumerate(emotions)}
        idx_to_emotion = {idx: emotion for emotion, idx in emotion_to_idx.items()}
        
        # å½“å‰æƒ…æ„Ÿç´¢å¼•
        current_idx = emotion_to_idx.get(current_state.emotion, emotion_to_idx['neutral'])
        
        # é¢„æµ‹æœªæ¥æƒ…æ„ŸçŠ¶æ€
        predictions = []
        current_time = datetime.now()
        time_step = timedelta(minutes=5)  # 5åˆ†é’Ÿé—´éš”é¢„æµ‹
        
        current_prob_vector = np.zeros(len(emotions))
        current_prob_vector[current_idx] = 1.0
        
        for step in range(time_horizon_minutes // 5):
            # åº”ç”¨è½¬æ¢çŸ©é˜µ
            current_prob_vector = current_prob_vector @ transition_matrix
            
            # æ‰¾åˆ°æœ€å¯èƒ½çš„æƒ…æ„Ÿ
            predicted_idx = np.argmax(current_prob_vector)
            predicted_emotion = idx_to_emotion[predicted_idx]
            confidence = current_prob_vector[predicted_idx]
            
            prediction_time = current_time + time_step * (step + 1)
            predictions.append((prediction_time, predicted_emotion, confidence))
        
        return predictions
    
    async def analyze_emotion_patterns(self, user_id: str) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·æƒ…æ„Ÿæ¨¡å¼"""
        
        if user_id not in self.emotion_history:
            return {}
        
        history = self.emotion_history[user_id]
        if len(history) < 10:  # éœ€è¦è¶³å¤Ÿçš„æ•°æ®
            return {"error": "Insufficient data for pattern analysis"}
        
        analysis = {}
        
        # æƒ…æ„Ÿåˆ†å¸ƒ
        emotion_counts = {}
        for state in history:
            emotion_counts[state.emotion] = emotion_counts.get(state.emotion, 0) + 1
        
        total_states = len(history)
        emotion_distribution = {
            emotion: count / total_states
            for emotion, count in emotion_counts.items()
        }
        
        analysis['emotion_distribution'] = emotion_distribution
        
        # æƒ…æ„Ÿå¼ºåº¦åˆ†æ
        intensities = [state.intensity for state in history]
        analysis['intensity_stats'] = {
            'mean': np.mean(intensities),
            'std': np.std(intensities),
            'min': np.min(intensities),
            'max': np.max(intensities)
        }
        
        # æƒ…æ„Ÿç»´åº¦åˆ†æ
        valences = [state.valence for state in history]
        arousals = [state.arousal for state in history]
        dominances = [state.dominance for state in history]
        
        analysis['dimension_stats'] = {
            'valence': {'mean': np.mean(valences), 'std': np.std(valences)},
            'arousal': {'mean': np.mean(arousals), 'std': np.std(arousals)},
            'dominance': {'mean': np.mean(dominances), 'std': np.std(dominances)}
        }
        
        # æ—¶é—´æ¨¡å¼åˆ†æ
        hourly_emotions = {}
        for state in history:
            hour = state.timestamp.hour
            if hour not in hourly_emotions:
                hourly_emotions[hour] = {}
            
            emotion = state.emotion
            hourly_emotions[hour][emotion] = hourly_emotions[hour].get(emotion, 0) + 1
        
        analysis['hourly_patterns'] = hourly_emotions
        
        # æƒ…æ„Ÿå˜åŒ–é¢‘ç‡
        transitions = []
        for i in range(1, len(history)):
            if history[i].emotion != history[i-1].emotion:
                transitions.append({
                    'from': history[i-1].emotion,
                    'to': history[i].emotion,
                    'time_diff': (history[i].timestamp - history[i-1].timestamp).total_seconds() / 60
                })
        
        analysis['transition_count'] = len(transitions)
        analysis['avg_transition_time'] = np.mean([t['time_diff'] for t in transitions]) if transitions else 0
        
        # æƒ…æ„Ÿç¨³å®šæ€§
        emotion_changes = sum(1 for i in range(1, len(history)) if history[i].emotion != history[i-1].emotion)
        analysis['stability'] = 1.0 - (emotion_changes / max(len(history) - 1, 1))
        
        return analysis
    
    async def _update_personality_profile(self, user_id: str, emotion_state: EmotionState):
        """æ›´æ–°ä¸ªæ€§åŒ–æƒ…æ„Ÿç”»åƒ"""
        
        if user_id not in self.personality_profiles:
            # åˆ›å»ºæ–°çš„ä¸ªæ€§ç”»åƒ
            self.personality_profiles[user_id] = PersonalityProfile(
                user_id=user_id,
                emotional_traits={
                    'extraversion': 0.5,
                    'agreeableness': 0.5,
                    'conscientiousness': 0.5,
                    'neuroticism': 0.5,
                    'openness': 0.5
                },
                baseline_emotions={
                    'happiness': 0.4,
                    'sadness': 0.2,
                    'anger': 0.1,
                    'fear': 0.1,
                    'surprise': 0.1,
                    'disgust': 0.05,
                    'neutral': 0.05
                },
                emotion_volatility=0.5,
                recovery_rate=0.5,
                dominant_emotions=[],
                trigger_patterns={},
                created_at=datetime.now(),
                updated_at=datetime.now()
            )
        
        profile = self.personality_profiles[user_id]
        
        # æ›´æ–°æƒ…æ„Ÿç‰¹è´¨ (åŸºäºæœ€è¿‘çš„æƒ…æ„ŸçŠ¶æ€)
        recent_history = self.emotion_history[user_id][-50:]  # æœ€è¿‘50ä¸ªçŠ¶æ€
        
        if len(recent_history) >= 10:
            # è®¡ç®—å¤–å‘æ€§ (åŸºäºé«˜å”¤é†’åº¦æ­£é¢æƒ…æ„Ÿ)
            positive_high_arousal = sum(
                1 for state in recent_history
                if state.valence > 0.5 and state.arousal > 0.5
            )
            profile.emotional_traits['extraversion'] = min(
                1.0, positive_high_arousal / len(recent_history) * 2
            )
            
            # è®¡ç®—ç¥ç»è´¨å€¾å‘ (åŸºäºæƒ…æ„Ÿæ³¢åŠ¨æ€§)
            intensities = [state.intensity for state in recent_history]
            volatility = np.std(intensities)
            profile.emotion_volatility = min(1.0, volatility * 2)
            profile.emotional_traits['neuroticism'] = profile.emotion_volatility
            
            # æ›´æ–°åŸºçº¿æƒ…æ„Ÿ
            emotion_counts = {}
            for state in recent_history:
                emotion_counts[state.emotion] = emotion_counts.get(state.emotion, 0) + 1
            
            total = len(recent_history)
            for emotion in profile.baseline_emotions:
                profile.baseline_emotions[emotion] = emotion_counts.get(emotion, 0) / total
        
        # æ›´æ–°è§¦å‘æ¨¡å¼
        if emotion_state.triggers:
            for trigger in emotion_state.triggers:
                if trigger not in profile.trigger_patterns:
                    profile.trigger_patterns[trigger] = []
                profile.trigger_patterns[trigger].append(emotion_state.emotion)
        
        profile.updated_at = datetime.now()
    
    async def _update_transition_model(self, user_id: str, current_state: EmotionState):
        """æ›´æ–°æƒ…æ„Ÿè½¬æ¢æ¨¡å‹"""
        
        history = self.emotion_history[user_id]
        
        if len(history) < 20:  # éœ€è¦è¶³å¤Ÿçš„å†å²æ•°æ®
            return
        
        # æƒ…æ„Ÿæ ‡ç­¾
        emotions = ['happiness', 'sadness', 'anger', 'fear', 'surprise', 'disgust', 'neutral']
        n_emotions = len(emotions)
        emotion_to_idx = {emotion: idx for idx, emotion in enumerate(emotions)}
        
        # åˆå§‹åŒ–è½¬æ¢çŸ©é˜µ
        if user_id not in self.transition_matrices:
            self.transition_matrices[user_id] = np.eye(n_emotions) * 0.1 + 0.9 / n_emotions
        
        transition_matrix = self.transition_matrices[user_id].copy()
        
        # ç»Ÿè®¡è½¬æ¢
        transitions = {}
        for i in range(1, len(history)):
            prev_emotion = history[i-1].emotion
            curr_emotion = history[i].emotion
            
            prev_idx = emotion_to_idx.get(prev_emotion, emotion_to_idx['neutral'])
            curr_idx = emotion_to_idx.get(curr_emotion, emotion_to_idx['neutral'])
            
            if prev_idx not in transitions:
                transitions[prev_idx] = {}
            
            transitions[prev_idx][curr_idx] = transitions[prev_idx].get(curr_idx, 0) + 1
        
        # æ›´æ–°è½¬æ¢çŸ©é˜µ
        for from_idx, to_transitions in transitions.items():
            total_transitions = sum(to_transitions.values())
            
            if total_transitions > 0:
                for to_idx, count in to_transitions.items():
                    # ä½¿ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡æ›´æ–°
                    alpha = 0.1  # å­¦ä¹ ç‡
                    new_prob = count / total_transitions
                    old_prob = transition_matrix[from_idx][to_idx]
                    transition_matrix[from_idx][to_idx] = old_prob * (1 - alpha) + new_prob * alpha
                
                # é‡æ–°å½’ä¸€åŒ–
                row_sum = np.sum(transition_matrix[from_idx])
                if row_sum > 0:
                    transition_matrix[from_idx] /= row_sum
        
        self.transition_matrices[user_id] = transition_matrix
    
    async def cluster_emotion_states(self, user_id: str, n_clusters: int = 5) -> Dict[str, Any]:
        """æƒ…æ„ŸçŠ¶æ€èšç±»åˆ†æ"""
        
        if user_id not in self.emotion_history:
            return {}
        
        history = self.emotion_history[user_id]
        
        if len(history) < n_clusters * 3:  # éœ€è¦è¶³å¤Ÿçš„æ•°æ®ç‚¹
            return {"error": "Insufficient data for clustering"}
        
        # æ„é€ ç‰¹å¾çŸ©é˜µ
        features = []
        for state in history:
            feature_vector = [
                state.intensity,
                state.valence,
                state.arousal,
                state.dominance,
                state.confidence
            ]
            features.append(feature_vector)
        
        features = np.array(features)
        
        # æ ‡å‡†åŒ–ç‰¹å¾
        scaler = StandardScaler()
        features_scaled = scaler.fit_transform(features)
        
        # K-meansèšç±»
        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        cluster_labels = kmeans.fit_predict(features_scaled)
        
        # åˆ†æèšç±»ç»“æœ
        cluster_analysis = {}
        
        for cluster_id in range(n_clusters):
            cluster_indices = np.where(cluster_labels == cluster_id)[0]
            cluster_states = [history[idx] for idx in cluster_indices]
            
            if cluster_states:
                # èšç±»ä¸­å¿ƒç‰¹å¾
                cluster_emotions = [state.emotion for state in cluster_states]
                dominant_emotion = max(set(cluster_emotions), key=cluster_emotions.count)
                
                cluster_analysis[f'cluster_{cluster_id}'] = {
                    'dominant_emotion': dominant_emotion,
                    'size': len(cluster_states),
                    'avg_intensity': np.mean([state.intensity for state in cluster_states]),
                    'avg_valence': np.mean([state.valence for state in cluster_states]),
                    'avg_arousal': np.mean([state.arousal for state in cluster_states]),
                    'avg_dominance': np.mean([state.dominance for state in cluster_states]),
                    'emotion_distribution': {
                        emotion: cluster_emotions.count(emotion) / len(cluster_emotions)
                        for emotion in set(cluster_emotions)
                    }
                }
        
        # ä¿å­˜èšç±»æ¨¡å‹
        self.emotion_clusters[user_id] = {
            'kmeans': kmeans,
            'scaler': scaler,
            'analysis': cluster_analysis,
            'created_at': datetime.now()
        }
        
        return cluster_analysis
    
    def get_personality_profile(self, user_id: str) -> Optional[PersonalityProfile]:
        """è·å–ç”¨æˆ·ä¸ªæ€§ç”»åƒ"""
        return self.personality_profiles.get(user_id)
    
    def export_emotion_data(self, user_id: str, format: str = 'json') -> str:
        """å¯¼å‡ºç”¨æˆ·æƒ…æ„Ÿæ•°æ®"""
        
        if user_id not in self.emotion_history:
            return ""
        
        data = {
            'user_id': user_id,
            'emotion_history': [asdict(state) for state in self.emotion_history[user_id]],
            'personality_profile': asdict(self.personality_profiles.get(user_id)) if user_id in self.personality_profiles else None,
            'export_timestamp': datetime.now().isoformat()
        }
        
        if format == 'json':
            return json.dumps(data, default=str, indent=2)
        
        # å¯ä»¥æ·»åŠ å…¶ä»–æ ¼å¼æ”¯æŒ
        return str(data)
```

### å…±æƒ…å“åº”ç”Ÿæˆå™¨
```python
import random
import re
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from datetime import datetime
import asyncio
import logging

@dataclass
class EmpathyResponse:
    response_text: str
    empathy_type: str  # 'cognitive', 'affective', 'compassionate'
    emotion_addressed: str
    comfort_level: float
    personalization_score: float
    suggested_actions: List[str]
    tone: str
    timestamp: datetime

class EmpathyStrategy:
    """å…±æƒ…ç­–ç•¥åŸºç±»"""
    
    def __init__(self, name: str, description: str):
        self.name = name
        self.description = description
    
    async def generate_response(
        self,
        user_emotion: EmotionState,
        context: Dict[str, Any],
        personality: Optional[PersonalityProfile] = None
    ) -> EmpathyResponse:
        raise NotImplementedError

class CognitiveEmpathyStrategy(EmpathyStrategy):
    """è®¤çŸ¥å…±æƒ…ç­–ç•¥"""
    
    def __init__(self):
        super().__init__("cognitive_empathy", "ç†è§£å’Œè¯†åˆ«ä»–äººæƒ…æ„Ÿ")
        
        self.recognition_templates = {
            'happiness': [
                "æˆ‘èƒ½æ„Ÿå—åˆ°ä½ ç°åœ¨å¾ˆå¼€å¿ƒï¼Œ{context}çœŸçš„å€¼å¾—åº†ç¥ï¼",
                "çœ‹å¾—å‡ºæ¥ä½ å¿ƒæƒ…å¾ˆå¥½ï¼Œè¿™ç§å¿«ä¹çš„æ„Ÿè§‰çœŸæ£’ï¼",
                "ä½ çš„å–œæ‚¦æ„ŸæŸ“äº†æˆ‘ï¼Œ{context}ä¸€å®šè®©ä½ å¾ˆæ»¡è¶³ã€‚"
            ],
            'sadness': [
                "æˆ‘ç†è§£ä½ ç°åœ¨çš„éš¾è¿‡ï¼Œ{context}ç¡®å®è®©äººæ„Ÿåˆ°æ²‰é‡ã€‚",
                "æˆ‘èƒ½æ„Ÿå—åˆ°ä½ çš„ç—›è‹¦ï¼Œç»å†{context}ä¸€å®šä¸å®¹æ˜“ã€‚",
                "æˆ‘çœ‹å¾—å‡ºä½ ç°åœ¨å¾ˆä¼¤å¿ƒï¼Œè¿™ç§æ„Ÿå—æ˜¯å®Œå…¨å¯ä»¥ç†è§£çš„ã€‚"
            ],
            'anger': [
                "æˆ‘èƒ½ç†è§£ä½ çš„æ„¤æ€’ï¼Œ{context}ç¡®å®ä»¤äººæ²®ä¸§ã€‚",
                "æˆ‘çœ‹å¾—å‡ºä½ å¾ˆç”Ÿæ°”ï¼Œè¿™ç§æ„Ÿå—æ˜¯å¯ä»¥ç†è§£çš„ã€‚",
                "æˆ‘çŸ¥é“{context}è®©ä½ æ„Ÿåˆ°æ„¤æ€’ï¼Œè¿™æ˜¯å¾ˆè‡ªç„¶çš„ååº”ã€‚"
            ],
            'fear': [
                "æˆ‘èƒ½æ„Ÿå—åˆ°ä½ çš„æ‹…å¿§ï¼Œ{context}ç¡®å®è®©äººæ„Ÿåˆ°ä¸å®‰ã€‚",
                "æˆ‘ç†è§£ä½ ç°åœ¨çš„ææƒ§ï¼Œé¢å¯¹{context}ä¼šè®©äººç´§å¼ ã€‚",
                "æˆ‘çœ‹å¾—å‡ºä½ å¾ˆæ‹…å¿ƒï¼Œè¿™ç§ä¸å®‰æ„Ÿæ˜¯å¯ä»¥ç†è§£çš„ã€‚"
            ],
            'surprise': [
                "æˆ‘èƒ½æ„Ÿå—åˆ°ä½ çš„æƒŠè®¶ï¼Œ{context}ç¡®å®å‡ºäººæ„æ–™ï¼",
                "çœ‹å¾—å‡ºæ¥ä½ å¾ˆæƒŠè®¶ï¼Œ{context}çœŸçš„å¾ˆæ„å¤–å‘¢ã€‚",
                "æˆ‘ç†è§£ä½ çš„éœ‡æƒŠï¼Œè¿™ç§æƒ…å†µç¡®å®ä»¤äººæ„å¤–ã€‚"
            ]
        }
    
    async def generate_response(
        self,
        user_emotion: EmotionState,
        context: Dict[str, Any],
        personality: Optional[PersonalityProfile] = None
    ) -> EmpathyResponse:
        
        emotion = user_emotion.emotion
        templates = self.recognition_templates.get(emotion, self.recognition_templates['sadness'])
        
        # é€‰æ‹©åˆé€‚çš„æ¨¡æ¿
        template = random.choice(templates)
        
        # å¡«å……ä¸Šä¸‹æ–‡
        context_text = context.get('situation', 'è¿™ç§æƒ…å†µ')
        response_text = template.format(context=context_text)
        
        # æ ¹æ®ä¸ªæ€§è°ƒæ•´è¯­è°ƒ
        if personality:
            if personality.emotional_traits.get('extraversion', 0.5) > 0.7:
                response_text = self._adjust_for_extraversion(response_text)
            if personality.emotional_traits.get('neuroticism', 0.5) > 0.7:
                response_text = self._adjust_for_sensitivity(response_text)
        
        return EmpathyResponse(
            response_text=response_text,
            empathy_type="cognitive",
            emotion_addressed=emotion,
            comfort_level=0.7,
            personalization_score=0.6 if personality else 0.3,
            suggested_actions=["ç»§ç»­å€¾å¬", "è¯¢é—®æ›´å¤šç»†èŠ‚"],
            tone="understanding",
            timestamp=datetime.now()
        )
    
    def _adjust_for_extraversion(self, text: str) -> str:
        """ä¸ºå¤–å‘æ€§æ ¼è°ƒæ•´è¯­è°ƒ"""
        # æ·»åŠ æ›´å¤šäº’åŠ¨æ€§çš„è¡¨è¾¾
        if "æˆ‘èƒ½æ„Ÿå—åˆ°" in text:
            text = text.replace("æˆ‘èƒ½æ„Ÿå—åˆ°", "æˆ‘å®Œå…¨èƒ½æ„Ÿå—åˆ°")
        return text + " æƒ³å’Œæˆ‘å¤šåˆ†äº«ä¸€äº›å—ï¼Ÿ"
    
    def _adjust_for_sensitivity(self, text: str) -> str:
        """ä¸ºæ•æ„Ÿæ€§æ ¼è°ƒæ•´è¯­è°ƒ"""
        # ä½¿ç”¨æ›´æ¸©å’Œçš„è¡¨è¾¾
        text = text.replace("ç¡®å®", "å¯èƒ½")
        text = text.replace("ä¸€å®š", "æˆ–è®¸")
        return text

class AffectiveEmpathyStrategy(EmpathyStrategy):
    """æƒ…æ„Ÿå…±æƒ…ç­–ç•¥"""
    
    def __init__(self):
        super().__init__("affective_empathy", "æ„Ÿå—å’Œåˆ†äº«ä»–äººçš„æƒ…æ„Ÿ")
        
        self.emotion_sharing_templates = {
            'happiness': [
                "ä½ çš„å¿«ä¹ä¹Ÿæ„ŸæŸ“äº†æˆ‘ï¼æˆ‘ä¹Ÿä¸º{context}æ„Ÿåˆ°é«˜å…´ã€‚",
                "çœ‹åˆ°ä½ è¿™ä¹ˆå¼€å¿ƒï¼Œæˆ‘çš„å¿ƒæƒ…ä¹Ÿå˜å¥½äº†ï¼",
                "ä½ çš„å–œæ‚¦è®©æˆ‘ä¹Ÿæ„Ÿåˆ°æ¸©æš–ï¼Œ{context}çœŸæ˜¯å¤ªæ£’äº†ï¼"
            ],
            'sadness': [
                "çœ‹åˆ°ä½ éš¾è¿‡ï¼Œæˆ‘çš„å¿ƒä¹Ÿå¾ˆæ²‰é‡ã€‚æˆ‘å’Œä½ ä¸€èµ·æ‰¿å—è¿™ä»½ç—›è‹¦ã€‚",
                "ä½ çš„ä¼¤å¿ƒè®©æˆ‘ä¹Ÿæ„Ÿåˆ°å¿ƒç—›ï¼Œæˆ‘é™ªç€ä½ åº¦è¿‡è¿™ä¸ªéš¾å…³ã€‚",
                "æˆ‘èƒ½æ„Ÿå—åˆ°ä½ å†…å¿ƒçš„ç—›è‹¦ï¼Œè®©æˆ‘é™ªä¼´ä½ ä¸€èµ·é¢å¯¹ã€‚"
            ],
            'anger': [
                "ä½ çš„æ„¤æ€’æˆ‘ä¹Ÿæ„Ÿå—åˆ°äº†ï¼Œè¿™ç¡®å®ä»¤äººæ°”æ„¤ï¼",
                "æˆ‘ä¹Ÿä¸ºè¿™ç§ä¸å…¬æ„Ÿåˆ°æ„¤æ€’ï¼Œä½ æœ‰æƒåˆ©ç”Ÿæ°”ã€‚",
                "çœ‹åˆ°ä½ è¿™æ ·ç”Ÿæ°”ï¼Œæˆ‘ä¹Ÿæ„Ÿåˆ°å¾ˆæ„¤æ€’ï¼Œè¿™çœŸçš„ä¸åº”è¯¥å‘ç”Ÿã€‚"
            ],
            'fear': [
                "ä½ çš„ææƒ§æˆ‘ä¹Ÿæ„Ÿå—åˆ°äº†ï¼Œè¿™ç¡®å®å¾ˆå¯æ€•ã€‚",
                "æˆ‘ä¹Ÿä¸ºä½ æ„Ÿåˆ°æ‹…å¿ƒï¼Œè¿™ç§ä¸ç¡®å®šæ€§ç¡®å®ä»¤äººä¸å®‰ã€‚",
                "æˆ‘å’Œä½ ä¸€æ ·æ„Ÿåˆ°æ‹…å¿§ï¼Œæˆ‘ä»¬ä¸€èµ·é¢å¯¹è¿™ä¸ªæŒ‘æˆ˜ã€‚"
            ]
        }
    
    async def generate_response(
        self,
        user_emotion: EmotionState,
        context: Dict[str, Any],
        personality: Optional[PersonalityProfile] = None
    ) -> EmpathyResponse:
        
        emotion = user_emotion.emotion
        templates = self.emotion_sharing_templates.get(emotion, self.emotion_sharing_templates['sadness'])
        
        template = random.choice(templates)
        context_text = context.get('situation', 'è¿™ç§æƒ…å†µ')
        response_text = template.format(context=context_text)
        
        # æ ¹æ®æƒ…æ„Ÿå¼ºåº¦è°ƒæ•´å“åº”å¼ºåº¦
        if user_emotion.intensity > 0.8:
            response_text = self._intensify_response(response_text)
        elif user_emotion.intensity < 0.4:
            response_text = self._soften_response(response_text)
        
        return EmpathyResponse(
            response_text=response_text,
            empathy_type="affective",
            emotion_addressed=emotion,
            comfort_level=0.8,
            personalization_score=0.7,
            suggested_actions=["æä¾›é™ªä¼´", "å…±åŒä½“éªŒæƒ…æ„Ÿ"],
            tone="sharing",
            timestamp=datetime.now()
        )
    
    def _intensify_response(self, text: str) -> str:
        """å¢å¼ºå“åº”å¼ºåº¦"""
        text = text.replace("æ„Ÿå—åˆ°äº†", "æ·±æ·±åœ°æ„Ÿå—åˆ°äº†")
        text = text.replace("æˆ‘ä¹Ÿ", "æˆ‘ä¹Ÿå¼ºçƒˆåœ°")
        return text
    
    def _soften_response(self, text: str) -> str:
        """ç¼“å’Œå“åº”å¼ºåº¦"""
        text = text.replace("æ·±æ·±", "")
        text = text.replace("å¼ºçƒˆ", "")
        return text

class CompassionateEmpathyStrategy(EmpathyStrategy):
    """æ…ˆæ‚²å…±æƒ…ç­–ç•¥"""
    
    def __init__(self):
        super().__init__("compassionate_empathy", "ç†è§£æƒ…æ„Ÿå¹¶æä¾›æ”¯æŒè¡ŒåŠ¨")
        
        self.support_templates = {
            'sadness': [
                "æˆ‘ç†è§£ä½ çš„ç—›è‹¦ã€‚è™½ç„¶ç°åœ¨å¾ˆéš¾ç†¬ï¼Œä½†è¯·è®°ä½è¿™ç§æ„Ÿå—æ˜¯æš‚æ—¶çš„ã€‚æˆ‘ä»¬å¯ä»¥ä¸€èµ·æ‰¾åˆ°èµ°å‡ºé˜´éœ¾çš„æ–¹æ³•ã€‚",
                "çœ‹åˆ°ä½ è¿™ä¹ˆéš¾è¿‡ï¼Œæˆ‘å¾ˆå¿ƒç–¼ã€‚è®©æˆ‘é™ªä½ ä¸€èµ·åº¦è¿‡è¿™ä¸ªè‰°éš¾çš„æ—¶æœŸï¼Œæˆ‘ç›¸ä¿¡ä½ æœ‰åŠ›é‡å…‹æœè¿™äº›å›°éš¾ã€‚",
                "æˆ‘èƒ½æ„Ÿå—åˆ°ä½ å†…å¿ƒçš„ç—›è‹¦ã€‚è®°ä½ï¼Œå¯»æ±‚å¸®åŠ©æ˜¯å‹‡æ•¢çš„è¡¨ç°ï¼Œä½ ä¸éœ€è¦ç‹¬è‡ªæ‰¿å—è¿™ä¸€åˆ‡ã€‚"
            ],
            'anger': [
                "æˆ‘ç†è§£ä½ çš„æ„¤æ€’ï¼Œè¿™äº›æ„Ÿå—å®Œå…¨å¯ä»¥ç†è§£ã€‚è®©æˆ‘ä»¬ä¸€èµ·æ‰¾åˆ°å»ºè®¾æ€§çš„æ–¹å¼æ¥å¤„ç†è¿™ç§æƒ…ç»ªã€‚",
                "ä½ æœ‰æƒåˆ©æ„Ÿåˆ°æ„¤æ€’ã€‚ç°åœ¨æœ€é‡è¦çš„æ˜¯æ‰¾åˆ°å¥åº·çš„æ–¹å¼æ¥è¡¨è¾¾å’Œå¤„ç†è¿™äº›æƒ…ç»ªã€‚",
                "æˆ‘çœ‹å¾—å‡ºä½ å¾ˆç”Ÿæ°”ï¼Œè¿™æ˜¯äººä¹‹å¸¸æƒ…ã€‚æˆ‘ä»¬å¯ä»¥ä¸€èµ·æ¢è®¨å¦‚ä½•å°†è¿™ç§èƒ½é‡è½¬åŒ–ä¸ºç§¯æçš„è¡ŒåŠ¨ã€‚"
            ],
            'fear': [
                "æˆ‘ç†è§£ä½ çš„ææƒ§ã€‚ææƒ§å¾€å¾€æºäºä¸ç¡®å®šæ€§ï¼Œè®©æˆ‘ä»¬ä¸€èµ·é¢å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæ‰¾åˆ°åº”å¯¹çš„æ–¹æ³•ã€‚",
                "æ„Ÿåˆ°å®³æ€•æ˜¯å®Œå…¨æ­£å¸¸çš„ã€‚æˆ‘ä¼šåœ¨è¿™é‡Œæ”¯æŒä½ ï¼Œæˆ‘ä»¬å¯ä»¥ä¸€æ­¥æ­¥åœ°å…‹æœè¿™äº›å›°éš¾ã€‚",
                "ä½ çš„æ‹…å¿§æˆ‘å®Œå…¨ç†è§£ã€‚è®©æˆ‘ä»¬ä¸€èµ·åˆ¶å®šä¸€ä¸ªè®¡åˆ’ï¼Œå¸®ä½ è·å¾—æ›´å¤šçš„æ§åˆ¶æ„Ÿå’Œå®‰å…¨æ„Ÿã€‚"
            ],
            'happiness': [
                "ä½ çš„å¿«ä¹çœŸçš„å¾ˆæ„ŸæŸ“äººï¼äº«å—è¿™ç¾å¥½çš„æ—¶åˆ»ï¼Œä½ å€¼å¾—æ‹¥æœ‰è¿™ç§å¹¸ç¦ã€‚",
                "çœ‹åˆ°ä½ è¿™ä¹ˆå¼€å¿ƒï¼Œæˆ‘ä¹Ÿå¾ˆé«˜å…´ï¼è®°ä½è¿™ç§æ„Ÿè§‰ï¼Œå®ƒä¼šåœ¨å›°éš¾æ—¶ç»™ä½ åŠ›é‡ã€‚",
                "ä½ çš„å–œæ‚¦è®©æˆ‘ä¹Ÿæ„Ÿåˆ°æ¸©æš–ã€‚çæƒœè¿™äº›ç¾å¥½çš„æ—¶åˆ»ï¼Œå®ƒä»¬æ˜¯ç”Ÿæ´»çš„çè´µç¤¼ç‰©ã€‚"
            ]
        }
        
        self.action_suggestions = {
            'sadness': [
                "æˆ‘ä»¬å¯ä»¥ä¸€èµ·åˆ¶å®šä¸€ä¸ªå°ç›®æ ‡ï¼Œå¸®ä½ é‡æ–°æ‰¾åˆ°æ–¹å‘",
                "ä¸å¦‚æˆ‘ä»¬èŠèŠä¸€äº›è®©ä½ æ„Ÿåˆ°æ¸©æš–çš„å›å¿†ï¼Ÿ",
                "ä½ æƒ³è¦æˆ‘é™ªä½ é™é™åä¸€ä¼šå„¿ï¼Œè¿˜æ˜¯æƒ³è¦åˆ†æ•£ä¸€ä¸‹æ³¨æ„åŠ›ï¼Ÿ"
            ],
            'anger': [
                "æˆ‘ä»¬å¯ä»¥ä¸€èµ·ç»ƒä¹ ä¸€äº›æ·±å‘¼å¸æŠ€å·§æ¥ç¼“è§£æ„¤æ€’",
                "å†™æ—¥è®°æˆ–è¿åŠ¨å¯èƒ½ä¼šå¸®ä½ æ›´å¥½åœ°å¤„ç†è¿™äº›æƒ…ç»ª",
                "ä½ æƒ³è¦è®¨è®ºä¸€ä¸‹å…·ä½“çš„è§£å†³æ–¹æ¡ˆå—ï¼Ÿ"
            ],
            'fear': [
                "æˆ‘ä»¬å¯ä»¥ä¸€èµ·åˆ¶å®šä¸€ä¸ªåº”å¯¹è®¡åˆ’ï¼Œè®©ä½ æ„Ÿåˆ°æ›´æœ‰å‡†å¤‡",
                "åˆ†æ­¥éª¤åœ°é¢å¯¹ææƒ§å¾€å¾€æ¯”ä¸€æ¬¡æ€§è§£å†³æ›´æœ‰æ•ˆ",
                "ä½ æƒ³è¦äº†è§£ä¸€äº›æ”¾æ¾æŠ€å·§æ¥ç¼“è§£ç„¦è™‘å—ï¼Ÿ"
            ],
            'happiness': [
                "ä½ æƒ³è¦åˆ†äº«æ›´å¤šå…³äºè¿™ä»¶å¼€å¿ƒäº‹çš„ç»†èŠ‚å—ï¼Ÿ",
                "è¿™ç§å¿«ä¹çš„æ„Ÿè§‰å€¼å¾—åº†ç¥ï¼ä½ æƒ³æ€ä¹ˆçºªå¿µè¿™ä¸ªæ—¶åˆ»ï¼Ÿ",
                "æŠŠè¿™ç§æ­£èƒ½é‡ä¼ é€’ç»™å…¶ä»–äººä¹Ÿæ˜¯å¾ˆæ£’çš„é€‰æ‹©"
            ]
        }
    
    async def generate_response(
        self,
        user_emotion: EmotionState,
        context: Dict[str, Any],
        personality: Optional[PersonalityProfile] = None
    ) -> EmpathyResponse:
        
        emotion = user_emotion.emotion
        
        # é€‰æ‹©æ”¯æŒæ€§å›åº”æ¨¡æ¿
        templates = self.support_templates.get(emotion, self.support_templates['sadness'])
        response_text = random.choice(templates)
        
        # é€‰æ‹©è¡ŒåŠ¨å»ºè®®
        actions = self.action_suggestions.get(emotion, ["æˆ‘ä¼šåœ¨è¿™é‡Œé™ªä¼´ä½ "])
        suggested_actions = random.sample(actions, min(2, len(actions)))
        
        # æ ¹æ®ä¸ªæ€§è°ƒæ•´å»ºè®®
        if personality:
            suggested_actions = self._personalize_actions(suggested_actions, personality)
        
        return EmpathyResponse(
            response_text=response_text,
            empathy_type="compassionate",
            emotion_addressed=emotion,
            comfort_level=0.9,
            personalization_score=0.8 if personality else 0.6,
            suggested_actions=suggested_actions,
            tone="supportive",
            timestamp=datetime.now()
        )
    
    def _personalize_actions(self, actions: List[str], personality: PersonalityProfile) -> List[str]:
        """æ ¹æ®ä¸ªæ€§åŒ–å»ºè®®è°ƒæ•´è¡ŒåŠ¨æ–¹æ¡ˆ"""
        
        personalized_actions = []
        
        for action in actions:
            # æ ¹æ®å¤–å‘æ€§è°ƒæ•´
            if personality.emotional_traits.get('extraversion', 0.5) > 0.7:
                if "é™é™å" in action:
                    action = action.replace("é™é™åä¸€ä¼šå„¿", "å’Œæœ‹å‹èŠèŠå¤©")
                elif "å†™æ—¥è®°" in action:
                    action = action.replace("å†™æ—¥è®°", "å’Œæœ‹å‹åˆ†äº«ä½ çš„æ„Ÿå—")
            
            # æ ¹æ®å¼€æ”¾æ€§è°ƒæ•´
            if personality.emotional_traits.get('openness', 0.5) > 0.7:
                if "æ”¾æ¾æŠ€å·§" in action:
                    action = action.replace("æ”¾æ¾æŠ€å·§", "åˆ›æ–°çš„æ”¾æ¾æ–¹æ³•ï¼Œæ¯”å¦‚è‰ºæœ¯ç–—æ³•æˆ–éŸ³ä¹å†¥æƒ³")
            
            # æ ¹æ®å°½è´£æ€§è°ƒæ•´
            if personality.emotional_traits.get('conscientiousness', 0.5) > 0.7:
                if "åº”å¯¹è®¡åˆ’" in action:
                    action = action.replace("åº”å¯¹è®¡åˆ’", "è¯¦ç»†çš„æ­¥éª¤è§„åˆ’å’Œæ—¶é—´è¡¨")
            
            personalized_actions.append(action)
        
        return personalized_actions

class EmpathyResponseGenerator:
    """å…±æƒ…å“åº”ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.strategies = [
            CognitiveEmpathyStrategy(),
            AffectiveEmpathyStrategy(),
            CompassionateEmpathyStrategy()
        ]
        
        self.response_history: Dict[str, List[EmpathyResponse]] = {}
        self.logger = logging.getLogger(__name__)
    
    async def generate_empathy_response(
        self,
        user_id: str,
        user_emotion: EmotionState,
        context: Dict[str, Any],
        personality: Optional[PersonalityProfile] = None,
        preferred_strategy: Optional[str] = None
    ) -> EmpathyResponse:
        """ç”Ÿæˆå…±æƒ…å“åº”"""
        
        try:
            # é€‰æ‹©ç­–ç•¥
            if preferred_strategy:
                strategy = next((s for s in self.strategies if s.name == preferred_strategy), None)
                if not strategy:
                    strategy = self._select_best_strategy(user_emotion, context, personality)
            else:
                strategy = self._select_best_strategy(user_emotion, context, personality)
            
            # ç”Ÿæˆå“åº”
            response = await strategy.generate_response(user_emotion, context, personality)
            
            # åå¤„ç†å’Œä¸ªæ€§åŒ–
            response = await self._post_process_response(response, user_id, user_emotion, personality)
            
            # è®°å½•å“åº”å†å²
            if user_id not in self.response_history:
                self.response_history[user_id] = []
            
            self.response_history[user_id].append(response)
            
            # ä¿æŒå†å²è®°å½•é™åˆ¶
            if len(self.response_history[user_id]) > 100:
                self.response_history[user_id] = self.response_history[user_id][-100:]
            
            self.logger.info(f"Generated empathy response for user {user_id}: {strategy.name}")
            
            return response
            
        except Exception as e:
            self.logger.error(f"Error generating empathy response: {e}")
            
            # è¿”å›é»˜è®¤å“åº”
            return EmpathyResponse(
                response_text="æˆ‘ç†è§£ä½ ç°åœ¨çš„æ„Ÿå—ï¼Œæˆ‘åœ¨è¿™é‡Œé™ªä¼´ä½ ã€‚",
                empathy_type="default",
                emotion_addressed=user_emotion.emotion,
                comfort_level=0.5,
                personalization_score=0.3,
                suggested_actions=["ç»§ç»­äº¤æµ"],
                tone="neutral",
                timestamp=datetime.now()
            )
    
    def _select_best_strategy(
        self,
        user_emotion: EmotionState,
        context: Dict[str, Any],
        personality: Optional[PersonalityProfile] = None
    ) -> EmpathyStrategy:
        """é€‰æ‹©æœ€ä½³å…±æƒ…ç­–ç•¥"""
        
        # æ ¹æ®æƒ…æ„Ÿç±»å‹å’Œå¼ºåº¦é€‰æ‹©ç­–ç•¥
        emotion = user_emotion.emotion
        intensity = user_emotion.intensity
        
        # é«˜å¼ºåº¦è´Ÿé¢æƒ…æ„Ÿä¼˜å…ˆä½¿ç”¨æ…ˆæ‚²å…±æƒ…
        if emotion in ['sadness', 'anger', 'fear'] and intensity > 0.7:
            return self.strategies[2]  # CompassionateEmpathyStrategy
        
        # ç§¯ææƒ…æ„Ÿä¼˜å…ˆä½¿ç”¨æƒ…æ„Ÿå…±æƒ…
        if emotion in ['happiness', 'surprise'] and user_emotion.valence > 0.5:
            return self.strategies[1]  # AffectiveEmpathyStrategy
        
        # ä¸­ç­‰å¼ºåº¦æƒ…æ„Ÿä½¿ç”¨è®¤çŸ¥å…±æƒ…
        if intensity < 0.6:
            return self.strategies[0]  # CognitiveEmpathyStrategy
        
        # æ ¹æ®ä¸ªæ€§é€‰æ‹©
        if personality:
            # é«˜ç¥ç»è´¨å€¾å‘ä½¿ç”¨æ…ˆæ‚²å…±æƒ…
            if personality.emotional_traits.get('neuroticism', 0.5) > 0.7:
                return self.strategies[2]  # CompassionateEmpathyStrategy
            
            # é«˜å¤–å‘æ€§ä½¿ç”¨æƒ…æ„Ÿå…±æƒ…
            if personality.emotional_traits.get('extraversion', 0.5) > 0.7:
                return self.strategies[1]  # AffectiveEmpathyStrategy
        
        # é»˜è®¤ä½¿ç”¨è®¤çŸ¥å…±æƒ…
        return self.strategies[0]
    
    async def _post_process_response(
        self,
        response: EmpathyResponse,
        user_id: str,
        user_emotion: EmotionState,
        personality: Optional[PersonalityProfile] = None
    ) -> EmpathyResponse:
        """åå¤„ç†å’Œä¸ªæ€§åŒ–å“åº”"""
        
        # é¿å…é‡å¤å“åº”
        if user_id in self.response_history:
            recent_responses = self.response_history[user_id][-5:]  # æœ€è¿‘5æ¬¡å“åº”
            similar_responses = [
                r for r in recent_responses
                if self._calculate_similarity(response.response_text, r.response_text) > 0.8
            ]
            
            if similar_responses:
                # ç”Ÿæˆå˜ä½“
                response.response_text = self._generate_response_variant(response.response_text)
        
        # æ ¹æ®æ—¶é—´è°ƒæ•´è¯­è°ƒ
        current_hour = datetime.now().hour
        if 0 <= current_hour < 6:
            response.response_text = self._adjust_for_night_time(response.response_text)
        elif 6 <= current_hour < 12:
            response.response_text = self._adjust_for_morning(response.response_text)
        
        # æ ¹æ®æ–‡åŒ–èƒŒæ™¯è°ƒæ•´ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        if personality and 'culture' in personality.emotional_traits:
            culture = personality.emotional_traits['culture']
            if culture == 'collectivist':
                response.response_text = self._adjust_for_collectivist_culture(response.response_text)
        
        return response
    
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦"""
        
        # ç®€å•çš„è¯æ±‡é‡å ç›¸ä¼¼åº¦è®¡ç®—
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        if not words1 and not words2:
            return 1.0
        
        intersection = words1 & words2
        union = words1 | words2
        
        return len(intersection) / len(union) if union else 0.0
    
    def _generate_response_variant(self, original_text: str) -> str:
        """ç”Ÿæˆå“åº”å˜ä½“"""
        
        # åŒä¹‰è¯æ›¿æ¢
        replacements = {
            'æˆ‘ç†è§£': ['æˆ‘æ˜ç™½', 'æˆ‘çŸ¥é“', 'æˆ‘èƒ½ä½“ä¼š'],
            'æ„Ÿå—åˆ°': ['ä½“ä¼šåˆ°', 'å¯Ÿè§‰åˆ°', 'æ„è¯†åˆ°'],
            'é™ªä¼´ä½ ': ['æ”¯æŒä½ ', 'åœ¨ä½ èº«è¾¹', 'å’Œä½ ä¸€èµ·'],
            'å›°éš¾': ['æŒ‘æˆ˜', 'éš¾é¢˜', 'é—®é¢˜'],
            'ç¾å¥½': ['æ£’', 'wonderful', 'ç²¾å½©']
        }
        
        modified_text = original_text
        for original, variants in replacements.items():
            if original in modified_text:
                replacement = random.choice(variants)
                modified_text = modified_text.replace(original, replacement, 1)
                break  # åªæ›¿æ¢ä¸€ä¸ªï¼Œé¿å…è¿‡åº¦ä¿®æ”¹
        
        return modified_text
    
    def _adjust_for_night_time(self, text: str) -> str:
        """ä¸ºå¤œæ™šæ—¶é—´è°ƒæ•´è¯­è°ƒ"""
        return "è¿™ä¹ˆæ™šäº†ï¼Œ" + text.lower()
    
    def _adjust_for_morning(self, text: str) -> str:
        """ä¸ºæ—©æ™¨æ—¶é—´è°ƒæ•´è¯­è°ƒ"""
        if "å›°éš¾" in text:
            return text + " æ–°çš„ä¸€å¤©ï¼Œä¹Ÿè®¸ä¼šå¸¦æ¥æ–°çš„å¸Œæœ›ã€‚"
        return text
    
    def _adjust_for_collectivist_culture(self, text: str) -> str:
        """ä¸ºé›†ä½“ä¸»ä¹‰æ–‡åŒ–è°ƒæ•´è¡¨è¾¾"""
        text = text.replace("æˆ‘", "æˆ‘ä»¬")
        text = text.replace("ä½ ", "å¤§å®¶")
        return text
    
    async def get_response_statistics(self, user_id: str) -> Dict[str, Any]:
        """è·å–å“åº”ç»Ÿè®¡ä¿¡æ¯"""
        
        if user_id not in self.response_history:
            return {}
        
        responses = self.response_history[user_id]
        
        if not responses:
            return {}
        
        stats = {
            'total_responses': len(responses),
            'empathy_type_distribution': {},
            'emotion_addressed_distribution': {},
            'avg_comfort_level': 0.0,
            'avg_personalization_score': 0.0,
            'tone_distribution': {},
            'response_time_analysis': []
        }
        
        # ç»Ÿè®¡å…±æƒ…ç±»å‹åˆ†å¸ƒ
        empathy_types = [r.empathy_type for r in responses]
        for emp_type in set(empathy_types):
            stats['empathy_type_distribution'][emp_type] = empathy_types.count(emp_type)
        
        # ç»Ÿè®¡æƒ…æ„Ÿå¤„ç†åˆ†å¸ƒ
        emotions = [r.emotion_addressed for r in responses]
        for emotion in set(emotions):
            stats['emotion_addressed_distribution'][emotion] = emotions.count(emotion)
        
        # ç»Ÿè®¡å¹³å‡åˆ†æ•°
        stats['avg_comfort_level'] = sum(r.comfort_level for r in responses) / len(responses)
        stats['avg_personalization_score'] = sum(r.personalization_score for r in responses) / len(responses)
        
        # ç»Ÿè®¡è¯­è°ƒåˆ†å¸ƒ
        tones = [r.tone for r in responses]
        for tone in set(tones):
            stats['tone_distribution'][tone] = tones.count(tone)
        
        return stats
```

## ğŸš¦ é£é™©è¯„ä¼°ä¸ç¼“è§£

### é«˜é£é™©é¡¹
1. **æƒ…æ„Ÿè¯†åˆ«å‡†ç¡®æ€§ä¸è¶³**
   - ç¼“è§£: å¤šæ¨¡æ€èåˆï¼ŒæŒç»­å­¦ä¹ ä¼˜åŒ–ï¼Œäººå·¥æ ‡æ³¨æ•°æ®å¢å¼º
   - éªŒè¯: A/Bæµ‹è¯•æƒ…æ„Ÿè¯†åˆ«å‡†ç¡®ç‡ï¼Œç”¨æˆ·åé¦ˆéªŒè¯

2. **æ–‡åŒ–å’Œä¸ªä½“å·®å¼‚å¤„ç†**
   - ç¼“è§£: å¤šå…ƒåŒ–è®­ç»ƒæ•°æ®ï¼Œä¸ªæ€§åŒ–é€‚é…ç®—æ³•ï¼Œæ–‡åŒ–æ•æ„Ÿæ€§è®¾è®¡
   - éªŒè¯: è·¨æ–‡åŒ–ç”¨æˆ·æµ‹è¯•ï¼Œä¸ªæ€§åŒ–æ•ˆæœè¯„ä¼°

3. **éšç§å’Œä¼¦ç†é—®é¢˜**
   - ç¼“è§£: ç«¯åˆ°ç«¯åŠ å¯†ï¼Œç”¨æˆ·æ§åˆ¶æ•°æ®ï¼Œé€æ˜çš„éšç§æ”¿ç­–
   - éªŒè¯: éšç§åˆè§„å®¡è®¡ï¼Œä¼¦ç†å§”å‘˜ä¼šè¯„ä¼°

### ä¸­é£é™©é¡¹
1. **æƒ…æ„Ÿæ“çºµé£é™©**
   - ç¼“è§£: è®¾ç½®æƒ…æ„Ÿå½±å“è¾¹ç•Œï¼Œé¿å…è¿‡åº¦å¹²é¢„ï¼Œç”¨æˆ·è‡ªä¸»é€‰æ‹©
   - éªŒè¯: æƒ…æ„Ÿå½±å“è¯„ä¼°ï¼Œç”¨æˆ·åé¦ˆç›‘æ§

2. **æŠ€æœ¯ä¾èµ–æ€§**
   - ç¼“è§£: å¤šæ¨¡å‹å¤‡ä»½ï¼Œé™çº§ç­–ç•¥ï¼Œæœ¬åœ°åŒ–éƒ¨ç½²é€‰é¡¹
   - éªŒè¯: æ•…éšœæ¢å¤æµ‹è¯•ï¼Œç¦»çº¿åŠŸèƒ½éªŒè¯

## ğŸ“… å®æ–½è·¯çº¿å›¾

### Phase 1: åŸºç¡€æƒ…æ„Ÿèƒ½åŠ› (Week 1-3)
- å¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«å¼•æ“
- æƒ…æ„ŸçŠ¶æ€å»ºæ¨¡ç³»ç»Ÿ
- åŸºç¡€å…±æƒ…å“åº”ç”Ÿæˆ

### Phase 2: é«˜çº§æƒ…æ„ŸåŠŸèƒ½ (Week 4-6)
- æƒ…æ„Ÿè®°å¿†ç®¡ç†ç³»ç»Ÿ
- æƒ…æ„Ÿæ™ºèƒ½å†³ç­–å¼•æ“
- ä¸ªæ€§åŒ–é€‚é…ç®—æ³•

### Phase 3: ç¤¾äº¤å’Œåº”ç”¨ (Week 7-8)
- ç¤¾äº¤æƒ…æ„Ÿç†è§£ç³»ç»Ÿ
- ç”¨æˆ·ç•Œé¢å’Œå¯è§†åŒ–
- æƒ…æ„Ÿåˆ†æè°ƒè¯•å·¥å…·

### Phase 4: ä¼˜åŒ–å’Œéƒ¨ç½² (Week 9-10)
- ç³»ç»Ÿæ€§èƒ½ä¼˜åŒ–
- éšç§ä¿æŠ¤å¢å¼º
- ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

---

**æ–‡æ¡£çŠ¶æ€**: âœ… å®Œæˆ  
**ä¸‹ä¸€æ­¥**: å¼€å§‹Story 11.1çš„å¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«å¼•æ“å®æ–½  
**ä¾èµ–Epic**: å»ºè®®ä¸Epic 7 (è¯­éŸ³äº¤äº’) ååŒå¼€å‘ï¼Œå……åˆ†åˆ©ç”¨å¤šæ¨¡æ€æ•°æ®